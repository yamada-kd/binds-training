{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_xhvUO10XD6"
   },
   "source": [
    "# 敵対的生成ネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5XKyMs27rU-"
   },
   "source": [
    "```{attention}\n",
    "作成途中！！！！！！！\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82Sx06lGrg3K"
   },
   "source": [
    "## 原理とできること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-S6ghDZpmSG"
   },
   "source": [
    "敵対的生成ネットワークとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EliP-z_krg3N"
   },
   "source": [
    "### 原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3P_sTkDzu4O"
   },
   "source": [
    "トランスフォーマーとはアテンションとポジショナルエンコードといわれる技術を用いて，再帰型ニューラルネットワークとは異なる方法で文字列を処理することができるニューラルネットワークの構造です．機械翻訳や質問応答に利用することができます．\n",
    "\n",
    "例えば，機械翻訳の場合，翻訳したい文字列を入力データ，翻訳結果の文字列を教師データとして利用します．構築した人工知能は翻訳したい文字列を入力値として受け取り，配列を出力します．配列の各要素は文字の個数と同じサイズのベクトル（その要素が何の文字なのかを示す確率ベクトル）です．\n",
    "\n",
    "トランスフォーマーはエンコーダーとデコーダーという構造からなります．エンコーダーは配列（機械翻訳の場合，翻訳したい配列）を入力にして，同じ長さの配列を出力します．デコーダーも配列（機械翻訳の場合，翻訳で得たい配列）とエンコーダーが出力した配列を入力にして同じ長さの配列（各要素は確率ベクトル）を出力します．エンコーダーが出力した配列情報をデコーダーで処理する際にアテンションという技術が利用されます．\n",
    "\n",
    "<img src=\"https://github.com/yamada-kd/binds-training/blob/main/image/transformer.svg?raw=1\" width=\"100%\" />\n",
    "\n",
    "エンコーダーとデコーダー間のアテンション以外にも，エンコーダーとデコーダーの内部でもそれぞれアテンション（セルフアテンション）が計算されます．アテンションは文字列内における文字の関連性を計算します．\n",
    "\n",
    "トランスフォーマーは再帰型ニューラルネットワークで行うような文字の逐次的な処理が不要です．よって，計算機の並列化性能をより引き出せます．扱える文脈の長さも無限です（再帰型ニューラルネットワークでも理論上無限です．）．\n",
    "\n",
    "このトランスフォーマーはものすごい性能を発揮しており，これまでに作られてきた様々な構造を過去のものとしました．特に応用の範囲が広いのはトランスフォーマーのエンコーダーの部分です．BERT と呼ばれる方法を筆頭に自然言語からなる配列を入力にして何らかの分散表現を出力する方法として自然言語処理に関わる様々な研究開発に利用されています．\n",
    "\n",
    "（会話でトランスフォーマーという場合は，トランスフォーマーのエンコーダーまたはデコーダーのことを言っている場合があります．エンコーダー・デコーダー，エンコーダー，デコーダー，この3個でそれぞれできることが異なります．）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8ViTfSl3gha"
   },
   "source": [
    "```{hint}\n",
    "実用上，配列を入力にして配列を返す構造とだけ覚えておけば問題はないと思います．\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isuh1_iiygT0"
   },
   "source": [
    "### できること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtIMcWPodXRj"
   },
   "source": [
    "Hugging Face で扱うことができるタスクは以下に示すものがあります．これ以外にもありますが自然言語処理に関する代表的なタスクを抽出しました．括弧内の文字列は実際に Hugging Face を利用する際に指定するオプションです（後で利用します．）．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRGjF8pHdtO1"
   },
   "source": [
    "    \n",
    "\n",
    "*   感情分析（`sentiment-analysis`）：入力した文章が有する感情を予測\n",
    "*   特徴抽出（`feature-extraction`）：入力した文章をその特徴を示すベクトルに変換\n",
    "*   穴埋め（`fill-mask`）：文章中のマスクされた単語を予測\n",
    "*   固有表現抽出（`ner`）：入力した文章中の固有表現（名前とか場所とか）にラベルをつける\n",
    "*   質問応答（`question-answering`）：質問文とその答えが含まれる何らかの説明文を入力として解答文を生成\n",
    "*   要約（`summarization`）：入力した文章を要約\n",
    "*   文章生成（`text-generation`）：文章を入力にして，その文章に続く文章を生成\n",
    "*   翻訳（`translation`）：文章を他の言語に翻訳\n",
    "*   ゼロショット文章分類（`zero-shot-classification`）：文章とそれが属する可能性があるいくつかのカテゴリを入力にしてその文章をひとつのカテゴリに分類\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RlLdfs5ynbW"
   },
   "source": [
    "## 基本的な構造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZpHl3AlpmSN"
   },
   "source": [
    "とても簡単に自然言語処理を実現することができる利用方法を紹介します．世界最高性能を求めたいとかでないなら，ここで紹介する方法を利用して様々なことを達成できると思います．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saOu-Onk5d-w"
   },
   "source": [
    "### 感情分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_RY-XjT5d-w"
   },
   "source": [
    "最も簡単な `tranformers` の利用方法は以下のようになると思います．`pipeline` を読み込んで，そこに取り組みたいタスク（`sentiment-analysis`）を指定します．初回の起動の際には事前学習済みモデルがダウンロードされるため時間がかかります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4QgsbGyfBA3"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "from transformers import pipeline\n",
    " \n",
    "def main():\n",
    "    classifier = pipeline(\"sentiment-analysis\")\n",
    "    text = \"I have a pen.\"\n",
    "    result = classifier(text)\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE4KbHIJHDFk"
   },
   "source": [
    "入力した文章がポジティブな文章なのかネガティブな文章なのかを分類できます．ここでは1個の文章を入力しましたが，以下のように2個以上の文章も入力可能です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVrVwjvFHVax"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "from transformers import pipeline\n",
    " \n",
    "def main():\n",
    "    classifier = pipeline(\"sentiment-analysis\")\n",
    "    litext = [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    "    result = classifier(litext)\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqwWY1c0O02R"
   },
   "source": [
    "## WGAN-gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pjsr5ACupmST"
   },
   "source": [
    "これまでに利用したものとは異なるモデルを利用したいとか，自身が持っているデータセットにより適合させたいとかの応用的な利用方法を紹介します．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSKzyoA1O02W"
   },
   "source": [
    "### 他のモデルの利用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G316vauoido7"
   },
   "source": [
    "これまでに，Hugging Face が自動でダウンロードしてくれたデフォルトの事前学習済みモデルを利用した予測を行いましたが，そうでなくて，モデルを指定することもできます．以下のページをご覧ください．Model Hub と言います．\n",
    "\n",
    "https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads\n",
    "\n",
    "\n",
    "この Model Hub の Tasks というところでタグを選択できます．例えば，Text Generation の `distilgpt2` を利用するには以下のように書きます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aEduyYGdPhf0"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "from transformers import pipeline\n",
    " \n",
    "def main():\n",
    "    generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "    text = \"In this course, we will teach you how to\"\n",
    "    result = generator(text)\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD4N6qje9TwB"
   },
   "source": [
    "## Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rfC8Kj03omW"
   },
   "source": [
    "```{note}\n",
    "終わりです．\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tensorflow_8.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}