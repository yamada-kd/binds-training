
<!DOCTYPE html>

<html lang="ja">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6. TensorFlow を利用した深層学習 &#8212; BINDSデータ科学演習</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="検索" href="search.html" />
    <link rel="next" title="7. TensorFlowファイルの分割" href="tensorflow-2.html" />
    <link rel="prev" title="5. Scikit-learnファイルの分割" href="scikit-learn-2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="ja">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/neko.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">BINDSデータ科学演習</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="この本を検索..." aria-label="この本を検索..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   はじめに
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  プログラミングの基礎
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="notebook/python-1.html">
   1. Python の基本的な使用方法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebook/python-2.html">
   2. 数値計算と描画ライブラリ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebook/python-3.html">
   3. クラスの利用とファイル入出力
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  一般的な機械学習法
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="scikit-learn-1.html">
   4. Scikit-learn 入門
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scikit-learn-2.html">
   5. Scikit-learnファイルの分割
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  深層学習法
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   6. TensorFlow を利用した深層学習
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tensorflow-2.html">
   7. TensorFlowファイルの分割
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tensorflow-3.html">
   8. Hugging Face
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="ナビゲーションを切り替え" aria-controls="site-navigation"
                title="ナビゲーションを切り替え" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="このページをダウンロード"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/tensorflow-1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="ソースファイルをダウンロード" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="PDFに印刷"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="全画面モード"
        title="全画面モード"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/yamada-kd/binds-training/master?urlpath=lab/tree/docs/tensorflow-1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="発売 Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/yamada-kd/binds-training/blob/master/docs/tensorflow-1.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="発売 Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>TensorFlow を利用した深層学習</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="tensorflow">
<h1><span class="section-number">6. </span>TensorFlow を利用した深層学習<a class="headerlink" href="#tensorflow" title="このヘッドラインへのパーマリンク">¶</a></h1>
<p>教材作成者：東北大学大学院 情報科学研究科</p>
<p>#1. <font color="Crimson">はじめに</font></p>
<p>##1-1. <font color="Crimson">このコンテンツで学ぶこと</font></p>
<p>TenforFlow とは 深層学習を Python で利用するためのフレームワークです．現在世界で最も多くの人に利用されています．TensorFlow はひとつのフレームワークなのですが，コーディングをする際にいくつかの書き方があります．Keras の書き方，Sequential な書き方，Functional な書き方，Subclassing な書き方です．Keras の書き方はとても簡単にニューラルネットワークを実現します．しかし，拡張性が高くありません．Subclassing API は最も柔軟な書き方が可能です．習得は大して難しくありません（Keras から入った人がそういう主張をしているように思えます）．習得の難易度と，ニューラルネットワークに対する理解を得られる度合いや柔軟にネットワークを構築できる利点を天秤にかけたときに，Subclassing API を最初に学習した方が得られるものが多いと思い，これを紹介します．Subclassing API は PyTorch（元々は Chainer の書き方 = define by run）とほぼ同じ書き方です．このコンテンツは以下の3個の章からなります．</p>
<ul class="simple">
<li><p>TensorFlow入門</p></li>
<li><p>深層学習入門</p></li>
<li><p>配列情報の処理</p></li>
</ul>
<p>最初の章で TensorFlow の基本的な操作方法を NumPy と比較しながら紹介し，次の章では深層学習の最も基本的なアルゴリズムである多層パーセプトロン（MLP）を実装します．最後の章では配列データ（文字列）を処理します．文章を人工知能に入力して，その文章の感情を positive か negative のふたつに分類する課題に取り組みます．</p>
<p>##1-2. <font color="Crimson">コンパニオン</font></p>
<p>このコンテンツには，受講者の理解を助けるためのコンパニオンがいます．以下のものは「サミー先生」です．サミー先生は今回のこの教材の制作者ではないのですが分かり難いところを詳しく教えてくれます．</p>
<p><font color="Crimson">(9｀･ω･)9 ｡oO(ちゃお！)</font></p>
<p>#2. <font color="Crimson">TensorFlow 入門</font></p>
<p>この章では TensorFlow の基本的な操作と，その操作を習得するために操作方法を知っておくと便利な NumPy という数値計算ライブラリの使い方を紹介します．</p>
<p>##2-1. <font color="Crimson">基本操作</font></p>
<p>###2-1-1. <font color="Crimson">インポート</font></p>
<p>NumPy と同じように TensorFlow をインポートします．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">pass</span>
    <span class="c1"># TensorFlow のバージョンを出力．</span>
 
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>###2-1-2. <font color="Crimson">テンソル</font></p>
<p>TensorFlow では「テンソル」と呼ばれる NumPy の多次元配列に類似したデータ構造を用います．2行目で TensorFlow をインポートします．5行目のテンソルを生成するためのコマンドは <code class="docutils literal notranslate"><span class="pre">tf.zeros()</span></code> で，これによって，全要素が <code class="docutils literal notranslate"><span class="pre">0</span></code> であるテンソルが生成されます．最初の引数には生成されるテンソルの次元数を指定します．また，データのタイプを指定することができますが以下の場合は32ビットのフロートの値を生成しています．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="c1"># 1階テンソルを生成．</span>
    <span class="c1"># 3階テンソルを生成．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>以下のようにすると，整数を生成できます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="c1"># ここが整数を生成するための記述</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="c1"># 1階テンソルを生成．</span>
    <span class="c1"># 3階テンソルを生成．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>データのタイプを確認したい場合とテンソルのシェイプを確認したい場合は以下のようにします．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># 浮動小数点数の2行2列の行列を生成して型と形を確認．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>一様分布に従う乱数を生成したい場合には以下のようにします．一様分布の母数（パラメータ）は最小値と最大値です．ここでは，最小値が-1で最大値が1の一様分布 <span class="math notranslate nohighlight">\(U(-1,1)\)</span> に従う乱数を生成します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">minval</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="c1"># 何度か実行して値が異なることを確認．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>上のコードセルを何度か繰り返し実行すると一様分布に従う4行3列のテンソルの値が生成されますが，1回ごとに異なる値が出力されているはずです．これは計算機実験をする際にとても厄介です．再現性が取れないからです．これを防ぐために「乱数の種」というものを設定します．以下のコードの3行目のような指定を追加します．ここでは，0という値を乱数の種に設定していますが，これはなんでも好きな値を設定して良いです．<font color="Crimson">普通，科学的な計算機実験をする際に乱数の種を固定せずに計算を開始することはあり得ません．乱数を使う場合は常に乱数の種を固定しておくことを習慣づける必要があります．</font></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">minval</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="c1"># 何度か繰り返して実行．</span>
    <span class="c1"># 全く同じコマンドで別の変数を生成して出力．</span>
    <span class="c1"># 何度か繰り返して実行．</span>
    <span class="c1"># 乱数のタネを別の値に変更した後に何度か繰り返して実行．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Python 配列より変換することもできます．この <code class="docutils literal notranslate"><span class="pre">tf.constant()</span></code> は実際には使う機会は多くありません．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="c1"># 多次元 Python 配列をテンソルに変換．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>なぜなら，TensorFlow のテンソル（tf.Tensor）と NumPy の多次元配列（ndarray）の変換は以下のふたつのルールによる簡単な変換を TensorFlow が自動で行ってくれるからです．</p>
<ol class="simple">
<li><p>TensorFlowの演算により NumPy の ndarray は自動的に tf.Tensor に変換される．</p></li>
<li><p>NumPy の演算により tf.Tensor は自動的に ndarray に変換される．</p></li>
</ol>
<p>これに関しては以下の四則計算のところでその挙動を確認します．</p>
<p>###2-1-3. <font color="Crimson">四則計算</font></p>
<p>テンソルの四則計算は以下のように行います．最初に足し算を行います．NumPy と同じようにやはり element-wise な計算です．実行結果は <code class="docutils literal notranslate"><span class="pre">tf.Tensor([3</span> <span class="pre">7],</span> <span class="pre">shape=(2,),</span> <span class="pre">dtype=int32)</span></code> となっており，配列の計算の結果が tf.Tensor に変換されていることが確認できます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="c1"># 別の計算を実行．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>以下では，ふたつの NumPy 多次元配列を生成しそれらを足し合わせます．得られる結果は NumPy の多次元配列でなくて tf.Tensor であることが確認できます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">na</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
    <span class="n">nb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">na</span><span class="p">,</span> <span class="n">nb</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="c1"># 別の計算を実行．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>その他の四則演算は以下のように行います．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">na</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">nb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">na</span><span class="p">,</span> <span class="n">nb</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">nb</span><span class="p">,</span> <span class="n">na</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">na</span><span class="p">,</span> <span class="n">nb</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">nb</span><span class="p">,</span> <span class="n">na</span><span class="p">))</span>
    <span class="c1"># 別の計算を実行．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><font color="Crimson">(9｀･ω･)9 ｡oO(上から足し算，引き算，掛け算，割り算です．)</font></p>
<p>上の <code class="docutils literal notranslate"><span class="pre">tf.multiply()</span></code> はテンソルの要素ごとの積（アダマール積）を計算するための方法です．行列の積は以下のように <code class="docutils literal notranslate"><span class="pre">tf.matmul()</span></code> を利用します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">na</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">nb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">na</span><span class="p">,</span> <span class="n">nb</span><span class="p">))</span>
    <span class="c1"># tf.multiply() との違いを確認．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>テンソルもブロードキャストしてくれます．以下のようなテンソルとスカラの計算も良い感じで解釈して実行してくれます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">na</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">na</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># 引き算を実行．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>以下のように <code class="docutils literal notranslate"><span class="pre">+</span></code> や <code class="docutils literal notranslate"><span class="pre">-</span></code> を使って記述することも可能です．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">ta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ta</span> <span class="o">+</span> <span class="n">tb</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tb</span> <span class="o">-</span> <span class="n">ta</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ta</span> <span class="o">*</span> <span class="n">tb</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tb</span> <span class="o">/</span> <span class="n">ta</span><span class="p">)</span>
    <span class="c1"># &quot;//&quot; と &quot;%&quot; の挙動を確認．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>二乗の計算やテンソルの要素の総和を求めるための便利な方法も用意されています．このような方法は状況に応じてその都度調べて使います．全部覚える必要はありません．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">nx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">nx</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">nx</span><span class="p">))</span>
    <span class="c1"># 多次元配列での挙動を確認．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>###2-1-4. <font color="Crimson">特殊な操作</font></p>
<p>以下のようなスライスの実装も NumPy と同じです．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1"># 2行目の値を出力．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><font color="Crimson">(9｀･ω･)9 ｡oO(これは2行2列の行列の1列目の値を取り出す操作です．)</font></p>
<p>テンソルのサイズの変更には <code class="docutils literal notranslate"><span class="pre">tf.reshape()</span></code> を利用します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="p">[</span><span class="mi">20</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
    <span class="c1"># tf.reshape(tx, [20, 1]) の形を確認．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>以上のプログラムの6行目では4行5列の行列が生成されています．これを，20要素からなるベクトルに変換するのが7行目の記述です．また，8行目の記述では1行20列の行列を生成できます．また，9行目は5行4列の行列を生成するためのものです．同じく10行目も5行4列の行列を生成します．ここでは，<code class="docutils literal notranslate"><span class="pre">tf.reshape()</span></code> の shape を指定するオプションの最初の引数に <code class="docutils literal notranslate"><span class="pre">-1</span></code> が指定されていますが，これのように書くと自動でその値が推測されます．この場合，<code class="docutils literal notranslate"><span class="pre">5</span></code> であると推測されています．</p>
<p>###2-1-5. <font color="Crimson">変数の変換</font></p>
<p>これまでに，NumPyの 多次元配列を TensorFlow のテンソルに変換する方法は確認しました．テンソルを NumPy 配列に変換するには明示的に <code class="docutils literal notranslate"><span class="pre">numpy()</span></code> を指定する方法があります．6行目は NumPy 配列を生成します．8行目はその NumPy 配列をテンソルに変換します．さらに，NumPy 配列に戻すためには10行目のように <code class="docutils literal notranslate"><span class="pre">.numpy()</span></code> を利用します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">na</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NumPy:&quot;</span><span class="p">,</span> <span class="n">na</span><span class="p">)</span>
    <span class="n">ta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">na</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor:&quot;</span><span class="p">,</span> <span class="n">ta</span><span class="p">)</span>
    <span class="n">na</span> <span class="o">=</span> <span class="n">ta</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NumPy:&quot;</span><span class="p">,</span> <span class="n">na</span><span class="p">)</span>
    <span class="c1"># さらに32ビット整数型のテンソルに変換．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>また，テンソルに対して NumPy の演算操作を行うと自動的にテンソルは NumPy 配列に変換されます．以下の8行目と9行目はどちらもベクトルの内積を計算していますが，8行目で得られる結果はテンソル，9行目で得られる結果は NumPy の値です．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">ta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">ta</span><span class="p">,</span> <span class="n">tb</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ta</span><span class="p">,</span> <span class="n">tb</span><span class="p">))</span>
    <span class="c1"># NumPy 配列とテンソルの内積をテンソルの演算方法で計算．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>###2-1-6. <font color="Crimson">勾配の計算</font></p>
<p>深層学習法におけるアルゴリズムの中身を分解すると行列の掛け算と微分から構成されていることがわかります．TensorFlow はこの行列の掛け算と微分を行うライブラリです．自動微分機能を提供します．ここでは勾配の計算を紹介するため，以下の式を考えます．</p>
<p><span class="math notranslate nohighlight">\(y = x^2 + 2\)</span></p>
<p>これに対して以下の偏微分を計算することができます．</p>
<p><span class="math notranslate nohighlight">\(\dfrac{\partial y}{\partial x} = 2x\)</span></p>
<p>よって <span class="math notranslate nohighlight">\(x=5\)</span> のときの偏微分係数は以下のように計算できます．</p>
<p><span class="math notranslate nohighlight">\(\left.\dfrac{\partial y}{\partial x}\right|_{x=5}=10\)</span></p>
<p>これを TensorFlow で実装すると以下のように書けます．微分は10行目のように <code class="docutils literal notranslate"><span class="pre">tape.gradient()</span></code> によって行います．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">ty</span> <span class="o">=</span> <span class="n">tx</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span> <span class="c1"># ここに勾配を求める対象の計算式を書く．</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">ty</span><span class="p">,</span> <span class="n">tx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
    <span class="c1"># y=3x^2+x+1をxで偏微分したときの，x=1の値を計算．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>上の程度の微分だとこの自動微分機能はさほど有難くないかもしれませんが，以下のような計算となると，そこそこ有難くなってきます．以下では，(1, 2) の行列 <code class="docutils literal notranslate"><span class="pre">ts</span></code> と (2, 2) の行列 <code class="docutils literal notranslate"><span class="pre">tt</span></code> と (2, 1) の行列 <code class="docutils literal notranslate"><span class="pre">tu</span></code> を順に掛けることで，最終的に (1, 1) の行列の値，スカラー値を得ますが，それを <code class="docutils literal notranslate"><span class="pre">tt</span></code> で微分した値を計算しています（<code class="docutils literal notranslate"><span class="pre">tt</span></code> で偏微分したので得られる行列のシェイプは <code class="docutils literal notranslate"><span class="pre">tt</span></code> と同じ）．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Definition</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># これが変数．</span>
    <span class="n">tu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># Calculation</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">tz</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">tt</span><span class="p">),</span> <span class="n">tu</span><span class="p">)</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">tz</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
    <span class="c1"># 2行2列の定数行列taを生成，ts*ta*tt*tuの行列の積を計算し，ttで偏微分．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>これは以下のような計算をしています．<code class="docutils literal notranslate"><span class="pre">tf.Variable()</span></code> で定義される行列は以下です：</p>
<p><span class="math notranslate nohighlight">\(
  t = \left[
    \begin{array}{cc}
      v &amp; w \\
      x &amp; y \\
    \end{array}
  \right]
\)</span>．</p>
<p>また，<code class="docutils literal notranslate"><span class="pre">tf.constant()</span></code> で定義される行列は以下です：</p>
<p><span class="math notranslate nohighlight">\(s = \left[
    \begin{array}{cc}
      2 &amp; 1 \\
    \end{array}
  \right]
\)</span>，</p>
<p><span class="math notranslate nohighlight">\(u = \left[
    \begin{array}{c}
      4 \\
      1
    \end{array}
  \right]
\)</span>．</p>
<p>これに対して11行目の計算で得られる値は以下です：</p>
<p><span class="math notranslate nohighlight">\(z(v,w,x,y) = 8v+2w+4x+y\)</span>．</p>
<p>よってこれらを偏微分して，それぞれの変数がプログラム中で定義される値のときの値は以下のように計算されます：</p>
<p><span class="math notranslate nohighlight">\(\left.\dfrac{\partial z}{\partial v}\right|_{(v,w,x,y)=(2,4,6,8)}=8\)</span>，</p>
<p><span class="math notranslate nohighlight">\(\left.\dfrac{\partial z}{\partial w}\right|_{(v,w,x,y)=(2,4,6,8)}=2\)</span>，</p>
<p><span class="math notranslate nohighlight">\(\left.\dfrac{\partial z}{\partial x}\right|_{(v,w,x,y)=(2,4,6,8)}=4\)</span>，</p>
<p><span class="math notranslate nohighlight">\(\left.\dfrac{\partial z}{\partial y}\right|_{(v,w,x,y)=(2,4,6,8)}=1\)</span>．</p>
<p><font color="Crimson">(9｀･ω･)9 ｡oO(これにコスト関数と活性化関数付けて最急降下法やったらニューラルネットワークです．自動微分すごい．)</font></p>
<p>なぜ微分を求めたいかというと，勾配法（深層学習の場合，普通，最急降下法）でパラメータをアップデートしたいからです．以下では最急降下法を実装してみます．最急降下法は関数の最適化法です．ある関数に対して極小値（極大値）を計算するためのものです．以下のような手順で計算が進みます．</p>
<ol class="simple">
<li><p>初期パラメータ（<span class="math notranslate nohighlight">\(\theta_0\)</span>）をランダムに生成します．</p></li>
<li><p>もしパラメータ（<span class="math notranslate nohighlight">\(\theta_t\)</span>）が最適値または，最適値に近いなら計算をやめます．ここで，<span class="math notranslate nohighlight">\(t\)</span> は以下の繰り返しにおける <span class="math notranslate nohighlight">\(t\)</span> 番目のパラメータです．</p></li>
<li><p>パラメータを以下の式によって更新し，かつ，<span class="math notranslate nohighlight">\(t\)</span> の値を <span class="math notranslate nohighlight">\(1\)</span> だけ増やします．ここで，<span class="math notranslate nohighlight">\(\alpha\)</span> は学習率と呼ばれる更新の大きさを決める値で，<span class="math notranslate nohighlight">\(g_t\)</span> は <span class="math notranslate nohighlight">\(t\)</span> のときの目的の関数の勾配です．<br>
<span class="math notranslate nohighlight">\(\theta_{t+1}=\theta_t-\alpha g_t\)</span></p></li>
<li><p>ステップ2と3を繰り返します．</p></li>
</ol>
<p>ここでは以下の関数を考えます．</p>
<p><span class="math notranslate nohighlight">\(y=(x+1)^2+2\)</span></p>
<p>初期パラメータを以下のように決めます（実際にはランダムに決める）．</p>
<p><span class="math notranslate nohighlight">\(x_0=1.6\)</span></p>
<p>この関数の極小値を見つけたいのです．これは解析的に解くのはとても簡単で，括弧の中が0になる値，すなわち <span class="math notranslate nohighlight">\(x\)</span> が <span class="math notranslate nohighlight">\(-1\)</span> のとき，極小値 <span class="math notranslate nohighlight">\(y=2\)</span> です．</p>
<p>最急降下法で解くと，以下の図のようになります．最急降下法は解析的に解くことが難しい問題を正解の方向へ少しずつ反復的に動かしていく方法です．</p>
<img src="https://drive.google.com/uc?id=1bRRIwEJy-ltIHnzfqOpOVVlZYXrT3PXR" width="70%"><p>これを TensorFlow を用いて実装すると以下のようになります．出力中，<code class="docutils literal notranslate"><span class="pre">Objective</span></code> は目的関数の値，<code class="docutils literal notranslate"><span class="pre">Solution</span></code> はその時点での解です．最終的に <span class="math notranslate nohighlight">\(x=-0.9968\simeq-1\)</span> のとき，最適値 <span class="math notranslate nohighlight">\(y=2\)</span> が出力されています．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
 
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># これが変数．</span>
    <span class="n">epoch</span><span class="p">,</span> <span class="n">update_value</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.1</span> <span class="c1"># 更新値はダミー変数．</span>
    <span class="k">while</span> <span class="nb">abs</span><span class="p">(</span><span class="n">update_value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.001</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">ty</span> <span class="o">=</span> <span class="p">(</span><span class="n">tx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">ty</span><span class="p">,</span> <span class="n">tx</span><span class="p">)</span>
        <span class="n">update_value</span> <span class="o">=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">tx</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">tx</span> <span class="o">-</span> <span class="n">update_value</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">:</span><span class="se">\t</span><span class="s2">Objective = </span><span class="si">{:5.3f}</span><span class="se">\t</span><span class="s2">Solution = </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">ty</span><span class="p">,</span> <span class="n">tx</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
        <span class="n">epoch</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># 下の新たなコードセルで計算．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>5行目で最初のパラメータを発生させています．通常は乱数によってこの値を決めますが，ここでは上の図に合わせて1.6とします．次の6行目では，最初のエポック，更新値，学習率を定義します．エポックとは（ここでは）パラメータの更新回数のことを言います．7行目は終了条件です．以上のような凸関数においては勾配の値が0になる点が本当の最適値（正しくは停留点）ではありますが，計算機的にはパラメータを更新する値が大体0になったところで計算を打ち切ります．この場合，「大体0」を「0.001」としました．9行目は目的の関数，10行目で微分をしています．11行目は最急降下法で更新する値を計算しています．12行目の計算で <code class="docutils literal notranslate"><span class="pre">tx</span></code> をアップデートします．この12行目こそが上述の最急降下法の式です．</p>
<p><font color="Crimson">(9｀･ω･)9 ｡oO(ここで最急降下法について説明しましたが，このような実装は TensorFlow を利用する際にする必要はありません．TensorFlow はこのような計算をしてくれる方法を提供してくれています．よって，ここの部分の意味が解らなかったとしても以降の部分は理解できます．)</font></p>
<p>#3. <font color="Crimson">深層学習入門</font></p>
<p>##3-1. <font color="Crimson">扱うデータの紹介</font></p>
<p>###3-1-1. <font color="Crimson">MNIST について</font></p>
<p>このセクションでは深層学習法で用いられるアルゴリズムの中でも最も基本的なものである MLP の実装方法を学びますが，この MLP に処理させるデータセットとして，機械学習界隈で最も有名なデータセットである MNIST（Mixed National Institute of Standards and Technology database）を解析対象に用います．筆者の経験によると，日本人も外国人も今のところ会った人全員がこれのことは「エムニスト」と発音しています．MNIST は縦横28ピクセル，合計784ピクセルよりなる画像データです．画像には手書きの一桁の数字（0から9）が含まれています．公式ウェブサイトでは，学習データセット6万個とテストデータセット1万個，全部で7万個の画像からなるデータセットが無償で提供されています．</p>
<p>###3-1-2. <font color="Crimson">ダウンロードと可視化</font></p>
<p>公式サイトよりダウンロードしてきても良いのですが，TensorFlow がダウンロードするためのユーティリティを準備してくれているため，それを用います．以下の <code class="docutils literal notranslate"><span class="pre">tf.keras.datasets.mnist.load_data()</span></code> を用いることで可能です．MNIST は合計7万インスタンスからなるデータセットです．5行目でふたつのタプルにデータをダウンロードしていますが，最初のタプルは学習データセット，次のタプルはテストデータセットのためのものです．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">),</span> <span class="p">(</span><span class="n">litestx</span><span class="p">,</span> <span class="n">litestt</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of instances in the learning dataset:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lilearnx</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of instances in the test dataset:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">litestx</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">litestt</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The input vector of the first instance in the learning dataset:&quot;</span><span class="p">,</span> <span class="n">lilearnx</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Its shape:&quot;</span><span class="p">,</span> <span class="n">lilearnx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The target vector of the first instance in the learning datast:&quot;</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1"># 2番目のインスタンスのインプットデータとターゲットデータを確認．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
	<span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>データを可視化します．可視化のために matplotlib というライブラリをインポートします．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">),</span> <span class="p">(</span><span class="n">litestx</span><span class="p">,</span> <span class="n">litestt</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">lilearnx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
    <span class="c1"># 別のインプットデータを表示．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
	<span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>このデータセットがダウンロードされている場所は <code class="docutils literal notranslate"><span class="pre">~/.keras/datasets</span></code> です．以下のような BaSH のコマンドを打つことで確認することができます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> ls /root/.keras/datasets
</pre></div>
</div>
</div>
</div>
<p>MNIST はこのような縦が28ピクセル，横が28ピクセルからなる手書き文字が書かれた（描かれた）画像です（0から9までの値）．それに対して，その手書き文字が0から9のどれなのかという正解データが紐づいています．この画像データを MLP に読み込ませ，それがどの数字なのかを当てるという課題に取り組みます．</p>
<p>##3-2. <font color="Crimson">MLP の実装</font></p>
<p>###3-2-1. <font color="Crimson">簡単な MLP の実装</font></p>
<p>実際に MNIST を処理する MLP を実装する前に，とても簡単なデータを処理するための MLP を実装します．ここでは，以下のようなデータを利用します．これが学習セットです．ここでは MLP の実装の方法を紹介するだけなのでバリデーションセットもテストセットも使用しません．</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>入力ベクトル</p></th>
<th class="text-align:center head"><p>ターゲットベクトル</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>[ 1.1, 2.2, 3.0, 4.0 ]</p></td>
<td class="text-align:center"><p>[ 0 ]</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>[ 2.0, 3.0, 4.0, 1.0 ]</p></td>
<td class="text-align:center"><p>[ 1 ]</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>[ 2.0, 2.0, 3.0, 4.0 ]</p></td>
<td class="text-align:center"><p>[ 2 ]</p></td>
</tr>
</tbody>
</table>
<p>すなわち，<code class="docutils literal notranslate"><span class="pre">[1.1,</span> <span class="pre">2.2,</span> <span class="pre">3.0,</span> <span class="pre">4.0]</span></code> が人工知能へ入力されたら，<code class="docutils literal notranslate"><span class="pre">0</span></code> というクラスを返し，<code class="docutils literal notranslate"><span class="pre">[2.0,</span> <span class="pre">3.0,</span> <span class="pre">4.0,</span> <span class="pre">1.0]</span></code> というベクトルが入力されたら <code class="docutils literal notranslate"><span class="pre">1</span></code> というクラスを返し，<code class="docutils literal notranslate"><span class="pre">[2.0,</span> <span class="pre">2.0,</span> <span class="pre">3.0,</span> <span class="pre">4.0]</span></code> というベクトルが入力されたら <code class="docutils literal notranslate"><span class="pre">2</span></code> というクラスを返す人工知能を MLP で構築します．実際には以下のように書きます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># データセットの生成</span>
    <span class="n">tx</span><span class="o">=</span><span class="p">[[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]]</span>
    <span class="n">tx</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tt</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">tt</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">()</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span> <span class="c1">#正解と出力の順番はこの通りにする必要がある．</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3000</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span> <span class="c1"># 学習の回数の上限値</span>
        <span class="n">traincost</span><span class="p">,</span><span class="n">trainacc</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="k">100</span>==0:
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:5d}</span><span class="s2">: Training cost= </span><span class="si">{:.4f}</span><span class="s2">, Training ACC= </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">trainacc</span><span class="p">))</span>
    
    <span class="c1"># 学習が本当にうまくいったのか入力ベクトルのひとつを処理させてみる</span>
    <span class="n">tx1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">ty1</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ty1</span><span class="p">)</span>

    <span class="c1"># 未知のデータを読ませてみる</span>
    <span class="n">tu</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">999</span><span class="p">,</span><span class="mi">888</span><span class="p">,</span><span class="mi">777</span><span class="p">,</span><span class="mi">666</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tu</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>

    <span class="c1"># Denseの最初の引数の値やエポックの値や変化させて，何が起こっているか把握する．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span> <span class="c1"># これは全結合層を生成するための記述．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>上から説明を行います．以下のような記述があります．ここで，上述のデータを生成しています．<code class="docutils literal notranslate"><span class="pre">tx</span></code> は入力ベクトル3つです．<code class="docutils literal notranslate"><span class="pre">tt</span></code> はそれに対応するターゲットベクトル（スカラ）3つです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">tx</span><span class="o">=</span><span class="p">[[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]]</span>
    <span class="n">tx</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tt</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">tt</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
</pre></div>
</div>
<p>次に，以下のような記述があります．この記述によって未学習の人工知能を生成します．生成した人工知能は <code class="docutils literal notranslate"><span class="pre">model</span></code> です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">()</span>
</pre></div>
</div>
<p>この未学習の人工知能を生成するための記述の本体はプログラムの最下層辺りにある以下の記述です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
<p>ここに <code class="docutils literal notranslate"><span class="pre">Dense(10,</span> <span class="pre">activation=&quot;relu&quot;)</span></code> とありますが，これは10個のニューロンを持つ層を1個生成するための記述です．活性化関数に ReLU を使うようにしています．これによって生成される層の名前は <code class="docutils literal notranslate"><span class="pre">self.d1()</span></code> です．ここでは10個という値を設定していますが，これは100でも1万でも1兆でもなんでも良いです．解きたい課題にあわせて増やしたり減らしたりします．ここをうまく選ぶことでより良い人工知能を構築でき，腕の見せ所です．次に，<code class="docutils literal notranslate"><span class="pre">Dense(3,</span> <span class="pre">activation=&quot;softmax&quot;)</span></code> という記述で3個のニューロンを持つ層を1個生成します．この3個という値は意味を持っています．入力するデータのクラスが0，1または2の3分類（クラス）であるからです．また，活性化関数にはソフトマックス関数を指定しています．ソフトマックス関数の出力ベクトルの要素を合計すると1になります．各要素の最小値は0です．よって出力結果を確率として解釈できます．次の，<code class="docutils literal notranslate"><span class="pre">def</span> <span class="pre">call(self,x):</span></code> という記述はこれ（<code class="docutils literal notranslate"><span class="pre">class</span> <span class="pre">Network()</span></code>）によって生成した人工知能を呼び出したときにどのような計算をさせるかを定義するものです．入力として <code class="docutils literal notranslate"><span class="pre">x</span></code> というベクトルが与えられたら，それに対して最初の層を適用し，次に，その出力に対して次の層を適用し，その値を出力する，と定義しています．構築した人工知能 <code class="docutils literal notranslate"><span class="pre">model</span></code> に対して <code class="docutils literal notranslate"><span class="pre">model.call()</span></code> のような方法で呼び出すことができます．</p>
<p>次の以下の記述は，それぞれ，損失関数，正確度（ACC）を計算する関数，最急降下法の最適化法（パラメータの更新ルール）を定義するものです．これは，TensorFlow ではこのように書くのだと覚えるものです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
</pre></div>
</div>
<p>次の以下の記述は損失を計算するためのものです．この <code class="docutils literal notranslate"><span class="pre">tf.GradientTapa()</span></code> は上でも出ました．最初に，<code class="docutils literal notranslate"><span class="pre">model.call()</span></code> に入力ベクトルのデータを処理させて出力ベクトル <code class="docutils literal notranslate"><span class="pre">ty</span></code> を得ます．この出力ベクトルとターゲットベクトルを損失関数の入力として損失 <code class="docutils literal notranslate"><span class="pre">traincost</span></code> を得ます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span> <span class="c1">#正解と出力の順番はこの通りにする必要がある．</span>
</pre></div>
</div>
<p>この損失は人工知能が持つパラメータによって微分可能なので，以下の記述によって勾配を求めます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
</pre></div>
</div>
<p>以下の記述はパラメータ更新のための最急降下法の定義と損失とは別の性能評価指標である正確度（accuracy（ACC））を計算するための定義です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
</pre></div>
</div>
<p>最後の以下の記述はこの関数の戻り値を定義するものです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
</pre></div>
</div>
<p>次に記述されている以下の部分は，実際の学習のループに関するものです．このループでデータを何度も何度も予測器（人工知能）に読ませ，そのパラメータを成長させます．この場合，3000回データを学習させます．また，学習100回毎に学習の状況を出力させます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3000</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">traincost</span><span class="p">,</span><span class="n">trainacc</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="mi">100</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:5d}</span><span class="s2">: Training cost= </span><span class="si">{:.4f}</span><span class="s2">, Training ACC= </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">trainacc</span><span class="p">))</span>
</pre></div>
</div>
<p>次の記述，以下の部分では学習がうまくいったのかを確認するために学習データのひとつを学習済みの人工知能に読ませて予測をさせています．この場合，最初のデータのターゲットベクトルは0なので0が出力されなければなりません．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習が本当にうまくいったのか入力ベクトルのひとつを処理させてみる</span>
    <span class="n">tx1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">ty1</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ty1</span><span class="p">)</span>
</pre></div>
</div>
<p>出力結果は以下のようになっているはずです．出力はソフトマックス関数なので各クラスの確率が表示されています．これを確認すると，最初のクラス（0）である確率が99%以上であると出力されています．よって，やはり人工知能は意図した通り成長したことが確認できます．</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">9.932116e-01</span> <span class="mf">7.842198e-06</span> <span class="mf">6.780579e-03</span><span class="p">]],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>次に，全く新たなデータを入力しています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 未知のデータを読ませてみる</span>
    <span class="n">tu</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">999</span><span class="p">,</span><span class="mi">888</span><span class="p">,</span><span class="mi">777</span><span class="p">,</span><span class="mi">666</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tu</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">[999,888,777,666]</span></code> というベクトルを入力したときにどのような出力がされるかということですが，この場合，以下のような出力がされています．このベクトルを入力したときの予測値は2であるとこの人工知能は予測したということです．</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">0.</span> <span class="mf">0.</span> <span class="mf">1.</span><span class="p">]],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>以下では <code class="docutils literal notranslate"><span class="pre">Dense()</span></code> の挙動を確認してみます．<code class="docutils literal notranslate"><span class="pre">Dense()</span></code> はもちろんクラスの中でなければ使えない関数ではなく，<code class="docutils literal notranslate"><span class="pre">main()</span></code> の中でも呼び出して利用可能です．これで挙動を確認することでどのようにネットワークが構築されているか把握できるかもしれません．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># データセットの生成</span>
    <span class="n">tx</span><span class="o">=</span><span class="p">[[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]]</span>
    <span class="n">tx</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="c1"># 関数を定義</span>
    <span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>

    <span class="c1"># データセットの最初の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;1-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># データセットの全部の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;2-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">))</span>

    <span class="c1"># 活性化関数を変更した関数を定義</span>
    <span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>

    <span class="c1"># データセットの最初の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;3-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># データセットの全部の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;4-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">))</span>

    <span class="c1"># 最初の引数の値を変更した関数を定義</span>
    <span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>

    <span class="c1"># データセットの最初の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;5-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># データセットの全部の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;6-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">))</span>

    <span class="c1"># 別の関数を定義</span>
    <span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>
    <span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>

    <span class="c1"># データセットの最初の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;7-----------&quot;</span><span class="p">)</span>
    <span class="n">y</span><span class="o">=</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

    <span class="c1"># データセットの全部の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;8-----------&quot;</span><span class="p">)</span>
    <span class="n">y</span><span class="o">=</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>###3-2-2. <font color="Crimson">MNIST の基本処理</font></p>
<p>次に，MNIST を処理して「0から9の数字が書かれた（描かれた）手書き文字を入力にして，その手書き文字が0から9のどれなのかを判別する人工知能」を構築します．以下のように書きます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>
    <span class="n">MINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># ミニバッチのサイズとトレーニングデータのサイズから何個のミニバッチができるか計算</span>

    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span> <span class="c1"># MNISTにおいて出力ベクトルのサイズは0から9の10</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
    
    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用するため学習では利用しないが次のコードのために一応定義しておく．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span> <span class="c1"># 「mode」という変数を新たに設定．これでパラメータ更新をするかしないかを制御する（バリデーションではパラメータ更新はしない）．</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>

    <span class="c1"># ユニットサイズやミニバッチサイズを変更したり層を追加したりして挙動を把握する．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>プログラムの中身について上から順に説明します．以下の部分はハイパーパラメータを設定する記述です．<code class="docutils literal notranslate"><span class="pre">MAXEPOCH</span></code> は計算させる最大エポックです．このエポックに至るまで繰り返しの学習をさせるということです．<code class="docutils literal notranslate"><span class="pre">MINIBATCHSIZE</span></code> とはミニバッチ処理でサンプリングするデータのサイズです．これが大きいとき実計算時間は短縮されます．この値が <code class="docutils literal notranslate"><span class="pre">1</span></code> のとき，学習法はオンライン学習法であり，この値がトレーニングセットのサイズと等しいとき，学習法は一括更新法です．ミニバッチの大きさは持っているマシンのスペックと相談しつつ，色々な値を試してみて一番良い値をトライアンドエラーで探します．<code class="docutils literal notranslate"><span class="pre">UNITSIZE</span></code> は MLP の層のサイズ，つまり，ニューロンの数です．<code class="docutils literal notranslate"><span class="pre">TRAINSIZE</span></code> はトレーニングセットのインスタンスの大きさです．MNIST の学習セットは60000インスタンスからなるのでその90%をトレーニングセットとして利用することにしています．<code class="docutils literal notranslate"><span class="pre">MINIBATCHNUMBER</span></code> はミニバッチのサイズとデータのサイズから計算されるミニバッチの個数です．オンライン学習法の場合，1エポックでパラメータ更新は，この例の場合，54000回行われます．一括更新法の場合，1エポックでパラメータ更新は1回行われます．このミニバッチのサイズ（500）とデータサイズの場合，1エポックでパラメータ更新は108回行われます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>
    <span class="n">MINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># ミニバッチのサイズとトレーニングデータのサイズから何個のミニバッチができるか計算</span>
</pre></div>
</div>
<p>データの読み込みは上で説明したため省略し，以下の部分では読み込んだデータをトレーニングセットとバリデーションセットに分割しています．この <code class="docutils literal notranslate"><span class="pre">:</span></code> の利用方法は NumPy の使い方解説のところで行った通りです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
</pre></div>
</div>
<p>以下の記述では，MNIST に含まれる値を0以上1以下の値に変換しています（元々の MNIST は0から255の値で構成されています）．用いるオプティマイザの種類やそのパラメータ更新を大きさを決めるハイパーパラメータ（学習率）の設定によってはこのような操作が良い効果をもたらす場合があります．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
</pre></div>
</div>
<p>ネットワークの定義は以下で行います．これは前述の例と同じです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用するため学習では利用しないが次のコードのために一応定義しておく．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
</pre></div>
</div>
<p>ネットワーク自体は以下の部分で定義されているのですが，前述の例と少し異なります．ここでは，28行28列の行列を784要素のベクトルに変換するための層 <code class="docutils literal notranslate"><span class="pre">self.d0</span></code> を定義しています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
<p>学習1回分の記述は前述の例と少し異なります．<code class="docutils literal notranslate"><span class="pre">mode</span></code> という変数を利用して，トレーニングの際にはパラメータ更新を行い，バリデーションの際にはパラメータ更新を行わないように制御します．その他は前述の例と同じです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span> <span class="c1"># 「mode」という変数を新たに設定．これでパラメータ更新をするかしないかを制御する（バリデーションではパラメータ更新はしない）．</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
</pre></div>
</div>
<p>学習ループが開始された最初の <code class="docutils literal notranslate"><span class="pre">index=np.random.permutation(TRAINSIZE)</span></code> ではトレーニングセットのサイズに応じた（この場合，0から53999）整数からなる要素をランダムに並べた配列を生成します．これを利用して，ミニバッチのときにランダムにインスタンスを抽出します．<code class="docutils literal notranslate"><span class="pre">traincost=0</span></code> のところではトレーニングコストを計算するための変数を宣言しています．ミニバッチ処理をするので，トレーニングコストはミニバッチの個数分，この場合108個分計算されるのですが，これを平均するために利用する変数です．この変数にミニバッチ処理1回毎に出力されるコストを足し合わせて，最後にミニバッチ処理の回数で割り平均値を出します．その次の <code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">subepoch</span> <span class="pre">in</span> <span class="pre">range(MINIBATCHNUMBER):</span></code> がミニバッチの処理です．この場合，最初に <code class="docutils literal notranslate"><span class="pre">somb</span></code> に入る値は <code class="docutils literal notranslate"><span class="pre">0</span></code>，<code class="docutils literal notranslate"><span class="pre">eomb</span></code> に入る値は <code class="docutils literal notranslate"><span class="pre">500</span></code> です．1番目から500番目までのデータを抽出する作業のためです．<code class="docutils literal notranslate"><span class="pre">index[somb:eomb]</span></code> には500個のランダムに抽出された整数が入っていますが，それを <code class="docutils literal notranslate"><span class="pre">litrainx[index[somb:eomb]]</span></code> のように使うことで，トレーニングセットからランダムに500個のインスタンスを抽出します．<code class="docutils literal notranslate"><span class="pre">traincost+=subtraincost</span></code> は1回のミニバッチ処理で計算されたコストを上で準備した変数に足し合わせる記述です．ミニバッチ処理が終了した後は，<code class="docutils literal notranslate"><span class="pre">traincost=traincost/MINIBATCHNUMBER</span></code> によって平均トレーニングコストを計算し，また，<code class="docutils literal notranslate"><span class="pre">validcost,_=inference(livalidx,livalidt,False)</span></code> によってバリデーションコストを計算し，それらの値をエポック毎に出力する記述をしています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習ループ</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
</pre></div>
</div>
<p>次に，出力結果について説明します．このプログラムを実行するとエポックとその時のトレーニングコストとバリデーションコストが出力されます．</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span>    <span class="mi">1</span><span class="p">:</span> <span class="n">Training</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.4437</span> <span class="n">Validation</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.1900</span>
<span class="n">Epoch</span>    <span class="mi">2</span><span class="p">:</span> <span class="n">Training</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.1914</span> <span class="n">Validation</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.1325</span>
<span class="n">Epoch</span>    <span class="mi">3</span><span class="p">:</span> <span class="n">Training</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.1372</span> <span class="n">Validation</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.1056</span>
<span class="o">.</span>
<span class="o">.</span>
<span class="o">.</span>
</pre></div>
</div>
<p>これは各エポックのときの人工知能の性能です．エポックが50のとき，トレーニングのコストはとても小さい値です．コストは小さければ小さいほど良いので，学習はしっかりされていることが確認されます．しかし，これはトレーニングデータに対する人工知能の性能です．もしかしたらトレーニングデータに対してのみ性能を発揮できる，トレーニングデータに過剰に適合してしまった人工知能である可能性があります．だから，そうなっていないかどうかを確認する別のデータ，つまり，バリデーションデータセットにおけるコストも確認する必要があります．エポックが50のときのバリデーションのコストはエポック20くらいのときのコストより大きくなっています．すなわち，この人工知能はトレーニングデータに過剰に適合しています．おそらくエポック20くらいの人工知能が最も良い人工知能であって，これを最終的なプロダクトとして選択する必要があります．次の操作ではこれを行います．</p>
<p>###3-2-3. <font color="Crimson">学習曲線の描画</font></p>
<p>学習曲線とは横軸にエポック，縦軸にコストの値をプロットした図です．これを観察することで，どれくらいのエポックで学習が進み始めたか，人工知能の成長が止まったか，どのくらいのエポックで過剰適合が起きたか等を視覚的に理解することができます（慣れたら前述の結果のような数字を読むだけでこの図を想像できるようになるのだと思います）．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>
    <span class="n">MINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># ミニバッチのサイズとトレーニングデータのサイズから何個のミニバッチができるか計算</span>

    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span> <span class="c1"># MNISTにおいて出力ベクトルのサイズは0から9の10</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
    
    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用するため学習では利用しないが次のコードのために一応定義しておく．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>

    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># 次に進む．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>最初に，コードの変更部位について説明します．以下の部分を追加しました．これは描画に必要なライブラリである <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> を利用するための記述です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
<p>次に，学習ループの記述ですが，以下のように最初に <code class="docutils literal notranslate"><span class="pre">liepoch</span></code>，<code class="docutils literal notranslate"><span class="pre">litraincost</span></code>，<code class="docutils literal notranslate"><span class="pre">livalidcost</span></code> という3つの空の配列を用意しました．その後ループの最後で，これらの配列に，それぞれ，エポックの値，トレーニングのコストおよびバリデーションのコストをエポックを進めるたびに追加しています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
</pre></div>
</div>
<p>最後の以下の部分は学習曲線をプロットするためのコードです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>結果を観ると，トレーニングセットにおけるコストの値はエポックを経るにつれて小さくなっていることがわかります．これは，人工知能が与えられたデータに適合していることを示しています．一方で，バリデーションセットにおけるコストの値は大体エポックが10と20の間くらいで下げ止まり，その後はコストが増加に転じています．このコストの増加，人工知能がこのデータセットに適合するのとは逆の方向に成長を始めたことを意味しています．この現象が起こった原因は，この人工知能がその成長に利用するデータセット（トレーニングデータセット）に（のみ）過剰に適合し，汎化性能を失ったことにあります．この曲線を観察する限り，エポックは大体10から20の間くらいに留めておいた方が良さそうです．このような画像を観て，大体20で学習を止める，みたいに決めても悪くはありませんが，もっと体系的な方法があるので次にその方法を紹介します．</p>
<p>###3-2-4. <font color="Crimson">早期終了</font></p>
<p>学習の早期終了（early stopping）とは過学習を防ぐための方法です．ここでは，ペイシェンス（patience）を利用した早期終了を紹介します．この方法では最も良い値のバリデーションコストを記録し続けます．そして学習を続け，そのベストなバリデーションコストを <span class="math notranslate nohighlight">\(n\)</span> 回連続で更新できなかった場合，そこで学習を打ち切ります．この <span class="math notranslate nohighlight">\(n\)</span> がペイシェンスと呼ばれる値です．ペイシェンスには我慢とか忍耐とかそのような意味があります．コードは以下のように書きます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>
    <span class="n">MINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># ミニバッチのサイズとトレーニングデータのサイズから何個のミニバッチができるか計算</span>
    <span class="n">PATIENCE</span><span class="o">=</span><span class="mi">5</span>

    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span> <span class="c1"># MNISTにおいて出力ベクトルのサイズは0から9の10</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
    
    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用するため学習では利用しないが次のコードのために一応定義しておく．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="n">patiencecounter</span><span class="p">,</span><span class="n">bestvalue</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">100000</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># 次に進む．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>プログラムには以下の部分を追加しました．今回は4回までコストが改善しなくても許すが，5回目は許さないということです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">PATIENCE</span><span class="o">=</span><span class="mi">5</span>
</pre></div>
</div>
<p>学習ループを以下のようにコードを追加しました．<code class="docutils literal notranslate"><span class="pre">patiencecounter</span></code> はコストが更新されなかった回数を数えるカウンタです．<code class="docutils literal notranslate"><span class="pre">bestvalue</span></code> は最も良いコストの値を記録する変数です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="n">patiencecounter</span><span class="p">,</span><span class="n">bestvalue</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">100000</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="k">break</span>
</pre></div>
</div>
<p>以下の部分で，もし最も良いコストよりさらに良いコストが得られたらベストなコストを更新し，また，ペイシェンスのカウンタを元に（<code class="docutils literal notranslate"><span class="pre">0</span></code>）戻す作業をし，それ以外の場合はペイシェンスのカウンタを1ずつ増やします．もし，カウンタの値があらかじめ設定したペイシェンスの値に達したら学習ループを停止します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="k">break</span>
</pre></div>
</div>
<p>結果を観ると，過学習が起こっていなさそうなところで学習が停止されているのが解ります．</p>
<p>###3-2-5. <font color="Crimson">モデルの保存と利用</font></p>
<p>これまでに，早期終了を利用して良い人工知能が生成できるエポックが判明しました．機械学習の目的は当然，良い人工知能を開発することです．開発した人工知能は普通，別のサーバーとかトレーニングした時とは別の時間に利用したいはずです．ここで，この学習で発見した人工知能を保存して別のプログラムから，独立した人工知能として利用する方法を紹介します．最後に，テストセットでのその人工知能の性能を評価します．コードは以下のように変更します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>
    <span class="n">MINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># ミニバッチのサイズとトレーニングデータのサイズから何個のミニバッチができるか計算</span>
    <span class="n">PATIENCE</span><span class="o">=</span><span class="mi">5</span>

    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span> <span class="c1"># MNISTにおいて出力ベクトルのサイズは0から9の10</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
    
    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用するため学習では利用しないが次のコードのために一応定義しておく．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    <span class="c1"># モデルを保存するための記述</span>
    <span class="n">checkpoint</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="n">patiencecounter</span><span class="p">,</span><span class="n">bestvalue</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">100000</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="n">checkpoint</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;mlp-mnist/model&quot;</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># ユニットサイズや層の数やその他のハイパーパラメータを色々変更してより良いバリデーションコストを出力する予測器を作る．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>以下の記述を追加しました．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># モデルを保存するための記述</span>
    <span class="n">checkpoint</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>また，学習ループの最後に以下のような記述を追加しました．<code class="docutils literal notranslate"><span class="pre">mlp-mnist</span></code> というディレクトリに <code class="docutils literal notranslate"><span class="pre">model</span></code> という名前で学習済みモデルを保存するように，という意味です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>            <span class="n">checkpoint</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;mlp-mnist/model&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>以下のシェルのコマンドを打つと，ディレクトリが新規に生成されていることを確認できます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> ls mlp-mnist
</pre></div>
</div>
</div>
</div>
<p>最後に，以下のコードで保存したモデル（実体はパラメータ）を呼び出して，テストセットにてその性能を評価します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>

    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span> <span class="c1"># MNISTにおいて出力ベクトルのサイズは0から9の10</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
    
    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用する．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    <span class="c1"># モデルの読み込み</span>
    <span class="n">checkpoint</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    <span class="n">checkpoint</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s2">&quot;mlp-mnist&quot;</span><span class="p">))</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># テストセットでの性能評価</span>
    <span class="n">testcost</span><span class="p">,</span><span class="n">testacc</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test cost= </span><span class="si">{:7.4f}</span><span class="s2"> Test ACC= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">testcost</span><span class="p">,</span><span class="n">testacc</span><span class="p">))</span>

    <span class="c1"># テストセットの最初の画像を入力してみる</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">litestx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">litestt</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
    <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">litestx</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># 予測器にデータを入れて予測</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output vector:&quot;</span><span class="p">,</span><span class="n">ty</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="c1"># 出力ベクトルを表示</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Argmax of the output vector:&quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ty</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span> <span class="c1"># 出力ベクトルの要素の中で最も大きい値のインデックスを表示</span>

    <span class="c1"># 上で構築したハイパーパラメータを変化させたより良い人工知能の性能評価をする．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>学習済みモデルは以下のような記述で読み込みます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># モデルの読み込み</span>
    <span class="n">checkpoint</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    <span class="n">checkpoint</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s2">&quot;mlp-mnist&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>テストセットでの性能評価のための記述です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># テストセットでの性能評価</span>
    <span class="n">testcost</span><span class="p">,</span><span class="n">testacc</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test cost= </span><span class="si">{:7.4f}</span><span class="s2"> Test ACC= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">testcost</span><span class="p">,</span><span class="n">testacc</span><span class="p">))</span>
</pre></div>
</div>
<p>最後に，テストセットの最初の画像を予測器に入れてその結果を確認してみます．以下のコードで行います．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># テストセットの最初の画像を入力してみる</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">litestx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">litestt</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
    <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">litestx</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># 予測器にデータを入れて予測</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output vector:&quot;</span><span class="p">,</span><span class="n">ty</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="c1"># 出力ベクトルを表示</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Argmax of the output vector:&quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ty</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span> <span class="c1"># 出力ベクトルの要素の中で最も大きい値のインデックスを表示</span>
</pre></div>
</div>
<p>実行すると，テストセットでも高い性能を示すことが確認できました．また，7が答えである画像を入力に，<code class="docutils literal notranslate"><span class="pre">7</span></code> を出力できていることを確認しました．</p>
<p>#4. <font color="Crimson">配列情報の処理</font></p>
<p>##4-1. <font color="Crimson">扱うデータの紹介</font></p>
<p>###4-1-1. <font color="Crimson">IMDb</font></p>
<p>ここでは，IMDb（Internet Movie Database）という映画に対するレビューデータを用いて，それに対する感情分析（sentiment analysis）を行います．レビューデータは元々は自然言語なので文字列データです．その文字列情報がポジティブな感じなのかネガティブな感じなのかということを判別する人工知能を構築します．</p>
<p>###4-1-2. <font color="Crimson">ダウンロードと性質調査</font></p>
<p>IMDb も TensorFlow を利用することでダウンロードすることができます．以下のように書きます．また，IMDb の性質を調査します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">),</span> <span class="p">(</span><span class="n">litestx</span><span class="p">,</span> <span class="n">litestt</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of instances in the learning dataset:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lilearnx</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of instances in the test dataset:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">litestx</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">litestt</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The input vector of the first instance in the learning dataset:&quot;</span><span class="p">,</span> <span class="n">lilearnx</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Its length:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lilearnx</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The target vector of the first instance in the learning datast:&quot;</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The input vector of the second instance in the learning dataset:&quot;</span><span class="p">,</span> <span class="n">lilearnx</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Its length:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lilearnx</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The target vector of the first instance in the learning datast:&quot;</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data in the target vector:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span>

    <span class="c1"># 次に進む．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
	<span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>データセットのサイズは学習セットとテストセットで等しく25000インスタンスでした．学習セットの最初のデータの長さは218で2番目のデータの長さは189です．MNIST はその入力ベクトルの長さは784に固定されていました．IMDb には様々な長さの入力ベクトルが格納されています．RNN はこのような様々な長さの入力ベクトルを扱うことができます．入力ベクトルの要素（数字）は単語を意味しています．元々は英語の単語であったものを，数字（整数）に変換してくれているのです．また，教師ベクトルは0か1の二値です．その文章がどのような感情を示すのかを0か1で表現しています．次に，入力ベクトルに何種類の単語が存在しているのかを調査します．入力ベクトルに存在する最も大きな値を知れたらこれを達成できます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">),</span> <span class="p">(</span><span class="n">litestx</span><span class="p">,</span> <span class="n">litestt</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">vocabsize</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">litestx</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span><span class="o">&gt;</span><span class="n">vocabsize</span><span class="p">:</span>
            <span class="n">vocabsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">lilearnx</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span><span class="o">&gt;</span><span class="n">vocabsize</span><span class="p">:</span>
            <span class="n">vocabsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of unique words:&quot;</span><span class="p">,</span><span class="n">vocabsize</span><span class="p">)</span>

    <span class="c1"># 次に進む．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
	<span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>ユニークな単語の数は88586個でした．実はテストセットの方が少しだけ少ないのですが，テストセットが少ない分には問題ありません．次に，入力ベクトルの長さを調べます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">),</span> <span class="p">(</span><span class="n">litestx</span><span class="p">,</span> <span class="n">litestt</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">maxlen</span><span class="p">,</span><span class="n">minlen</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1000000</span>
    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">lilearnx</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span><span class="o">&gt;</span><span class="n">maxlen</span><span class="p">:</span>
            <span class="n">maxlen</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span><span class="o">&lt;</span><span class="n">minlen</span><span class="p">:</span>
            <span class="n">minlen</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Minimum and maximum length of instances in learning dataset:&quot;</span><span class="p">,</span><span class="n">minlen</span><span class="p">,</span><span class="n">maxlen</span><span class="p">)</span>
    <span class="n">maxlen</span><span class="p">,</span><span class="n">minlen</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1000000</span>
    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">litestx</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span><span class="o">&gt;</span><span class="n">maxlen</span><span class="p">:</span>
            <span class="n">maxlen</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span><span class="o">&lt;</span><span class="n">minlen</span><span class="p">:</span>
            <span class="n">minlen</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Minimum and maximum length of instances in test dataset:&quot;</span><span class="p">,</span><span class="n">minlen</span><span class="p">,</span><span class="n">maxlen</span><span class="p">)</span>

    <span class="c1"># 次に進む．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
	<span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>学習セットとテストセットの入力ベクトルの長さの最小値と最大値が判りました．</p>
<p>##4-2. <font color="Crimson">単語の埋め込み</font></p>
<p>###4-2-1. <font color="Crimson">各種エンコード法の特徴</font></p>
<p>上で紹介したように今回用いるデータセットは，自然言語の単語を1から88586の整数で既にエンコードされています．人工知能に処理させるためには自然言語では都合が悪く，数字データが都合が良いからです．提供されたデータで既に行われているように単語を数字に割り振って人工知能に入力しても，もちろん計算自体は可能です．しかし，この整数エンコーディングにはふたつの欠点があるそうです．あるそうです，と書きましたが，これは TensorFlow の公式ウェブサイトにそう書いてあったことを抜き出したためです．</p>
<ul class="simple">
<li><p>整数エンコーディングは単語間のいかなる関係性を含まない．</p></li>
<li><p>整数エンコーディングは人工知能にとっては解釈が難しい．例えば，線形分類器はそれぞれの特徴量について単一の重みしか学習しないため，ふたつの単語が似ていることとそれらのエンコーディングが似ていることの間には何の関係もなく，特徴と重みの組み合わせに意味がない．</p></li>
</ul>
<p>最初のひとつは学習全体を通して考えると人工知能のパラメータの方で解決できるし，ふたつ目も非線形な関数を近似できる人工知能を使えば解決できるため，回避できない問題とは思えませんが．</p>
<p>これとは別のエンコード方法として，ワンホットエンコーディングがあります．ワンホットエンコーディングはワンホットベクトルに単語を対応させます．ワンホットベクトルとは，ベクトルのある要素が1で他の全要素が0であるベクトルです．以下のような感じです．</p>
<img src="https://drive.google.com/uc?id=1p0Ti6W1qnNMbDl_v0qSb4Dweu333JYTN" width="50%">
（https://www.tensorflow.org/）
<p>この方法は非効率的です．ワンホットベクトルはとても疎です．ボキャブラリに1万の単語がある場合，各ベクトルはその要素の99.99%が0からなります．学習を効率よく進めるためには多くの重みパラメータを設定しなければならないことになるでしょう．また，入力ベクトルが場合によってはものすごく長くなるでしょう．</p>
<p>現在のところ最も良い方法と考えられるのは単語埋め込み（word embedding）です．単語埋め込みを利用すると似たような単語が似たようなベクトルへとエンコードされます（学習の過程で）．埋め込みは浮動小数点数で行い，密なベクトルができます．以下のような感じです．</p>
<img src="https://drive.google.com/uc?id=1znT0RNS-JBAqIfrTi9h--S-RHAO7Ettl" width="50%">
（https://www.tensorflow.org/）<p>###4-2-2. <font color="Crimson">Embedding Projector</font></p>
<p>TensorFlow は単語間の距離を可視化するウェブアプリを提供しています．Embedding Projector といいます．URL は <a class="reference external" href="https://projector.tensorflow.org/">https://projector.tensorflow.org/</a> です．以下の計算では LSTM を用いて映画レビューデータの感情分析をしますが，その過程で構築された人工知能の埋め込みベクトルをこのウェブアプリで可視化した結果は以下のような画像になりました．</p>
<img src="https://drive.google.com/uc?id=1ZSGM8pVCgj_5SEm0fLG0r6RJf9q2gPkB"><p><font color="Crimson">(9｀･ω･)9 ｡oO(よくわからないので，後で各自観察してみましょう．)</font></p>
<p>##4-3. <font color="Crimson">再帰型ニューラルネットワーク</font></p>
<p>###4-3-1. <font color="Crimson">LSTM について</font></p>
<p>次に，IMDb を使わずにより簡単なデータを生成して RNN の使い方を紹介します．ここでは，長短期記憶（LSTM（long short-term memory））という RNN を利用します．LSTM は様々な長さからなる配列情報を入力データとして受け取り，配列情報を出力することができるニューラルネットワークです．以下の点で MLP と異なります．</p>
<ul class="simple">
<li><p>長さの異なる入力ベクトルを同じ構造で扱うことができる．</p></li>
<li><p>配列情報を出力することもできる．MLP と同様の出力も可能．</p></li>
</ul>
<p>LSTM のアルゴリズムは以下の式で定義されます：</p>
<p>\begin{eqnarray}
\mathbf{v}<em>1&amp;=&amp;\sigma(\mathbf{W}</em>{1a}\mathbf{u}<em>t+\mathbf{W}</em>{1b}\mathbf{h}<em>{t-1}+\mathbf{b}</em>{1}),\
\mathbf{v}<em>2&amp;=&amp;\sigma(\mathbf{W}</em>{2a}\mathbf{u}<em>t+\mathbf{W}</em>{2b}\mathbf{h}<em>{t-1}+\mathbf{b}</em>{2}),\
\mathbf{v}<em>3&amp;=&amp;\sigma(\mathbf{W}</em>{3a}\mathbf{u}<em>t+\mathbf{W}</em>{3b}\mathbf{h}<em>{t-1}+\mathbf{b}</em>{3}),\
\mathbf{v}<em>4&amp;=&amp;\tau(\mathbf{W}</em>{4a}\mathbf{u}<em>t+\mathbf{W}</em>{4b}\mathbf{h}<em>{t-1}+\mathbf{b}</em>{4}),\
\mathbf{s}_t&amp;=&amp;\mathbf{v}_1\odot\mathbf{v}_4+\mathbf{v}<em>2\odot\mathbf{s}</em>{t-1},\
\mathbf{h}_t&amp;=&amp;\mathbf{v}_3\odot\tau(\mathbf{s}_t)．
\end{eqnarray}</p>
<p>ここで，太字の小文字はベクトル（1列の行列）で，太字の大文字は行列です．<span class="math notranslate nohighlight">\(t\)</span> は入力配列の要素の位置を示します．時系列なら <span class="math notranslate nohighlight">\(t\)</span> 時間目の要素です．文字列なら <span class="math notranslate nohighlight">\(t\)</span> 番目の要素です．例えば，ピリオドを含めて5文字の長さからなる <code class="docutils literal notranslate"><span class="pre">I</span> <span class="pre">have</span> <span class="pre">a</span> <span class="pre">pen</span> <span class="pre">.</span></code> のような文字列において，<span class="math notranslate nohighlight">\(t=1\)</span> の値は <code class="docutils literal notranslate"><span class="pre">I</span></code> で，<span class="math notranslate nohighlight">\(t=5\)</span> の値は <code class="docutils literal notranslate"><span class="pre">.</span></code> です．<span class="math notranslate nohighlight">\(\mathbf{W}\)</span> は LSTM で学習すべき重みパラメータです．<span class="math notranslate nohighlight">\(\mathbf{b}\)</span> はバイアスパラメータです．<span class="math notranslate nohighlight">\(\mathbf{\sigma}\)</span> と <span class="math notranslate nohighlight">\(\mathbf{\tau}\)</span> はそれぞれシグモイド関数とハイパボリックタンジェント関数です．それぞれの値域は，[0, 1] および [-1, 1] です．<span class="math notranslate nohighlight">\(\mathbf{h}_t\)</span> は時間 <span class="math notranslate nohighlight">\(t\)</span> における出力ベクトルです．<span class="math notranslate nohighlight">\(\mathbf{u}_t\)</span> は時間 <span class="math notranslate nohighlight">\(t\)</span> における入力ベクトルです．<span class="math notranslate nohighlight">\(\odot\)</span> はアダマール積を示し，<span class="math notranslate nohighlight">\(+\)</span> は行列の足し算を示します．<span class="math notranslate nohighlight">\(\mathbf{W}\mathbf{u}\)</span> のような変数が結合している部分はその変数間で行列の掛け算を行う表記です．</p>
<p>LSTM では入力ベクトルに対して最初の類似した4つの式にて中間ベクトル <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> を計算します．シグモイド関数を含む式の最小値は0で最大値は1です．これに対してハイパボリックタンジェント関数を含む4番目の式の最小値は-1で最大値は1です．この4番目の式は入力された値に LSTM のパラメータを作用させ-1から1の値に規格化する効果を持ちます．1から3番目の式はゲート構造と呼ばれる LSTM の仕組みです．この3つの式の出力値を5番目と6番目で <span class="math notranslate nohighlight">\(\mathbf{v}_4\)</span> に作用させます．</p>
<p>例えば，<span class="math notranslate nohighlight">\(\mathbf{v}_1\)</span> は入力ゲートと呼ばれるゲートです．この値が <span class="math notranslate nohighlight">\(\mathbf{0}\)</span> であった場合，入力値である <span class="math notranslate nohighlight">\(\mathbf{v}_4\)</span> と <span class="math notranslate nohighlight">\(\mathbf{v}_1\)</span> の（アダマール）積である <span class="math notranslate nohighlight">\(\mathbf{v}_1\odot\mathbf{v}_4\)</span> の値（5番目の式の第1項）は <span class="math notranslate nohighlight">\(\mathbf{0}\)</span> であり，その入力値は以降の計算に影響しなくなります．これはゲートが閉じているという状況です．また，2番目の式は忘却ゲートです．<span class="math notranslate nohighlight">\(\mathbf{s}_{t-1}\)</span> は現在（<span class="math notranslate nohighlight">\(t\)</span>）のひとつ前の時間における情報を保持した以前の記憶を保持したベクトルです．これに対してのゲートとしての機能を持つことから忘却ゲートと呼ばれます．また，3番目の式は出力ゲートです．<span class="math notranslate nohighlight">\(\mathbf{h}_t\)</span> は <span class="math notranslate nohighlight">\(t\)</span> における出力ベクトルですが，これを計算するために用いられるため出力ゲートと呼ばれます．LSTM はこのようなゲート構造を有することで高性能化を達成した RNN であると考えられています．元々は動物の脳の機能をモデルにして開発されました．</p>
<p>この出力の値 <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> は <span class="math notranslate nohighlight">\(\mathbf{s}\)</span> と同様に保存され，次の時間（timestep）での計算に用いられます．このように，LSTM は以前の情報（ひとつ前の timestep の情報）を使って出力をする人工知能です．ひとつ前の情報にはさらにひとつ前の情報が記憶されており，またそのひとつ前の情報にはさらにひとつ前の情報が記憶されています．よって，LSTM ではどんな長い配列情報であっても（パラメータサイズが十分なら），すべての文脈に関わる情報を記憶することが可能です．</p>
<p>###4-3-2. <font color="Crimson">実装の種類</font></p>
<p>次に，実際の LSTM の実装方法を紹介します．IMDb は様々な長さの配列を入力ベクトルとして0か1のスカラ値を出力させる問題です．ここで，スカラ値と表現していますが，TensorFlow の出力は実際はスカラの値ではなく，1つの要素からなるベクトルです．TensorFlow で入力および出力ベクトルとして純粋なスカラの値を使うことは基本的にはありません．よって入力や出力データのことを入力ベクトルとか出力ベクトルとかの表現で統一しています．また，0か1という分類をする問題です．これとは異なり，配列を入力に配列を出力させたいときもあるはずです．また，分類ではなく回帰をしたい場合もあるはずです．さらに，単語（整数）の多次元のベクトルへの埋め込み（embedding）が必要な場合もあります．例えば <code class="docutils literal notranslate"><span class="pre">1</span></code> という文字は人工知能に入力するためには <code class="docutils literal notranslate"><span class="pre">[0.2,</span> <span class="pre">0.1,</span> <span class="pre">0.3,</span> <span class="pre">0.4]</span></code> みたいなベクトルに変換しなければなりません．何次元のベクトルでも良いです．また，<code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">0,</span> <span class="pre">0,</span> <span class="pre">0]</span></code> みたいなワンホットエンコーディングと呼ばれる埋め込み方法でも良いです．これらの種類をまとめると以下の表のようになります．実装方法がそれぞれにおいてほんの少しずつ異なります．ちょっと厄介ですね．</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>入力</p></th>
<th class="text-align:center head"><p>出力</p></th>
<th class="text-align:center head"><p>問題</p></th>
<th class="text-align:center head"><p>埋め込み</p></th>
<th class="text-align:center head"><p>向き</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p><font color="Crimson">配列</font></p></td>
<td class="text-align:center"><p><font color="Crimson">スカラ</font></p></td>
<td class="text-align:center"><p><font color="Crimson">分類</font></p></td>
<td class="text-align:center"><p><font color="Crimson">不要</font></p></td>
<td class="text-align:center"><p><font color="Crimson">単方向</font></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>スカラ</p></td>
<td class="text-align:center"><p>分類</p></td>
<td class="text-align:center"><p>不要</p></td>
<td class="text-align:center"><p>双方向</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>スカラ</p></td>
<td class="text-align:center"><p>分類</p></td>
<td class="text-align:center"><p>必要</p></td>
<td class="text-align:center"><p>単方向</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>スカラ</p></td>
<td class="text-align:center"><p>分類</p></td>
<td class="text-align:center"><p>必要</p></td>
<td class="text-align:center"><p>双方向</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>スカラ</p></td>
<td class="text-align:center"><p>回帰</p></td>
<td class="text-align:center"><p>不要</p></td>
<td class="text-align:center"><p>単方向</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>スカラ</p></td>
<td class="text-align:center"><p>回帰</p></td>
<td class="text-align:center"><p>不要</p></td>
<td class="text-align:center"><p>双方向</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>スカラ</p></td>
<td class="text-align:center"><p>回帰</p></td>
<td class="text-align:center"><p>必要</p></td>
<td class="text-align:center"><p>単方向</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>スカラ</p></td>
<td class="text-align:center"><p>回帰</p></td>
<td class="text-align:center"><p>必要</p></td>
<td class="text-align:center"><p>双方向</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>分類</p></td>
<td class="text-align:center"><p>不要</p></td>
<td class="text-align:center"><p>単方向</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>分類</p></td>
<td class="text-align:center"><p>不要</p></td>
<td class="text-align:center"><p>双方向</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>分類</p></td>
<td class="text-align:center"><p>必要</p></td>
<td class="text-align:center"><p>単方向</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>分類</p></td>
<td class="text-align:center"><p>必要</p></td>
<td class="text-align:center"><p>双方向</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>回帰</p></td>
<td class="text-align:center"><p>不要</p></td>
<td class="text-align:center"><p>単方向</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>回帰</p></td>
<td class="text-align:center"><p>不要</p></td>
<td class="text-align:center"><p>双方向</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>配列</p></td>
<td class="text-align:center"><p>回帰</p></td>
<td class="text-align:center"><p>必要</p></td>
<td class="text-align:center"><p>単方向</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p><font color="Crimson">配列</font></p></td>
<td class="text-align:center"><p><font color="Crimson">配列</font></p></td>
<td class="text-align:center"><p><font color="Crimson">回帰</font></p></td>
<td class="text-align:center"><p><font color="Crimson">必要</font></p></td>
<td class="text-align:center"><p><font color="Crimson">双方向</font></p></td>
</tr>
</tbody>
</table>
<p>ここでは，「単方向で入力ベクトルが配列で出力ベクトルがスカラ（1要素からなるベクトル）で問題が分類で文字の埋め込みが不要なパターン」と「双方向で入力ベクトルと出力ベクトルがともに配列で問題が回帰で埋め込みが必要なパターン」のふたつの実装を紹介します．</p>
<p>###4-3-3. <font color="Crimson">LSTM の実装①</font></p>
<p>ここでは，「単方向で入力ベクトルが配列で出力ベクトルがスカラ（1要素からなるベクトル）で問題が分類で文字の埋め込みが不要なパターン」の実装方法を紹介します．ここでは以下のようなデータを生成して利用します．このデータセットは3つのインスタンスからなります．最初のインスタンスは4文脈からなる配列です．入力ベクトルの各 timestep は2要素からなるベクトルで構成されています．<span class="math notranslate nohighlight">\(t=1\)</span> のときの値は <code class="docutils literal notranslate"><span class="pre">[1.1,</span> <span class="pre">0.1]</span></code> で，<span class="math notranslate nohighlight">\(t=2\)</span> のときの値は <code class="docutils literal notranslate"><span class="pre">[2.2,</span> <span class="pre">0.3]</span></code> で，<span class="math notranslate nohighlight">\(t=3\)</span> のときの値は <code class="docutils literal notranslate"><span class="pre">[3.0,</span> <span class="pre">0.3]</span></code> で，<span class="math notranslate nohighlight">\(t=4\)</span> のときの値は <code class="docutils literal notranslate"><span class="pre">[4.0,</span> <span class="pre">1.0]</span></code> です．これに紐づいているターゲットベクトルは <code class="docutils literal notranslate"><span class="pre">[1]</span></code> です．これは分類問題なのでこのターゲットベクトルの <code class="docutils literal notranslate"><span class="pre">0</span></code> は <code class="docutils literal notranslate"><span class="pre">1</span></code> という値より <code class="docutils literal notranslate"><span class="pre">1</span></code> ほど小さい値を意味しているのでなく，単にクラスを意味する数字です．</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>入力ベクトル</p></th>
<th class="text-align:center head"><p>ターゲットベクトル</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>[ [1.1, 0.1], [2.2, 0.3], [3.0, 0.3], [4.0, 1.0] ]</p></td>
<td class="text-align:center"><p>[ 1 ]</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>[ [2.0 ,0.9], [0.1, 0.8], [3.0, 0.7], [4.0, 0.1], [1.0, 0.3] ]</p></td>
<td class="text-align:center"><p>[ 2 ]</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>[ [2.0, 1.0], [3.0, 0.6], [4.0, 0.6] ]</p></td>
<td class="text-align:center"><p>[ 0 ]</p></td>
</tr>
</tbody>
</table>
<p>プログラムは以下のように書きます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># データセットの生成</span>
    <span class="n">tx</span><span class="o">=</span><span class="p">[[[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">],[</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">0.3</span><span class="p">],[</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">0.3</span><span class="p">],[</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">]],[[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.8</span><span class="p">],[</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">0.7</span><span class="p">],[</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.3</span><span class="p">]],[[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">0.6</span><span class="p">],[</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.6</span><span class="p">]]]</span>
    <span class="n">tx</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tt</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">tt</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">()</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span> <span class="c1">#正解と出力の順番はこの通りにする必要がある．</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習前の人工知能がどのような出力をしているのかを確認</span>
    <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output vector:&quot;</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Target vector:&quot;</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>

    <span class="c1"># 学習ループ</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">traincost</span><span class="p">,</span><span class="n">trainacc</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="k">50</span>==0:
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:5d}</span><span class="s2">: Training cost= </span><span class="si">{:.4f}</span><span class="s2">, Training ACC= </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">trainacc</span><span class="p">))</span>
    
    <span class="c1"># 学習後の人工知能がどのような出力をしているのかを確認</span>
    <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output vector:&quot;</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Target vector:&quot;</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>

    <span class="c1"># MLPの場合と比較しつつ，ハイパーパラメータを変更しながらどのような挙動をしているか確認．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="o">=</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">tx</span><span class="p">):</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ty</span>

<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>以下の部分はデータセットを生成するための記述です．<code class="docutils literal notranslate"><span class="pre">tx</span></code> が入力ベクトルを格納するための変数です．入力ベクトルは二次元配列なので，<code class="docutils literal notranslate"><span class="pre">tx</span></code> は三次元配列の構造をとります．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># データセットの生成</span>
    <span class="n">tx</span><span class="o">=</span><span class="p">[[[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">],[</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">0.3</span><span class="p">],[</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">0.3</span><span class="p">],[</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">]],[[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">0.9</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.8</span><span class="p">],[</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">0.7</span><span class="p">],[</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">],[</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.3</span><span class="p">]],[[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">0.6</span><span class="p">],[</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">0.6</span><span class="p">]]]</span>
    <span class="n">tx</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tt</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">tt</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">tf.keras.preprocessing.sequence.pad_sequences()</span></code> はゼロパディングのための記述です．これによって以下のようにデータは変換されます．</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>入力ベクトル</p></th>
<th class="text-align:center head"><p>ターゲットベクトル</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>[ [1.1, 0.1], [2.2, 0.3], [3.0, 0.3], [4.0, 1.0], [0.0, 0.0] ]</p></td>
<td class="text-align:center"><p>[ 1 ]</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>[ [2.0 ,0.9], [0.1, 0.8], [3.0, 0.7], [4.0, 0.1], [1.0, 0.3] ]</p></td>
<td class="text-align:center"><p>[ 2 ]</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>[ [2.0, 1.0], [3.0, 0.6], [4.0, 0.6], [0.0, 0.0], [0.0, 0.0] ]</p></td>
<td class="text-align:center"><p>[ 0 ]</p></td>
</tr>
</tbody>
</table>
<p>その他の部分は MLP のときと変わりません．ネットワークの定義は異なっており，以下ように行います．MLP の場合は <code class="docutils literal notranslate"><span class="pre">Dense()</span></code> だけを用いました．これに対して LSTM を実装したい場合は <code class="docutils literal notranslate"><span class="pre">LSTM()</span></code> を用います．<code class="docutils literal notranslate"><span class="pre">LSTM(50)</span></code> となっていますが，これは LSTM のユニットサイズが50ということです．また，<code class="docutils literal notranslate"><span class="pre">Dense(3,activation=&quot;softmax&quot;)</span></code> とありますが，これは全結合層（最も基本的な層）でニューロンのサイズは3個であることを意味しています．また，この層は出力層です．前述の MNIST を扱った MLP が入力層784，中間層500，出力層10のサイズでしたが，これを <code class="docutils literal notranslate"><span class="pre">(784,</span> <span class="pre">500,</span> <span class="pre">10)</span></code>と表現します．これに対して，このネットワークの1 timestep では <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">50,</span> <span class="pre">3)</span></code> という MLP の計算がされます．これが LSTM の仕組みによって，timestep 分（5回）繰り返されます．この場合，出力は配列でないため，最後の <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">50,</span> <span class="pre">3)</span></code> の計算の出力のみが最終的な予測に用いられます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="o">=</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">tx</span><span class="p">):</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ty</span>
</pre></div>
</div>
<p>結果を確認すると，しっかりコストが下がっており，同時に正確度も上昇している様子が判ります．また，未学習の際には正解を導けていなかったところ，学習済みのモデルでは正解をしっかり出力できていることが確認できます．</p>
<p>###4-3-4. <font color="Crimson">LSTM の実装②</font></p>
<p>次に，「双方向で入力ベクトルと出力ベクトルがともに配列で問題が回帰で埋め込みが必要なパターン」の実装方法を紹介します．ここでは以下のようなデータを生成して利用します．このデータセットは3つのインスタンスからなります．最初のインスタンスは3文脈からなる配列です．入力ベクトルの各 timestep は整数です．ここでの7という数字は5よりも2ほど大きい値を意味しているのはなく，単なるダミー変数です．ターゲットベクトルの各 timestep は2要素からなるベクトルで構成されています．最初のインスタンスの <span class="math notranslate nohighlight">\(t=1\)</span> のときの値は <code class="docutils literal notranslate"><span class="pre">[6.2,</span> <span class="pre">1.1]</span></code> です．この6.2は1.1よりも5.1ほど大きい数値です．このインスタンスでは，最初に入力された7というダミー変数に対して，<code class="docutils literal notranslate"><span class="pre">[6.2,</span> <span class="pre">1.1]</span></code> を予測しなければなりません．これは，分類問題ではなく回帰問題です．</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>入力ベクトル</p></th>
<th class="text-align:left head"><p>ターゲットベクトル</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>[ 7, 5, 8 ]</p></td>
<td class="text-align:left"><p>[ [6.2, 1.1], [3.5, 2.1], [2.0, 1.1] ]</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>[ 3, 9, 3, 4, 6 ]</p></td>
<td class="text-align:left"><p>[ [4.5, 3.8], [4.1, 4.9], [3.4, 4.6], [2.7, 1.7], [2.1, 2.5] ]</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>[ 2, 3, 4, 1 ]</p></td>
<td class="text-align:left"><p>[ [1.2, 1.0], [4.4, 3.3], [3.1, 2.8], [2.7, 1.6] ]</p></td>
</tr>
</tbody>
</table>
<p>プログラムは以下のように書きます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Bidirectional</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># データセットの生成</span>
    <span class="n">tx</span><span class="o">=</span><span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">tt</span><span class="o">=</span><span class="p">[[[</span><span class="mf">6.2</span><span class="p">,</span><span class="mf">1.1</span><span class="p">],[</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">2.1</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">]],[[</span><span class="mf">4.5</span><span class="p">,</span><span class="mf">3.8</span><span class="p">],[</span><span class="mf">4.1</span><span class="p">,</span><span class="mf">4.9</span><span class="p">],[</span><span class="mf">3.4</span><span class="p">,</span><span class="mf">4.6</span><span class="p">],[</span><span class="mf">2.7</span><span class="p">,</span><span class="mf">1.7</span><span class="p">],[</span><span class="mf">2.1</span><span class="p">,</span><span class="mf">2.5</span><span class="p">]],[[</span><span class="mf">1.2</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">4.4</span><span class="p">,</span><span class="mf">3.3</span><span class="p">],[</span><span class="mf">3.1</span><span class="p">,</span><span class="mf">2.8</span><span class="p">],[</span><span class="mf">2.7</span><span class="p">,</span><span class="mf">1.6</span><span class="p">]]]</span>
    <span class="n">tx</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">tt</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span><span class="n">value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">()</span>
    <span class="n">mse</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">mse</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">costvalue</span>
    
    <span class="c1"># 学習前の人工知能がどのような出力をしているのかを確認</span>
    <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output vector:&quot;</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Target vector:&quot;</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>

    <span class="c1"># 学習ループ</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="k">50</span>==0:
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch=</span><span class="si">{0:5d}</span><span class="s2"> Cost=</span><span class="si">{1:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="nb">float</span><span class="p">(</span><span class="n">traincost</span><span class="p">)))</span>
    
    <span class="c1"># 学習後の人工知能がどのような出力をしているのかを確認</span>
    <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output vector:&quot;</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Target vector:&quot;</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>

    <span class="c1"># 上の例と比較しながら挙動を確認．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="o">=</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">9</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">output_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="o">=</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">tx</span><span class="p">):</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ty</span>

<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>このプログラムでは以下のような関数をインポートしています．この <code class="docutils literal notranslate"><span class="pre">Embedding()</span></code> は <code class="docutils literal notranslate"><span class="pre">7</span></code> とか <code class="docutils literal notranslate"><span class="pre">5</span></code> とか <code class="docutils literal notranslate"><span class="pre">8</span></code> というようなダミー変数をそれぞれ，<code class="docutils literal notranslate"><span class="pre">[5.1234,</span> <span class="pre">0.4516,</span> <span class="pre">1.4631]</span></code> とか <code class="docutils literal notranslate"><span class="pre">[1.5462,</span> <span class="pre">0.4641,</span> <span class="pre">0.9798]</span></code> とか <code class="docutils literal notranslate"><span class="pre">[3.7486,</span> <span class="pre">0.7672,</span> <span class="pre">4.423]</span></code> みたいなベクトルに変換するための関数です．ダミー変数を何らかのベクトル空間に埋め込むという作業をします．</p>
<div class="highlight-pyton notranslate"><div class="highlight"><pre><span></span>from tensorflow.keras.layers import Embedding
</pre></div>
</div>
<p>次に，以下の部分ですが，ダミー変数の場合は0でパディングを行いました．それに対してこのターゲットベクトルに関しては，<code class="docutils literal notranslate"><span class="pre">-1</span></code> というターゲットベクトルに出現しそうにない値でパディングを行っています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tt</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span><span class="n">value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>学習1回分の記述がこれまでと少し異なっています．回帰問題においては正確度は計算できないため，その部分を削除しました．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">mse</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">costvalue</span>
</pre></div>
</div>
<p>実際のネットワークは以下で定義しています．<code class="docutils literal notranslate"><span class="pre">Embedding(input_dim=9+1,output_dim=3,mask_zero=True)</span></code> における <code class="docutils literal notranslate"><span class="pre">9+1</span></code> は入力ベクトルのダミー変数の種類が <code class="docutils literal notranslate"><span class="pre">1</span></code> から <code class="docutils literal notranslate"><span class="pre">9</span></code> の9種類あることに加えて，配列をパディングするために <code class="docutils literal notranslate"><span class="pre">0</span></code> を利用するためです．この <code class="docutils literal notranslate"><span class="pre">0</span></code> から <code class="docutils literal notranslate"><span class="pre">9</span></code> の10種類の値を3要素からなるベクトルデータに変換する作業をこれで行います．<code class="docutils literal notranslate"><span class="pre">LSTM(units=50,return_sequences=True)</span></code> の部分は前述の例と異なります．<code class="docutils literal notranslate"><span class="pre">return_sequences=True</span></code> というオプションが指定されていますが，これは LSTM の最終的な出力としてひとつの固定長のベクトルを返すのではなくて，入力ベクトルの長さに合った個数のベクトルを返すためのオプションです．入力ベクトルはパディングされて5文脈のベクトルに変換されているので，この LSTM では5文脈のベクトルが返されます．また，<code class="docutils literal notranslate"><span class="pre">Bidirectional()</span></code> は RNN を双方向で計算させるためのものです．LSTM 自体は50個のニューロンで定義されていますが，双方向なので正方向の出力と負方向の出力が連結された100の大きさのベクトルが返ります．最後の <code class="docutils literal notranslate"><span class="pre">Dense()</span></code> は全結合層であり，出力データの各時刻における値が2要素からなるベクトルなのでニューロンは2個に設定します．プログラムを実行すると学習済みの人工知能の出力は教師ベクトルと類似していることが確認できます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="o">=</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">9</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">output_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="o">=</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">tx</span><span class="p">):</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ty</span>
</pre></div>
</div>
<p>以下では，<code class="docutils literal notranslate"><span class="pre">Embedding()</span></code> や <code class="docutils literal notranslate"><span class="pre">LSTM()</span></code> がどのような挙動をしているのかを観察します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Bidirectional</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># データセットの生成</span>
    <span class="n">tx</span><span class="o">=</span><span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">tt</span><span class="o">=</span><span class="p">[[[</span><span class="mf">6.2</span><span class="p">,</span><span class="mf">1.1</span><span class="p">],[</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">2.1</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">]],[[</span><span class="mf">4.5</span><span class="p">,</span><span class="mf">3.8</span><span class="p">],[</span><span class="mf">4.1</span><span class="p">,</span><span class="mf">4.9</span><span class="p">],[</span><span class="mf">3.4</span><span class="p">,</span><span class="mf">4.6</span><span class="p">],[</span><span class="mf">2.7</span><span class="p">,</span><span class="mf">1.7</span><span class="p">],[</span><span class="mf">2.1</span><span class="p">,</span><span class="mf">2.5</span><span class="p">]],[[</span><span class="mf">1.2</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">4.4</span><span class="p">,</span><span class="mf">3.3</span><span class="p">],[</span><span class="mf">3.1</span><span class="p">,</span><span class="mf">2.8</span><span class="p">],[</span><span class="mf">2.7</span><span class="p">,</span><span class="mf">1.6</span><span class="p">]]]</span>
    <span class="n">tx</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">tt</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span><span class="n">value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># 関数を定義</span>
    <span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>

    <span class="c1"># データセットの最初の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;1-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># ネットワークの定義</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="o">=</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">9</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">output_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="o">=</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">tx</span><span class="p">):</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">ty</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ty</span>

<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>##4-4. <font color="Crimson">テキスト感情分析</font></p>
<p>###4-4-1. <font color="Crimson">LSTM による計算</font></p>
<p>LSTM によって IMDb の感情分析をするには以下のようにプログラムを書きます．前述の MLP の書き方とかなり類似しています．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">30</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">PATIENCE</span><span class="o">=</span><span class="mi">7</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">100</span>
    <span class="n">EMBEDSIZE</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">22500</span>
    <span class="n">VALIDSIZE</span><span class="o">=</span><span class="mi">25000</span><span class="o">-</span><span class="n">TRAINSIZE</span>
    <span class="n">TRAINMINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span>
    <span class="n">VALIDMINIBATCHNUMBER</span><span class="o">=</span><span class="n">VALIDSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span>
    
    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span>
    <span class="n">lilearnx</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># データセットに存在するボキャブラリのサイズを計算</span>
    <span class="n">vocabsize</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">lilearnx</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span><span class="o">&gt;</span><span class="n">vocabsize</span><span class="p">:</span>
            <span class="n">vocabsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="n">vocabsize</span><span class="o">=</span><span class="n">vocabsize</span><span class="o">+</span><span class="mi">1</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>

    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">vocabsize</span><span class="p">,</span><span class="n">EMBEDSIZE</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>

    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="n">patiencecounter</span><span class="p">,</span><span class="n">bestvalue</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">100000</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TRAINMINIBATCHNUMBER</span><span class="p">):</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">TRAINMINIBATCHNUMBER</span>
        <span class="c1"># バリデーション（本来バリデーションでミニバッチ処理をする意味はないがColaboratoryの環境だとバッチ処理するとGPUメモリが枯渇したためミニバッチ処理をする）</span>
        <span class="n">validcost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">VALIDMINIBATCHNUMBER</span><span class="p">):</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">subvalidcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">],</span><span class="n">litraint</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">],</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">validcost</span><span class="o">+=</span><span class="n">subvalidcost</span>
        <span class="n">validcost</span><span class="o">=</span><span class="n">validcost</span><span class="o">/</span><span class="n">VALIDMINIBATCHNUMBER</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># 挙動を確認．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">vocabsize</span><span class="p">,</span><span class="n">EMBEDSIZE</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">vocabsize</span><span class="p">,</span><span class="n">output_dim</span><span class="o">=</span><span class="n">EMBEDSIZE</span><span class="p">,</span><span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">LSTM</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">outputsize</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>以下の部分は MLP による MNIST の解析においてはしなかった処理です．単語のベクトル空間への埋め込みのためにボキャブラリのサイズが必要であるため追加しています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># データセットに存在するボキャブラリのサイズを計算</span>
    <span class="n">vocabsize</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">lilearnx</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span><span class="o">&gt;</span><span class="n">vocabsize</span><span class="p">:</span>
            <span class="n">vocabsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="n">vocabsize</span><span class="o">=</span><span class="n">vocabsize</span><span class="o">+</span><span class="mi">1</span>
</pre></div>
</div>
<p>以下の部分はこれまでの実装と異なります．本来，バリデーションの過程においてミニバッチ処理をする必要はありません．しかし，この Google Colaboratory で使わせてもらっている GPU のメモリの都合上，バッチ処理をすると計算が止まってしまう場合があります．よって，ここではバリデーションの計算の際にもミニバッチ処理を行っています．パラメータの更新はもちろんしていません．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="c1"># バリデーション（本来バリデーションでミニバッチ処理をする意味はないがColaboratoryの環境だとバッチ処理するとGPUメモリが枯渇したためミニバッチ処理をする）</span>
        <span class="n">validcost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">VALIDMINIBATCHNUMBER</span><span class="p">):</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">subvalidcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">],</span><span class="n">litraint</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">],</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">validcost</span><span class="o">+=</span><span class="n">subvalidcost</span>
        <span class="n">validcost</span><span class="o">=</span><span class="n">validcost</span><span class="o">/</span><span class="n">VALIDMINIBATCHNUMBER</span>
</pre></div>
</div>
<p>その他の処理に関しては，これまで紹介してきたものと相違ないので省略します．また，テストセットを用いたテストの過程やパラメータ保存の方法もこれまでと同じなので省略します．プログラムを実行すると MLP による MNIST の処理と比べて計算にとても時間がかかったことが確認できると思います．RNN は MLP や CNN 等と比べて本質的に深いネットワークを形成します．よって（設計したネットワークに当然依りますが同程度のパラメータを指定した場合は）それらに比べてたくさんの計算時間が必要となるのです．</p>
<p>###4-4-2. <font color="Crimson">単語間距離の確認</font></p>
<p>上で紹介した Embedding Projector で単語間距離を可視化するために埋め込みベクトルとその埋め込みベクトルに対応する文字を出力します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">30</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">PATIENCE</span><span class="o">=</span><span class="mi">7</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">100</span>
    <span class="n">EMBEDSIZE</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">22500</span>
    <span class="n">VALIDSIZE</span><span class="o">=</span><span class="mi">25000</span><span class="o">-</span><span class="n">TRAINSIZE</span>
    <span class="n">TRAINMINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span>
    <span class="n">VALIDMINIBATCHNUMBER</span><span class="o">=</span><span class="n">VALIDSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span>
    
    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span>
    <span class="n">lilearnx</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># データセットに存在するボキャブラリのサイズを計算</span>
    <span class="n">vocabsize</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">lilearnx</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span><span class="o">&gt;</span><span class="n">vocabsize</span><span class="p">:</span>
            <span class="n">vocabsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="n">vocabsize</span><span class="o">=</span><span class="n">vocabsize</span><span class="o">+</span><span class="mi">1</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>

    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">vocabsize</span><span class="p">,</span><span class="n">EMBEDSIZE</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>

    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="n">patiencecounter</span><span class="p">,</span><span class="n">bestvalue</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">100000</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TRAINMINIBATCHNUMBER</span><span class="p">):</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">TRAINMINIBATCHNUMBER</span>
        <span class="c1"># バリデーション（本来バリデーションでミニバッチ処理をする意味はないがColaboratoryの環境だとバッチ処理するとGPUメモリが枯渇したためミニバッチ処理をする）</span>
        <span class="n">validcost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">VALIDMINIBATCHNUMBER</span><span class="p">):</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">subvalidcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">],</span><span class="n">litraint</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">],</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">validcost</span><span class="o">+=</span><span class="n">subvalidcost</span>
        <span class="n">validcost</span><span class="o">=</span><span class="n">validcost</span><span class="o">/</span><span class="n">VALIDMINIBATCHNUMBER</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># 埋め込み層の情報出力</span>
    <span class="n">embedweight</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_v</span><span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;vecs.tsv&quot;</span><span class="p">,</span><span class="s2">&quot;w&quot;</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
    <span class="n">out_m</span><span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;meta.tsv&quot;</span><span class="p">,</span><span class="s2">&quot;w&quot;</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>

    <span class="n">dvocab</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">get_word_index</span><span class="p">()</span>
    <span class="n">dvocab</span><span class="o">=</span><span class="p">{(</span><span class="n">v</span><span class="o">+</span><span class="mi">2</span><span class="p">):</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">dvocab</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="c1"># ゼロパディングとSOSとOOV</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dvocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">vec</span><span class="o">=</span><span class="n">embedweight</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">out_m</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;&quot;&#39;</span><span class="o">+</span><span class="n">dvocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39;&quot;&#39;</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">out_v</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">vec</span><span class="p">])</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">out_v</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">out_m</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    
    <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;vecs.tsv&#39;</span><span class="p">)</span>
    <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;meta.tsv&#39;</span><span class="p">)</span>

    <span class="c1"># Embedding Projector で単語の類似傾向を確認．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">vocabsize</span><span class="p">,</span><span class="n">EMBEDSIZE</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">vocabsize</span><span class="p">,</span><span class="n">output_dim</span><span class="o">=</span><span class="n">EMBEDSIZE</span><span class="p">,</span><span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">LSTM</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">outputsize</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>変更した部分は以下の部分です．<code class="docutils literal notranslate"><span class="pre">model.layers[0]</span></code> が埋め込みそうなので，2行目の記述でそのパラメータを <code class="docutils literal notranslate"><span class="pre">embedweight</span></code> に格納します．<code class="docutils literal notranslate"><span class="pre">dvocab=tf.keras.datasets.imdb.get_word_index()</span></code> の行では TensorFlow が準備してくれている IMDb に関する単語のインデックスの辞書をダウンロードしています（単語とそれが割り当てられている数値のペア）．<code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">dvocab.keys():</span></code> の中ではパラメータとそれに対応する単語を単に出力します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 埋め込み層の情報出力</span>
    <span class="n">embedweight</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_v</span><span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;vecs.tsv&quot;</span><span class="p">,</span><span class="s2">&quot;w&quot;</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
    <span class="n">out_m</span><span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;meta.tsv&quot;</span><span class="p">,</span><span class="s2">&quot;w&quot;</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>

    <span class="n">dvocab</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">get_word_index</span><span class="p">()</span>
    <span class="n">dvocab</span><span class="o">=</span><span class="p">{(</span><span class="n">v</span><span class="o">+</span><span class="mi">2</span><span class="p">):</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">dvocab</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="c1"># ゼロパディングとSOSとOOV</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dvocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">vec</span><span class="o">=</span><span class="n">embedweight</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">out_m</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;&quot;&#39;</span><span class="o">+</span><span class="n">dvocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39;&quot;&#39;</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">out_v</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">vec</span><span class="p">])</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">out_v</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">out_m</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    
    <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;vecs.tsv&#39;</span><span class="p">)</span>
    <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;meta.tsv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>上のプログラムを実行すると自身の計算機にふたつのファイルを保存することができます．それを Embedding Projector（<a class="reference external" href="https://projector.tensorflow.org/">https://projector.tensorflow.org/</a> ）の「Load」というところから読み込むと単語間の距離を観察することができます．</p>
<p>###4-4-3. <font color="Crimson">他のアルゴリズムの利用</font></p>
<p>上の例では LSTM を使って文字列の感情分析を行いました．TensorFlow はとても整備が行き届いたフレームワークです．LSTM 以外の RNN を使いたい場合は以下のように2行だけ書き換えるのみで TensorFlow が用意してくれている RNN は利用可能です．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">GRU</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">30</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">PATIENCE</span><span class="o">=</span><span class="mi">10</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">100</span>
    <span class="n">EMBEDSIZE</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">22500</span>
    <span class="n">VALIDSIZE</span><span class="o">=</span><span class="mi">25000</span><span class="o">-</span><span class="n">TRAINSIZE</span>
    <span class="n">TRAINMINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span>
    <span class="n">VALIDMINIBATCHNUMBER</span><span class="o">=</span><span class="n">VALIDSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span>
    
    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span>
    <span class="n">lilearnx</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s2">&quot;post&quot;</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># データセットに存在するボキャブラリのサイズを計算</span>
    <span class="n">vocabsize</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">lilearnx</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span><span class="o">&gt;</span><span class="n">vocabsize</span><span class="p">:</span>
            <span class="n">vocabsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>
    <span class="n">vocabsize</span><span class="o">=</span><span class="n">vocabsize</span><span class="o">+</span><span class="mi">1</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>

    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">vocabsize</span><span class="p">,</span><span class="n">EMBEDSIZE</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>

    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="n">patiencecounter</span><span class="p">,</span><span class="n">bestvalue</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">100000</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TRAINMINIBATCHNUMBER</span><span class="p">):</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">TRAINMINIBATCHNUMBER</span>
        <span class="c1"># バリデーション（本来バリデーションでミニバッチ処理をする意味はないがColaboratoryの環境だとバッチ処理するとGPUメモリが枯渇したためミニバッチ処理をする）</span>
        <span class="n">validcost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">VALIDMINIBATCHNUMBER</span><span class="p">):</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span>
            <span class="n">subvalidcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">],</span><span class="n">litraint</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">],</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">validcost</span><span class="o">+=</span><span class="n">subvalidcost</span>
        <span class="n">validcost</span><span class="o">=</span><span class="n">validcost</span><span class="o">/</span><span class="n">VALIDMINIBATCHNUMBER</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># TensorFlow が実装しているもうひとつの組み込み RNN である SimpleRNN も試す．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">vocabsize</span><span class="p">,</span><span class="n">EMBEDSIZE</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">vocabsize</span><span class="p">,</span><span class="n">output_dim</span><span class="o">=</span><span class="n">EMBEDSIZE</span><span class="p">,</span><span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">GRU</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">outputsize</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>ひとつ目の変更点は最初の辺りの以下の記述です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">GRU</span>
</pre></div>
</div>
<p>もうひとつはネットワーク記述の以下の部分です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">GRU</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">)</span>
</pre></div>
</div>
<p>GRU はゲート付き再帰型ユニット（gated recurrent unit）という LSTM と比較して大体 75% くらいのパラメータを持つ RNN です．どちらが良いかは解こうとする問題に依ります．LSTM や GRU 以外にも，例えば，自身で考案した RNN を実装することもできます．その場合には，<code class="docutils literal notranslate"><span class="pre">tf.keras.layers.AbstractRNNCell()</span></code> というものを利用します．（宣伝ですが）以下の論文では LSTM や GRU よりもパラメータの数が少なくて，それにもかかわらず，様々な問題において既存の RNN よりも早く同程度の収束域まで達する（パラメータと問題に依っては既存の RNN が到達できない収束域まで達する場合がある） RNN である YamRNN を開発しましたが，TensorFlow 用に <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.AbstractRNNCell()</span></code> を利用して書いたコードを公開しています．</p>
<p><font color="Crimson">(9｀･ω･)9 ｡oO(終わりです．)</font></p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="scikit-learn-2.html" title="前へ ページ">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">前へ</p>
            <p class="prev-next-title"><span class="section-number">5. </span>Scikit-learnファイルの分割</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="tensorflow-2.html" title="次へ ページ">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">次へ</p>
        <p class="prev-next-title"><span class="section-number">7. </span>TensorFlowファイルの分割</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      <div class="extra_footer">
        <a href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img style="0;margin-bottom:0.2em;" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a> © Copyright 2022 Graduate School of Information Sciences, Tohoku University．

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>