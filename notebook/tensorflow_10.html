
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>12. 強化学習法 &#8212; 実践データ科学</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="演習問題" href="worksheet.html" />
    <link rel="prev" title="11. 敵対的生成ネットワーク" href="tensorflow_08.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/neko.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">実践データ科学</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  データ科学を学ぶにあたって
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="introduction.html">
   1. 機械学習とその周辺事項
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  プログラミングの基礎
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="python_01.html">
   2. Python の基本的な使用方法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_02.html">
   3. Python の発展的な使用方法
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  scikit-learn を利用した機械学習
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="scikit_learn_01.html">
   4. 教師あり学習法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scikit_learn_02.html">
   5. 教師なし学習法
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  深層学習
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="tensorflow_01.html">
   6. TensorFlow の基本的な利用方法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tensorflow_02.html">
   7. 多層パーセプトロン
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tensorflow_05.html">
   8. 再帰型ニューラルネットワーク
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tensorflow_06.html">
   9. アテンションネットワーク
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tensorflow_07.html">
   10. Hugging Face の利用方法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tensorflow_08.html">
   11. 敵対的生成ネットワーク
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   12. 強化学習法
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  付録
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="worksheet.html">
   演習問題
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebook/tensorflow_10.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/yamada-kd/binds-training/tree/main/notebook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/yamada-kd/binds-training/blob/main/notebook/tensorflow_10.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   12.1. 基本的な事柄
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     12.1.1. 強化学習法とは
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     12.1.2. 用語の整理
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     12.1.3. 強化学習法の種類
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#q">
   12.2. Q 学習
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     12.2.1. 解きたい問題
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     12.2.2. Q 学習で行うこと
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     12.2.3. Q 学習の実装
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     12.2.4. 環境の可視化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     12.2.5. Q テーブルの出力
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#openai-gym">
   12.3. OpenAI Gym
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     12.3.1. インストール
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     12.3.2. 環境の生成
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     12.3.3. 環境遷移の再生
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     12.3.4. 環境遷移の画像化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     12.3.5. 環境のインポート
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id16">
   12.4. 深層 Q 学習
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id17">
     12.4.1. 深層学習と Q 学習
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id18">
     12.4.2. 教師データ
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     12.4.3. 計算の概要
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id20">
     12.4.4. 性能向上テクニック
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     12.4.5. 取り組む問題
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id22">
     12.4.6. 深層 Q 学習法の実装
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>強化学習法</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   12.1. 基本的な事柄
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     12.1.1. 強化学習法とは
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     12.1.2. 用語の整理
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     12.1.3. 強化学習法の種類
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#q">
   12.2. Q 学習
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     12.2.1. 解きたい問題
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     12.2.2. Q 学習で行うこと
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     12.2.3. Q 学習の実装
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     12.2.4. 環境の可視化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     12.2.5. Q テーブルの出力
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#openai-gym">
   12.3. OpenAI Gym
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     12.3.1. インストール
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     12.3.2. 環境の生成
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     12.3.3. 環境遷移の再生
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     12.3.4. 環境遷移の画像化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     12.3.5. 環境のインポート
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id16">
   12.4. 深層 Q 学習
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id17">
     12.4.1. 深層学習と Q 学習
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id18">
     12.4.2. 教師データ
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     12.4.3. 計算の概要
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id20">
     12.4.4. 性能向上テクニック
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     12.4.5. 取り組む問題
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id22">
     12.4.6. 深層 Q 学習法の実装
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1><span class="section-number">12. </span>強化学習法<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id2">
<h2><span class="section-number">12.1. </span>基本的な事柄<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>この章では強化学習法を紹介します．中でも Q 学習と呼ばれる方法を紹介します．その後，深層学習法を利用して Q 学習を実行する深層 Q 学習の紹介をします．この節ではそれらを理解するために必要な基礎知識の説明をします．</p>
<div class="section" id="id3">
<h3><span class="section-number">12.1.1. </span>強化学習法とは<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>機械学習法は大きく分けて，教師あり学習法，教師なし学習法，強化学習法の 3 個に分類されます．教師あり学習法は入力データとそれに紐づいた教師データからなるデータを利用して，入力データに対して教師データに応じた出力をするように人工知能（機械学習モデル）を成長させるものです．強化学習法で成長させるものはエージェントと呼ばれる人工知能です．強化学習法をする際の登場人物は環境とエージェントのふたつです．エージェントが何らかの根拠に基づいて環境に作用します．例えば，ゲームで言うところの環境とはマップであったり空間であったり，そこに存在するキャラクターであったりしますが，それに作用するとは，プレイヤーの分身であるキャラクターを空間上で動かすこと等に相当します．このエージェントによる行動決定の根拠を方策と言います．強化学習法ではエージェントを成長させますが，これに与えるものは入力データと教師データの組み合わせではありません．エージェントは行動を選択した際のその行動の良さの指標である報酬という値を獲得します．エージェントは自身の行動に基づいてこの報酬を得ますが，環境の遷移が終わったとき（ゲームをクリアしたときや対戦の決着がついたとき）の報酬を最大化するように成長させられます．</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>環境は遷移します．例えば，囲碁というゲームでは碁をプレイヤーが動かす度に盤面が変化しますが，この盤面が別の盤面に変化することを環境の遷移と言います．</p>
</div>
</div>
<div class="section" id="id4">
<h3><span class="section-number">12.1.2. </span>用語の整理<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>強化学習法ではこれまでの機械学習法では用いなかった用語を利用するため，それについての整理を行います．</p>
<p><strong>エージェント</strong>とは強化学習法で成長させられる対象です．以下で紹介する Q 学習において成長させられるものは Q テーブルというものであるため厳密には違うのですが，エージェントはそれを参照して行動を決定するため，このように書きました．</p>
<p><strong>環境</strong>とはエージェントが作用を及ぼす対象です．囲碁でいうところの盤面と碁が環境です．任天堂のマリオを動かすゲームでいうところのフィールドやマリオ等が環境です．この環境はエージェントが選択した行動によって遷移をします．</p>
<p><strong>報酬</strong>とはエージェントを成長させるために与える得点です．何かの行動を選択した際に，その行動が良かったなら報酬をエージェントに与えます．エージェントは獲得できる報酬を最大化するように成長します．ただし，この行動に対して得られた報酬を即時的に処理してエージェントが成長するわけではありません．以下の価値関数のところで記述しますが，この報酬を長期的に獲得し続けた結果の価値という値を指標にしてエージェントは成長させられます．</p>
<p><strong>価値関数</strong>とはその他の機械学習法でいうところの評価関数です．価値関数はさらに状態価値関数と行動価値関数というものに細分化されます．状態価値関数とはある方策のもとにおいて，ある状態であった場合に将来的にもらえる報酬の和を出力する関数です．一方で，行動価値関数とは，ある方策のもとである状態であった場合にある行動を選択したときにもらえる報酬の和を出力する関数です．これは以下の節で紹介する Q 学習において Q 値と呼ばれる値です．報酬と価値は似て非なるものです．報酬はエージェントが何らかの行動を選択したときに即時的に得られる値ですが，価値は得られる報酬の期待値です．ここで報酬の和と表現した値です．</p>
<p><strong>方策</strong>とはエージェントが行動を選択するために利用するルールです．意思決定則です．これに基づいてエージェントは行動を決定します．以下の項で紹介する方策ベース法では方策関数というものを利用しますが，これは現在の環境の状態を入力として行動（または行動の確率）を出力する関数です．</p>
<p><strong>エピソード</strong>とはエージェントが環境に作用し環境の遷移が何らかの停止条件に到達し終了するまでの時間の単位です．エピソードの中において環境が遷移する時間の単位はステップとかサイクルと言います．全ステップが 1 エピソードということです．</p>
<p><strong>割引率</strong>とは <span class="math notranslate nohighlight">\(\gamma\)</span> で表される値です．エピソードの最初から最後までの報酬の和を価値と言いますが，現在の状態から未来の報酬を計算する場合，不確定要素が入ってくることを避けれません．それを吸収するために未来の報酬に 0 から 1 の間の値である <span class="math notranslate nohighlight">\(\gamma\)</span> を掛けたもので和を計算します．この場合の報酬を割引報酬と言い，これを合計することで価値を計算します．割引報酬を利用した場合の時刻 <span class="math notranslate nohighlight">\(t\)</span> における価値 <span class="math notranslate nohighlight">\(V_t\)</span> は時刻 <span class="math notranslate nohighlight">\(t+1\)</span> における報酬 <span class="math notranslate nohighlight">\(r_{t+1}\)</span> を用いて以下のように表されます．</p>
<p><span class="math notranslate nohighlight">\(
V_t=r_{t+1}+\gamma V_{t+1}
\)</span></p>
<p>未来の報酬の重要度が下がるということになります．この値を調節することで未来の報酬をどれだけ重要視するかということを決めることができます．</p>
<p><strong>グリーディ</strong>（greedy）な方法とは長期的に考えればより良い解が見つかることを考慮せずに，短期的に最も良いと考えられる解を見つけようとする方法のことです．貪欲法と言います．これは強化学習の分野における専門的な言葉ではありません．この教材でははじめて出したような気がしたのでここで一応まとめてみました．</p>
</div>
<div class="section" id="id5">
<h3><span class="section-number">12.1.3. </span>強化学習法の種類<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>強化学習法を実行する方法には様々な分類の方法があります．モデルに基づく方法か価値または方策に基づく方法か等の分類方法です．強化学習法の種類は現在開発が活発であり，どの方法がどのような分類となるかを整理して言及することをこの教材では避けます．</p>
<p>最初に，モデルに基づく方法かそうでないかの観点から分類をすると，<strong>動的計画法</strong>はモデルに基づく方法です．動的計画法は正確な環境モデルを持っている場合に最適な方策を決定することが可能な方法です．例えば，何らかの格子世界を移動するオブジェクトが右に移動すればある報酬を得られるし，格子世界を出ようとするならペナルティが加えられる等というような環境の性質が完全に判明している場合に利用可能です．エピソードを終了せずとも方策を最適化しようとすることが可能です．これ以降で紹介する方法はモデルに基づく方法ではありません．</p>
<p>モデルフリーの方法であり，価値ベース法としては<strong>モンテカルロ法</strong>があります．モンテカルロ法はモデルに基づく方法である動的計画法とは異なり，完全な環境モデルを持たない場合，行動の結果として報酬が得られるかどうかが不明な際に用いられる方法です．エージェントの行動に応じて学習を進めます．エピソードを終了させることではじめて報酬を計算します．これを実績ベースであると言います．</p>
<p>モデルフリーの方法であり，実績ベースでない方法としては<strong>時間的差分法</strong>（Temporal Difference（TD）法）があります．時間的差分法は上述のふたつを組み合わせたような方法です．行動に対して得られる実際の報酬から環境遷移の度に評価関数を改善することで最適な方策を見つけようとする方法です．この 3 個の方法の中では時間的差分法が最も現実的な学習法であると思います．時間的差分法はさらに，アルゴリズムの実装の違いにより細分化されます．エージェントの行動を決定する方策と評価関数の更新に用いる方策が異なる方策オフ型の方法である <strong>Q 学習法</strong>と，エージェントの行動を決定する方策と評価関数の更新に用いる方策が同じ方策オン型の方法である <strong>SARSA</strong> です．どちらも価値ベースの方法です．この章で紹介する方法は Q 学習です．</p>
<p>それ以外にモデルフリーの方策ベース法にアクター・クリティック法という方法もありますが，これは時間的差分法の一種であるものの価値ベースの方法ではないもののことを言います．時間的差分法で価値ベースのものは Q 学習法と SARSA でしたね．アクター・クリティック法ではアクターという存在が行動を選択しますが，それを評価するものとしてクリティックという存在があり，アクターの行動をクリティックが評価することで方策を決定する方法です．</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>ある状態とそのときに選択する行動から別の状態に遷移する確率と，ある状態から別の状態に遷移した際の報酬すべてが明らかになっている方法がモデルベースの方法です．</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>方策ベース法とは，エージェントが何らかの方策（ニューラルネットワークによって記述されるルールとか）を持っており，その方法を改善する方法です．価値ベース法とは，行動から価値を得て（価値関数の値を推定して），その価値を高める方策を選択する方法です．エージェントの詳細な制御方法がわからなくてもエピソードが成功裏に終わらせたという価値をもとにエージェントの成長をさせる方法です．</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>より詳しく学びたい人は Bellman 方程式について調べてみてください．</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>深層学習の時代において開発が進められている方法は，時間的差分法に分類される Q 学習（価値ベース）と同じくアクター・クリティック法です．</p>
</div>
</div>
</div>
<div class="section" id="q">
<h2><span class="section-number">12.2. </span>Q 学習<a class="headerlink" href="#q" title="Permalink to this headline">¶</a></h2>
<p>この節ではフィールド上を動いてゴールを目指すオブジェクトの動きをコントロールするというタスクを通じて Q 学習の利用方法を理解します．</p>
<div class="section" id="id6">
<h3><span class="section-number">12.2.1. </span>解きたい問題<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>以下のような 5 行 4 列の行列を考えます．これはフィールドです．このフィールド上で何らかのオブジェクト（人でも犬でも何でも良いです）を動かしてゴール（G）を目指すこととします．オブジェクトはフィールド上のグリッド線で囲まれたどこかの位置に存在できることとします．このグリッド線で囲まれた位置のことをこれ以降マスと呼びます．オブジェクトは上下左右に動かせるものとします．ただし，フィールドは壁に囲まれているとします．つまり，オブジェクトはこの 5 行 4 列のフィールドの外には出られません．また，フィールドには障害物（X）があり，障害物が存在する位置にオブジェクトは行けないこととします．オブジェクトは最初ゴールでも障害物でもないオブジェクトが移動可能な普通のマス（S），座標にして <code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">0)</span></code> に位置しているものとします．このオブジェクトをうまく移動させてゴールまで導くエージェントを作ることをここでの問題とします．</p>
<a class="reference internal image-reference" href="https://github.com/yamada-kd/binds-training/blob/main/image/field.svg?raw=1"><img alt="https://github.com/yamada-kd/binds-training/blob/main/image/field.svg?raw=1" src="https://github.com/yamada-kd/binds-training/blob/main/image/field.svg?raw=1" style="width: 100%;" /></a>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>左上のマスを <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">0)</span></code> として右下のマスを <code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">3)</span></code> とします．つまり行列の要素の呼び方と同じですね．</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>この動かす対象であるオブジェクトのことをエージェントとして記載している記事がインターネット上にたくさんあります．例えば，囲碁における碁に相当するような存在だと思いますが，それをエージェントと呼ぶことはないと思います．エージェントとはプレイヤーであって，ゲームで言うところの環境の一部であるキャラクターや碁等のオブジェクトを移動させたりオブジェクトに何かをさせたりする存在であると思います．よってここではオブジェクトとエージェントを明確に使い分けます．</p>
</div>
</div>
<div class="section" id="id7">
<h3><span class="section-number">12.2.2. </span>Q 学習で行うこと<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>強化学習はエージェントがもらえる報酬を最大化するように学習を行います．エージェントがオブジェクトを動かした結果ゴールまでオブジェクトを導けたのであれば多くの報酬を獲得できます．一方で，障害物があるマスにはオブジェクトを移動できませんがその際には報酬が減ります．その他のマスにオブジェクトを移動させる場合は報酬は得られません．</p>
<p>このような状況において，Q 学習では報酬を最大化するために参照する Q テーブルなるものを構築します．学習の過程でこの Q テーブルは更新されます．エージェントは良い Q テーブルを参照することによってより良い性能でオブジェクトを的確に動かせるようになります．つまり，Q 学習で成長させられるものは Q テーブルです．Q テーブルには Q 値が格納されます．というよりは Q 値の集合が Q テーブルです．Q 値は環境がある状態 <span class="math notranslate nohighlight">\(s\)</span> にあるときに <span class="math notranslate nohighlight">\(a\)</span> というアクションをエージェントがとることの良さを示す値です．<span class="math notranslate nohighlight">\(Q(s,a)\)</span> と表します．</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>例えば，あるマス「<code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">0)</span></code>」という「状態」でエージェントがオブジェクトを「上に移動させる」という「アクション」をとったときの良さを表すものが Q 値です．</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Q 学習の Q は quality のイニシャルです．</p>
</div>
<p>Q 値の更新式を紹介します．ここでは更新された Q 値を <span class="math notranslate nohighlight">\(Q'\)</span> と書きます．Q 値はエージェントがある行動をとって環境が遷移した後に更新されます．この環境遷移前の Q 値を <span class="math notranslate nohighlight">\(Q\)</span>，状態を <span class="math notranslate nohighlight">\(s\)</span>，行動を <span class="math notranslate nohighlight">\(a\)</span>，獲得した報酬を <span class="math notranslate nohighlight">\(r\)</span> と書きます．また，環境遷移後の状態を <span class="math notranslate nohighlight">\(s'\)</span>，環境遷移後にとり得る行動を <span class="math notranslate nohighlight">\(a'\)</span> と書きます．このとき，Q 値の更新式は以下のように表されます．</p>
<p><span class="math notranslate nohighlight">\(
\displaystyle Q'(s,a)=Q(s,a)+\alpha(r+\gamma\max Q(s',a')-Q(s,a))
\)</span></p>
<p>このとき，<span class="math notranslate nohighlight">\(\alpha\)</span> は学習率と呼ばれ，0 から 1 の値をとります．この割引率は直後の括弧内の値（TD 誤差という値）をどれくらい更新の際に考慮するかという値です．TD 誤差は目標の価値と現在の価値のずれを示しています．時間的差分法ではこの TD 誤差を小さくすることでより良い行動価値関数を推定する方法と言えます．また，<span class="math notranslate nohighlight">\(\gamma\)</span> は割引率であり，0 から 1 の値をとります．</p>
<p>この式において，<span class="math notranslate nohighlight">\(\max Q(s',a')\)</span> は現在の行動によって遷移した状態において取り得るすべての行動（この場合上下左右の 4 個）に対する Q 値の中で最も大きな値のことです．</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>TD 誤差の部分を確認していただければわかるように，Q 値の更新式はある状態から次の状態に遷移したとき，最初の状態の Q 値を次の状態の最も大きな Q 値と報酬の和に近づけることを意味しています．例えば，ゴール直前の状態とそのひとつ前の状態を考えたとき，ひとつ前の状態の Q 値はゴール直前の状態に遷移しようとするように値が大きくなります．</p>
</div>
</div>
<div class="section" id="id8">
<h3><span class="section-number">12.2.3. </span>Q 学習の実装<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>実際の Q 学習は以下の手順で行われます．以下の項目の括弧内の記述はこの節で扱う問題に関する記述です．</p>
<ol class="simple">
<li><p>環境の初期化（オブジェクトをスタートのマスに置く）．</p></li>
<li><p>エージェントによる行動選択（オブジェクトを動かす方向である上下左右を選択する）．</p></li>
<li><p>環境の更新（オブジェクトを動かそうとする）．</p></li>
<li><p>環境の更新がそれ以上され得るかの終了条件の判定（ゴールに到達したかどうかを確認）．</p></li>
<li><p>Q テーブルの更新．</p></li>
<li><p>上記 1 から 5 の繰り返し．</p></li>
</ol>
<p>繰り返し作業の単位をエピソードと言います．上の 1 から 5 で 1 エピソードの計算です．学習の最中に epsilon-greedy 法という方法を利用して行動選択を行っています．epsilon-greedy 法とは <span class="math notranslate nohighlight">\(\epsilon\)</span> の確率でランダムに行動選択をし，それ以外の <span class="math notranslate nohighlight">\((1-\epsilon)\)</span> の確率では最も Q 値の高い行動を選択する方法です．</p>
<p>以上の Q 学習を実行するためのコードは以下のものです．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">Environment</span><span class="p">()</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actions</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">observation</span><span class="o">=</span><span class="n">observation</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="c1"># 環境の初期化．</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span> <span class="c1"># エージェントによってオブジェクトにさせるアクションを選択する．</span>
            <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># 環境を進める．</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span> <span class="c1"># Qテーブルの更新．</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Episode: </span><span class="si">{:3d}</span><span class="s2">, number of steps: </span><span class="si">{:3d}</span><span class="s2">, mean reward: </span><span class="si">{:6.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">episode</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)))</span>

<span class="k">class</span> <span class="nc">Environment</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;up&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;down&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;G&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="c1"># 以下は環境を初期化する関数．</span>
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
    
    <span class="c1"># 以下は環境を進める関数．</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkMovable</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span> <span class="c1"># オブジェクトの移動が可能かどうかを判定．</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">False</span> <span class="c1"># 移動できないときの報酬は-1．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">]:</span>
                <span class="n">y</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1"># フィールドと座標の都合上，上への移動の場合は-1をする．</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">]:</span>
                <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># 以下のifは報酬の計算とオブジェクトがゴールに到達してゲーム終了となるかどうかの判定のため．</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;O&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;G&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span>
    
    <span class="c1"># 以下は移動が可能かどうかを判定する関数．</span>
    <span class="k">def</span> <span class="nf">checkMovable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

<span class="k">class</span> <span class="nc">Agent</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">observation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="n">actions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1"># Qテーブル</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
    
    <span class="c1"># 以下の関数は行動を選択する関数．</span>
    <span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span> <span class="c1"># イプシロンの確率でランダムに行動する．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">])</span> <span class="c1"># 最もQ値が高い行動を選択．</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="c1"># 以下はQテーブルを更新する関数．</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">objectNewPosition</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
        <span class="n">objectNewPosition</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">objectNewPosition</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">objectNewPosition</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">:</span> <span class="c1"># Qテーブルのキーを新たに作る．</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">objectNewPosition</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">][</span><span class="n">action</span><span class="p">]</span>  <span class="c1"># Q(s,a)の計算．</span>
        <span class="n">maxQ</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">objectNewPosition</span><span class="p">])</span>  <span class="c1"># max(Q(s&#39;,a&#39;))の計算．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">q</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">maxQ</span><span class="p">)</span> <span class="o">-</span> <span class="n">q</span><span class="p">))</span> <span class="c1"># Q&#39;(s, a) = Q(s, a) + alpha * (reward + gamma * maxQ(s&#39;,a&#39;) - Q(s, a))の計算．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>実行した結果，エピソードを経るに従ってゴールに到達するまでに要した環境の更新数（<code class="docutils literal notranslate"><span class="pre">number</span> <span class="pre">of</span> <span class="pre">steps</span></code>）が小さくなり，その更新回数に渡って平均した報酬値（<code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">reward</span></code>）が大きくなったことがわかります．つまり，学習（Q テーブルの更新）がうまく進みエージェントが成長したことがわかります．</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>この出力だけ見るとこのプログラムを実行して何が起こったのかわかりませんね．次の項でオブジェクトがフィールドをどのように動いたかを可視化します．</p>
</div>
<p>プログラム最初から順に説明しますが，以下の部分では環境（マスとか移動するオブジェクトとかそのオブジェクトの位置とか）のインスタンスを生成します．その後，生成した環境を初期化します．次に環境中のオブジェクトを操作するエージェントのインスタンスを生成します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">env</span> <span class="o">=</span> <span class="n">Environment</span><span class="p">()</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actions</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">observation</span><span class="o">=</span><span class="n">observation</span><span class="p">)</span>
</pre></div>
</div>
<p>環境のクラス <code class="docutils literal notranslate"><span class="pre">Environment</span></code> は以下に示す通りです．以降で中身の要素の説明をします．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Environment</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;up&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;down&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;G&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="c1"># 以下は環境を初期化する関数．</span>
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
    
    <span class="c1"># 以下は環境を進める関数．</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkMovable</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span> <span class="c1"># オブジェクトの移動が可能かどうかを判定．</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">False</span> <span class="c1"># 移動できないときの報酬は-1．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">]:</span>
                <span class="n">y</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1"># フィールドと座標の都合上，上への移動の場合は-1をする．</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">]:</span>
                <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># 以下のifは報酬の計算とオブジェクトがゴールに到達してゲーム終了となるかどうかの判定のため．</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;O&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;G&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span>
    
    <span class="c1"># 以下は移動が可能かどうかを判定する関数．</span>
    <span class="k">def</span> <span class="nf">checkMovable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
</pre></div>
</div>
<p>以下の部分は環境の初期化をする記述です．最初に <code class="docutils literal notranslate"><span class="pre">self.actions</span></code> ですが，この環境が取りするコマンドはオブジェクトを上下左右に動かすためのもので，その記述です．次の <code class="docutils literal notranslate"><span class="pre">self.field</span></code> ですが，これは上に画像で示したフィールドを生成するためのものです．<code class="docutils literal notranslate"><span class="pre">X</span></code> が障害物，<code class="docutils literal notranslate"><span class="pre">G</span></code> がゴール，それ以外の <code class="docutils literal notranslate"><span class="pre">O</span></code> がオブジェクトが自由に移動できるマスです．<code class="docutils literal notranslate"><span class="pre">self.done</span></code> はオブジェクトがゴールに到達することでこのゲーム（オブジェクトをゴールまで動かすゲーム）が終了したかどうかを判定するための変数です．<code class="docutils literal notranslate"><span class="pre">self.reward</span></code> は報酬を格納する変数です．実はこの <code class="docutils literal notranslate"><span class="pre">self.iteration</span></code> はこのプログラムでは使わないのですが，後のレンダリングの際に必要なので加えています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;up&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;down&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;G&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">self.reward</span></code> はインスタンス変数にしなくても良かったかもしれません．</p>
</div>
<p>環境はエピソード毎にリセットする必要がありますが，そのための記述です．オブジェクトは <code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">0)</span></code> のマスに置きます．このメソッドは戻り値としてオブジェクトの位置を返します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 以下は環境を初期化する関数．</span>
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
</pre></div>
</div>
<p>以下は環境を進めるための記述です．最初に <code class="docutils literal notranslate"><span class="pre">self.checkMovable</span></code> でオブジェクトを移動させることができるかを判定します．オブジェクトは壁の外に移動させることができないし，また，障害物のあるマスには移動させることができません．そのような場合は，報酬としては <code class="docutils literal notranslate"><span class="pre">-1</span></code> の値を与えて，また，オブジェクトの存在するマスを変化させません．それ以外の場合は，入力された上下左右のコマンド（<code class="docutils literal notranslate"><span class="pre">action</span></code>）に従ってオブジェクトの位置を変化させます．さらに，報酬は障害物やゴール以外のマスにオブジェクトが位置する場合は <code class="docutils literal notranslate"><span class="pre">0</span></code> でゴールの場合は <code class="docutils literal notranslate"><span class="pre">100</span></code> を与えるようにします．ゴールにオブジェクトが到達している場合は <code class="docutils literal notranslate"><span class="pre">self.done</span></code> に <code class="docutils literal notranslate"><span class="pre">True</span></code> を入れます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 以下は環境を進める関数．</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkMovable</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span> <span class="c1"># オブジェクトの移動が可能かどうかを判定．</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">False</span> <span class="c1"># 移動できないときの報酬は-1．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">]:</span>
                <span class="n">y</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1"># フィールドと座標の都合上，上への移動の場合は-1をする．</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">]:</span>
                <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># 以下のifは報酬の計算とオブジェクトがゴールに到達してゲーム終了となるかどうかの判定のため．</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;O&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;G&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span>
    
    <span class="c1"># 以下は移動が可能かどうかを判定する関数．</span>
    <span class="k">def</span> <span class="nf">checkMovable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
</pre></div>
</div>
<p>次にエージェントのクラス <code class="docutils literal notranslate"><span class="pre">Agent</span></code> は以下に示す通りです．以降で中身の説明をします．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Agent</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">observation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="n">actions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1"># Qテーブル</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
    
    <span class="c1"># 以下の関数は行動を選択する関数．</span>
    <span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span> <span class="c1"># イプシロンの確率でランダムに行動する．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">])</span> <span class="c1"># 最もQ値が高い行動を選択．</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="c1"># 以下はQテーブルを更新する関数．</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">objectNewPosition</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
        <span class="n">objectNewPosition</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">objectNewPosition</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">objectNewPosition</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">:</span> <span class="c1"># Qテーブルのキーを新たに作る．</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">objectNewPosition</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">][</span><span class="n">action</span><span class="p">]</span>  <span class="c1"># Q(s,a)の計算．</span>
        <span class="n">maxQ</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">objectNewPosition</span><span class="p">])</span>  <span class="c1"># max(Q(s&#39;,a&#39;))の計算．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">q</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">maxQ</span><span class="p">)</span> <span class="o">-</span> <span class="n">q</span><span class="p">))</span> <span class="c1"># Q&#39;(s, a) = Q(s, a) + alpha * (reward + gamma * maxQ(s&#39;,a&#39;) - Q(s, a))の計算．</span>
</pre></div>
</div>
<p>最初の記述は，エージェントが持つ変数を生成するためのものです．<code class="docutils literal notranslate"><span class="pre">self.alpha</span></code> や <code class="docutils literal notranslate"><span class="pre">self.gamma</span></code> は Q 値の更新式で利用するものです．<code class="docutils literal notranslate"><span class="pre">self.epsilon</span></code> は epsilon-greedy 法に利用する値です．<code class="docutils literal notranslate"><span class="pre">self.observation</span></code> は上の Q 値の更新式における <code class="docutils literal notranslate"><span class="pre">s</span></code> に相当するものです．マスの座標です．その後の Q テーブル構築の際のディクショナリのキーとなる値です．これを文字列化します．その次のディクショナリ <code class="docutils literal notranslate"><span class="pre">self.qValues</span></code> が Q テーブルです．ここに，ある状態におけるそれぞれの行動の Q 値を格納し，それを学習の過程で更新します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">observation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="n">actions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1"># Qテーブル</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
</pre></div>
</div>
<p>以下の部分はエージェントが行動を選択するための記述です．epsilon-greedy 法を利用しています．確率的にランダムな行動を選択するか，または，これまでの Q テーブルを参照して最も Q 値が高い行動をとります．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 以下の関数は行動を選択する関数．</span>
    <span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span> <span class="c1"># イプシロンの確率でランダムに行動する．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">])</span> <span class="c1"># 最もQ値が高い行動を選択．</span>
        <span class="k">return</span> <span class="n">action</span>
</pre></div>
</div>
<p>最後の以下の部分は Q テーブルを更新するための記述です．行動選択によって新たなマスへの移動が行われる場合は新たに Q テーブルのキーを生成します．その後，現在の Q 値を計算（参照）し，また，環境遷移後の最も高い Q 値を示す行動の Q 値の値を計算します．これらは，上述の Q 値の更新式で利用する値です．これらを利用して Q 値を更新します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 以下はQテーブルを更新する関数．</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">objectNewPosition</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
        <span class="n">objectNewPosition</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">objectNewPosition</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">objectNewPosition</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">:</span> <span class="c1"># Qテーブルのキーを新たに作る．</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">objectNewPosition</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">][</span><span class="n">action</span><span class="p">]</span>  <span class="c1"># Q(s,a)の計算．</span>
        <span class="n">maxQ</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">objectNewPosition</span><span class="p">])</span>  <span class="c1"># max(Q(s&#39;,a&#39;))の計算．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">q</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">maxQ</span><span class="p">)</span> <span class="o">-</span> <span class="n">q</span><span class="p">))</span> <span class="c1"># Q&#39;(s, a) = Q(s, a) + alpha * (reward + gamma * maxQ(s&#39;,a&#39;) - Q(s, a))の計算．</span>
</pre></div>
</div>
<p>最後に，<code class="docutils literal notranslate"><span class="pre">main()</span></code> に戻って以下の部分の説明をします．エピソードは 50 回分計算します．環境の初期化をした後に，<code class="docutils literal notranslate"><span class="pre">agent.act()</span></code> によってオブジェクトにさせる行動を選択します．その行動を基に <code class="docutils literal notranslate"><span class="pre">env.step()</span></code> で環境を勧めます．引き続いて Q テーブルの更新を行います．もし，オブジェクトがゴールに達している場合はそれ以上のオブジェクトの移動や Q テーブルの更新を停止します．最後に，ゴールに到達するまでに要した環境遷移の回数と各エピソード毎に得られた報酬の平均値を出力します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="c1"># 環境の初期化．</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span> <span class="c1"># エージェントによってオブジェクトにさせるアクションを選択する．</span>
            <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># 環境を進める．</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span> <span class="c1"># Qテーブルの更新．</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Episode: </span><span class="si">{:3d}</span><span class="s2">, number of steps: </span><span class="si">{:3d}</span><span class="s2">, mean reward: </span><span class="si">{:6.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">episode</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="section" id="id9">
<h3><span class="section-number">12.2.4. </span>環境の可視化<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>上のプログラムを実行しただけではエージェントによる行動の選択や環境の遷移によってどのようなことが起こっているのかがよくわかりませんでした．以下のプログラムを動かすとどのように環境が遷移したのかを観察することができます．フィールドの様子を可視化している点以外は上のブログラムと同じものです．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># 環境をステップ毎に描画するようにしたもの．</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">Environment</span><span class="p">()</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actions</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">observation</span><span class="o">=</span><span class="n">observation</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="c1"># 環境の初期化．</span>
        <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span> <span class="c1"># エージェントによってオブジェクトにさせるアクションを選択する．</span>
            <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># 環境を進める．</span>
            <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span> <span class="c1"># Qテーブルの更新．</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Episode: </span><span class="si">{:3d}</span><span class="s2">, number of steps: </span><span class="si">{:3d}</span><span class="s2">, mean reward: </span><span class="si">{:6.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">episode</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)))</span>

<span class="k">class</span> <span class="nc">Environment</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;up&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;down&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;G&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="c1"># 以下は環境を初期化する関数．</span>
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
    
    <span class="c1"># 以下は環境を進める関数．</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkMovable</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span> <span class="c1"># オブジェクトの移動が可能かどうかを判定．</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">False</span> <span class="c1"># 移動できないときの報酬は-1．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">]:</span>
                <span class="n">y</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1"># フィールドと座標の都合上，上への移動の場合は-1をする．</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">]:</span>
                <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># 以下のifは報酬の計算とオブジェクトがゴールに到達してゲーム終了となるかどうかの判定のため．</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;O&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;G&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span>
    
    <span class="c1"># 以下は移動が可能かどうかを判定する関数．</span>
    <span class="k">def</span> <span class="nf">checkMovable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
    
    <span class="c1"># 以下はフィールドとオブジェクト（8）の様子を可視化する関数．</span>
    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
        <span class="n">field</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;G&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">]]</span>
        <span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;8&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration = </span><span class="si">{:3d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">field</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">Agent</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">observation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="n">actions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1"># Qテーブル</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
    
    <span class="c1"># 以下の関数は行動を選択する関数．</span>
    <span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span> <span class="c1"># イプシロンの確率でランダムに行動する．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">])</span> <span class="c1"># 最もQ値が高い行動を選択．</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="c1"># 以下はQテーブルを更新する関数．</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">objectNewPosition</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
        <span class="n">objectNewPosition</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">objectNewPosition</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">objectNewPosition</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">:</span> <span class="c1"># Qテーブルのキーを新たに作る．</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">objectNewPosition</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">][</span><span class="n">action</span><span class="p">]</span>  <span class="c1"># Q(s,a)の計算．</span>
        <span class="n">maxQ</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">objectNewPosition</span><span class="p">])</span>  <span class="c1"># max(Q(s&#39;,a&#39;))の計算．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">q</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">maxQ</span><span class="p">)</span> <span class="o">-</span> <span class="n">q</span><span class="p">))</span> <span class="c1"># Q&#39;(s, a) = Q(s, a) + alpha * (reward + gamma * maxQ(s&#39;,a&#39;) - Q(s, a))の計算．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>プログラムを実行した結果，フィールドが表示され，環境遷移のイタレーションの度に <code class="docutils literal notranslate"><span class="pre">8</span></code> で表示されるオブジェクトがスタート位置からゴール位置へと移動している様子が可視化されました．</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>エピソードの数値が小さいとき，つまり，Q テーブルの性能が低い場合は <code class="docutils literal notranslate"><span class="pre">8</span></code> はフラフラしていますね．</p>
</div>
<p>このプログラムが上のプログラムと変わっている点は環境のレンダリングをしているところです．プログラムでは以下の部分に <code class="docutils literal notranslate"><span class="pre">env.render()</span></code> という記述が加わっています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="c1"># 環境の初期化．</span>
        <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span> <span class="c1"># エージェントによってオブジェクトにさせるアクションを選択する．</span>
            <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># 環境を進める．</span>
            <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span> <span class="c1"># Qテーブルの更新．</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Episode: </span><span class="si">{:3d}</span><span class="s2">, number of steps: </span><span class="si">{:3d}</span><span class="s2">, mean reward: </span><span class="si">{:6.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">episode</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)))</span>
</pre></div>
</div>
<p>クラス <code class="docutils literal notranslate"><span class="pre">Environment</span></code> の部分に，<code class="docutils literal notranslate"><span class="pre">env.render()</span></code> がしていることの記述があります．フィールドにオブジェクトの位置を代入してそれを表示するだけですね．</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 以下はフィールドとオブジェクト（8）の様子を可視化する関数．</span>
    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
        <span class="n">field</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;G&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">]]</span>
        <span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;8&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration = </span><span class="si">{:3d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">field</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="id10">
<h3><span class="section-number">12.2.5. </span>Q テーブルの出力<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>最後に Q テーブルがどんなように成長したのかを以下のプログラムで確認します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Qテーブルを出力可能にしたもの．</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">Environment</span><span class="p">()</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actions</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">observation</span><span class="o">=</span><span class="n">observation</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="c1"># 環境の初期化．</span>
        <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span> <span class="c1"># エージェントによってオブジェクトにさせるアクションを選択する．</span>
            <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># 環境を進める．</span>
            <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span> <span class="c1"># Qテーブルの更新．</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Episode: </span><span class="si">{:3d}</span><span class="s2">, number of steps: </span><span class="si">{:3d}</span><span class="s2">, mean reward: </span><span class="si">{:6.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">episode</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)))</span>
        <span class="n">agent</span><span class="o">.</span><span class="n">outputQTable</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">Environment</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;up&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;down&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;G&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                      <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="c1"># 以下は環境を初期化する関数．</span>
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
    
    <span class="c1"># 以下は環境を進める関数．</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkMovable</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span> <span class="c1"># オブジェクトの移動が可能かどうかを判定．</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">False</span> <span class="c1"># 移動できないときの報酬は-1．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">]:</span>
                <span class="n">y</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1"># フィールドと座標の都合上，上への移動の場合は-1をする．</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">]:</span>
                <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]:</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># 以下のifは報酬の計算とオブジェクトがゴールに到達してゲーム終了となるかどうかの判定のため．</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;O&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;G&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span>
    
    <span class="c1"># 以下は移動が可能かどうかを判定する関数．</span>
    <span class="k">def</span> <span class="nf">checkMovable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;up&quot;</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;down&quot;</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">y</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
    
    <span class="c1"># 以下はフィールドとオブジェクト（8）の様子を可視化する関数．</span>
    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectPosition</span>
        <span class="n">field</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;G&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">],</span>
                 <span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">,</span> <span class="s2">&quot;O&quot;</span><span class="p">]]</span>
        <span class="n">field</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;8&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration = </span><span class="si">{:3d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">field</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">Agent</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">observation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="n">actions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1"># Qテーブル</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
    
    <span class="c1"># 以下の関数は行動を選択する関数．</span>
    <span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span> <span class="c1"># イプシロンの確率でランダムに行動する．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">])</span> <span class="c1"># 最もQ値が高い行動を選択．</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="c1"># 以下はQテーブルを更新する関数．</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">objectNewPosition</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
        <span class="n">objectNewPosition</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">objectNewPosition</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">objectNewPosition</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">:</span> <span class="c1"># Qテーブルのキーを新たに作る．</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">objectNewPosition</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">][</span><span class="n">action</span><span class="p">]</span>  <span class="c1"># Q(s,a)の計算．</span>
        <span class="n">maxQ</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">objectNewPosition</span><span class="p">])</span>  <span class="c1"># max(Q(s&#39;,a&#39;))の計算．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">observation</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">q</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">maxQ</span><span class="p">)</span> <span class="o">-</span> <span class="n">q</span><span class="p">))</span> <span class="c1"># Q&#39;(s, a) = Q(s, a) + alpha * (reward + gamma * maxQ(s&#39;,a&#39;) - Q(s, a))の計算．</span>
    
    <span class="c1"># 以下はQテーブルを出力する関数．</span>
    <span class="k">def</span> <span class="nf">outputQTable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Q-table:    Up   Down   Left  Right&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:7.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">j</span><span class="p">]),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>これは Q テーブルを出力する記述を加えただけなので説明は不要かもしれませんが，Q テーブルを出力するための記述はクラス <code class="docutils literal notranslate"><span class="pre">Agent</span></code> の以下の部分に追加しました．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 以下はQテーブルを出力する関数．</span>
    <span class="k">def</span> <span class="nf">outputQTable</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Q-table:    Up   Down   Left  Right&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:7.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qValues</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">j</span><span class="p">]),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
<p>全てのエピソードが終了した後の Q テーブルは以下のようなものとなりました．例えば，ゴール付近のマスである，<code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">2)</span></code> や <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">3)</span></code> ではどのような行動が高い Q 値を持つかと確認してみると，オブジェクトが <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">2)</span></code> のときは「右」に移動させることが，<code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">3)</span></code> のときは「上」に移動させることが最も高い Q 値を示していました．良い Q テーブルへと成長したことが確認できます．</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Q</span><span class="o">-</span><span class="n">table</span><span class="p">:</span>    <span class="n">Up</span>   <span class="n">Down</span>   <span class="n">Left</span>  <span class="n">Right</span>
<span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="mf">10.674</span>  <span class="mf">1.824</span> <span class="o">-</span><span class="mf">0.190</span> <span class="mf">99.030</span>
<span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>   <span class="mf">0.000</span>  <span class="mf">0.000</span>  <span class="mf">0.000</span>  <span class="mf">0.000</span>
<span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="o">-</span><span class="mf">0.100</span> <span class="o">-</span><span class="mf">0.100</span> <span class="o">-</span><span class="mf">0.100</span>  <span class="mf">7.221</span>
<span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="mf">27.443</span>  <span class="mf">0.433</span>  <span class="mf">0.238</span> <span class="mf">68.646</span>
<span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="mf">84.938</span>  <span class="mf">7.338</span> <span class="mf">18.591</span> <span class="mf">12.410</span>
<span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="mf">46.856</span>  <span class="mf">0.000</span>  <span class="mf">6.858</span>  <span class="mf">1.610</span>
<span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="mf">48.270</span>  <span class="mf">0.997</span>  <span class="mf">9.978</span> <span class="mf">10.193</span>
<span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="mf">44.444</span>  <span class="mf">0.453</span>  <span class="mf">0.000</span>  <span class="mf">0.000</span>
<span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>   <span class="mf">1.532</span>  <span class="mf">1.509</span>  <span class="mf">2.382</span> <span class="mf">20.779</span>
<span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="mf">32.544</span>  <span class="mf">0.346</span>  <span class="mf">0.864</span>  <span class="mf">3.671</span>
<span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="mf">12.940</span> <span class="o">-</span><span class="mf">0.254</span>  <span class="mf">1.262</span>  <span class="mf">0.341</span>
<span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="mf">0.457</span> <span class="o">-</span><span class="mf">0.171</span>  <span class="mf">3.350</span>  <span class="mf">0.000</span>
<span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="o">-</span><span class="mf">0.271</span> <span class="o">-</span><span class="mf">0.100</span>  <span class="mf">0.041</span>  <span class="mf">0.000</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="openai-gym">
<h2><span class="section-number">12.3. </span>OpenAI Gym<a class="headerlink" href="#openai-gym" title="Permalink to this headline">¶</a></h2>
<p>OpenAI Gym を利用すると様々なゲームを Python からコントロールできるようになります．スーパーマリオブラザーズ等の有名なゲームも Python コード上で構築したエージェントが動かすことができるようになります．たくさんの Atari のゲームも動かすことができます．</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>ただし，現在の OpenAI Gym には ROM ファイルは同梱されていません．著作権の問題なのかもしれませんが，詳しい事情は知りません．よって，マリオのゲームや Atari のゲームを利用したい場合はどこかからか ROM ファイルを入手する必要があります．</p>
</div>
<div class="section" id="id11">
<h3><span class="section-number">12.3.1. </span>インストール<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>以下のようなコマンドを打つことで OpenAI Gym をインストールすることができます．グーグルコラボラトリーにはあらかじめインストールされているためこのコマンドは打つ必要はありません．打っても良いです．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> pip install gym
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id12">
<h3><span class="section-number">12.3.2. </span>環境の生成<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>どのような環境（ゲーム）が利用可能であるかは以下のようなコードによって確認できます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">from</span> <span class="nn">gym</span> <span class="kn">import</span> <span class="n">envs</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">envids</span> <span class="o">=</span> <span class="p">[</span><span class="n">spec</span><span class="o">.</span><span class="n">id</span> <span class="k">for</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">envs</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">all</span><span class="p">()]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of environments:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">envs</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">all</span><span class="p">()))</span> <span class="c1"># 全ての環境の個数を出力．</span>
    <span class="k">for</span> <span class="n">envid</span> <span class="ow">in</span> <span class="n">envids</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">envid</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>この中の <code class="docutils literal notranslate"><span class="pre">CartPole-v1</span></code> というものを呼び出します．また，環境を初期化し，ランダムな入力から行動選択し，その行動によって環境を遷移させます．以下のように書きます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">gym</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="c1"># 環境の初期化，リセット．</span>
    <span class="nb">print</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">observation</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> <span class="c1"># ランダムな行動選択．強化学習をする際はここはエージェントによる行動選択となる．</span>
    <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># 環境の遷移．現在の状況に対して行動を行って，次の状態，報酬，停止条件の真偽，ゲーム状態を出力．</span>
    <span class="nb">print</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">observation</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>観測値として出力されている値は 4 個の要素からなるリストですが，最初から「台車の位置」，「台車の速さ」，「棒の角度」，「棒の角速度」です．何のことを言っているのかわからないと思いますが，次の項で可視化すると意味がわかると思います．</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>インターネット上の記事で速度と速さの使い分けがされていなさすぎて驚きました．</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>この gym を利用した場合に，<code class="docutils literal notranslate"><span class="pre">reset()</span></code> とか <code class="docutils literal notranslate"><span class="pre">step()</span></code> のような書き方があります．上の節で紹介した Q 学習の部分で環境のクラス <code class="docutils literal notranslate"><span class="pre">Enviroment</span></code> にも同様の方法がありましたが，あれは gym の挙動に似せて作ったものです．</p>
</div>
<p>状態空間，行動空間，報酬空間は以下のようにすることで確認できます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">gym</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">reward_range</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>以下のようにすると複数の環境を一度に実行することができます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">gym</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">vector</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">asynchronous</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id13">
<h3><span class="section-number">12.3.3. </span>環境遷移の再生<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>グーグルコラボラトリー可視化を行うためには特殊なコマンドを打って準備をする必要があります．以下のコマンドを打ちます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> apt update
<span class="o">!</span> apt install xvfb
<span class="o">!</span> pip install pyvirtualdisplay
</pre></div>
</div>
</div>
</div>
<p>また，2022 年 10 月 5 日に気づいたところ，以下のライブラリをインストールしないといけなくなったようなので，インストールします．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> pip install pygame
</pre></div>
</div>
</div>
</div>
<p>以下のプログラムを実行して描画に必要なディスプレイの起動をします．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">from</span> <span class="nn">pyvirtualdisplay</span> <span class="kn">import</span> <span class="n">Display</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">gymDisplay</span> <span class="o">=</span> <span class="n">Display</span><span class="p">()</span>
    <span class="n">gymDisplay</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>描画をする前にこのコマンドを打たなければなりません．これを打つ前に以下にあるプログラムを実行するとエラーが出ます．気をつけてください．やってしまった場合はグーグルコラボラトリーのランタイムを削除して再起動してやり直してください．</p>
</div>
<p>以下のようなプログラムでゲームの実行画面を描画することができます．ここでは描画の方法を 2 個紹介しますが，その 1 個目です．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">animation</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">)</span>

    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># 描画のための記述</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span> <span class="c1"># 描画をきれいにするための記述</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># 描画をきれいにするための記述</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># 描画をきれいにするための記述</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="n">image</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">))</span> <span class="c1"># 描画のための記述</span>
        <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">image</span><span class="p">])</span> <span class="c1"># 描画のための記述</span>

        <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="n">generatedAnimation</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">ArtistAnimation</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">(),</span> <span class="n">images</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 描画のための記述</span>
    <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">generatedAnimation</span><span class="o">.</span><span class="n">to_jshtml</span><span class="p">()))</span> <span class="c1"># 描画のための記述</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>表示された動画を確認するとわかるように，このゲームは車の上に棒が設置されているもので，その棒が倒れないように車をうまく動かすというものです．次に，もう 1 個の描画方法を紹介します．以下のように書きます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">animation</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;MountainCar-v0&quot;</span><span class="p">)</span>

    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># 描画のための記述</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 描画のための記述</span>
        <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">))</span> <span class="c1"># 描画のための記述</span>

        <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span> <span class="c1"># 描画のための記述</span>
    <span class="n">moment</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># 描画のための記述</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
        <span class="n">moment</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">generatedAnimation</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">(),</span> <span class="n">update</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">),</span> <span class="n">interval</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span> <span class="c1"># 描画のための記述</span>
    <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">generatedAnimation</span><span class="o">.</span><span class="n">to_jshtml</span><span class="p">()))</span> <span class="c1"># 描画のための記述</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id14">
<h3><span class="section-number">12.3.4. </span>環境遷移の画像化<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>上のプログラムでは動画をグーグルコラボラトリー上で表示しましたが，次のプログラムを実行すると動画を GIF ファイルとして保存することができます．画像の保存方法も 2 個紹介しますが，その 1 個目です．グーグルコラボラトリーの左にあるサイドバー上のフォルダのアイコンをクリックすると保存されたファイルを確認することができます．そのファイル名をダブルクリックすると画面右に動画が表示されます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">animation</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;CartPole-v1&#39;</span><span class="p">)</span>

    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="n">image</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">))</span>
        <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">image</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="n">generatedAnimation</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">ArtistAnimation</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">(),</span> <span class="n">images</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">generatedAnimation</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;cartpole-01.gif&quot;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s2">&quot;pillow&quot;</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span> <span class="c1"># ここだけ変化．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>もう 1 個の画像の生成方法です．以下のようなプログラムを実行します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">imageio</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;MountainCar-v0&quot;</span><span class="p">)</span>

    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="n">imageio</span><span class="o">.</span><span class="n">mimsave</span><span class="p">(</span><span class="s2">&quot;cartpole-02.gif&quot;</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="s2">&quot;GIF&quot;</span><span class="p">,</span> <span class="o">**</span><span class="p">{</span><span class="s1">&#39;duration&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="mi">50</span><span class="p">})</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id15">
<h3><span class="section-number">12.3.5. </span>環境のインポート<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>この項の記述はこの教材を実行する際に必要なものではありません．もし他の色々なゲームを導入したい場合にやってみてください．</p>
</div>
<p>この gym で実際に呼び出せる環境はデフォルトのままだととても少ないです．Atari の ROM を入手してそれを呼び出したい場合は以下のようにします．最初に以下のコマンドで Atari Learning Environment をインストールします．</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>! pip install ale-py
</pre></div>
</div>
<p>次に ROM ファイルを入れたフォルダをグーグルコラボラトリーを利用しているユーザーのグーグルドライブに置きます．グーグルドライブのフォルダをグーグルコラボラトリーから参照できるように以下のコードを実行します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s2">&quot;/content/drive&quot;</span><span class="p">,</span> <span class="n">force_remount</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<p>そのフォルダの名前が <code class="docutils literal notranslate"><span class="pre">atari2600</span></code> であったとします．その場合，以下のようなコマンドで ROM ファイルをインポートします．</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>! ale-import-roms drive/MyDrive/atari2600/
</pre></div>
</div>
<p>この結果，以下のような Atari に由来する環境を呼び出せるようになります．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">gym</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;MontezumaRevengeDeterministic-v4&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id16">
<h2><span class="section-number">12.4. </span>深層 Q 学習<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h2>
<p>Q 学習に深層学習法を利用した深層 Q 学習という方法を紹介します．</p>
<div class="section" id="id17">
<h3><span class="section-number">12.4.1. </span>深層学習と Q 学習<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<p>上の節で紹介した Q 学習法は環境（や行動）のサイズが大きくなるととても大きな計算時間が必要となります．すべての場合における Q テーブルを作成するからです．それを避けるために，Q テーブルを深層学習法を用いて近似しようという試みがありますが，それが深層 Q 学習法です．英語だと Deep Q Network（DQN）と言います．</p>
</div>
<div class="section" id="id18">
<h3><span class="section-number">12.4.2. </span>教師データ<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<p>深層 Q 学習は Q テーブルをニューラルネットワークによって近似する方法です．よって計算の過程でニューラルネットワークを成長させます．どうやって成長させるかですが，実はとても言い難いことなのですが，実は，そのニューラルネットワークは教師あり学習法によって成長させられます．</p>
<p>Q 値の更新式を再掲します．更新された Q 値を <span class="math notranslate nohighlight">\(Q'\)</span>，環境遷移前の Q 値を <span class="math notranslate nohighlight">\(Q\)</span>，状態を <span class="math notranslate nohighlight">\(s\)</span>，行動を <span class="math notranslate nohighlight">\(a\)</span>，獲得した報酬を <span class="math notranslate nohighlight">\(r\)</span>，環境遷移後の状態を <span class="math notranslate nohighlight">\(s'\)</span>，環境遷移後にとり得る行動を <span class="math notranslate nohighlight">\(a'\)</span> と書きます．</p>
<p><span class="math notranslate nohighlight">\(
\displaystyle Q'(s,a)=Q(s,a)+\alpha(r+\gamma\max Q(s',a')-Q(s,a))
\)</span></p>
<p>これにたいしてニューラルネットワークの学習に用いる教師データは <span class="math notranslate nohighlight">\(r+\gamma\max Q(s',a')\)</span> の部分です．停止条件に到達した場合は，<span class="math notranslate nohighlight">\(s'\)</span> も <span class="math notranslate nohighlight">\(a'\)</span> もないので，<span class="math notranslate nohighlight">\(r\)</span> のみが教師データになります．深層 Q 学習に登場するニューラルネットワークはこの教師データと同じような出力ができるように成長します．</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>強化学習なのに教師あり学習．不思議ですね．摩訶不思議です．</p>
</div>
</div>
<div class="section" id="id19">
<h3><span class="section-number">12.4.3. </span>計算の概要<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<p>深層 Q 学習がどのように計算されるかについて紹介します．エージェントは 2 個のニューラルネットワークを持ちます．ひとつは Q ネットワークと呼ばれるもので，もうひとつはターゲットネットワークと呼ばれるものです．Q ネットワークは Q 値を学習するためのネットワークです．学習の最中にもニューラルネットワークによって Q 値は常に計算され続けるのですが，その計算にこのネットワークを使うのは良くなさそうです．なぜなら，報酬を教師データとしてその都度成長させられるネットワークを使って，別の状態における Q 値を計算しようとすると，常に別の条件（パラメータ）によって Q 値を計算してしまうからです．よって，パラメータ更新の頻度が少ない別のネットワークを利用して Q 値を計算しますが，それがターゲットネットワークです．</p>
<ol class="simple">
<li><p>環境の初期化をする．</p></li>
<li><p>エージェントによる行動選択をする．このときのネットワークにはターゲットネットワークを利用する．</p></li>
<li><p>環境を進めて状態を得る．また，状態を経験バッファ（後で説明）に溜める．</p></li>
<li><p>経験バッファに溜めたデータを用いて Q ネットワークを学習させる．</p></li>
<li><p>停止条件に達したら環境を停止．</p></li>
<li><p>ターゲットネットワークの更新（Q ネットワークのパラメータに同期）．</p></li>
<li><p>上の 1 から 6 を繰り返す．</p></li>
</ol>
<p>実際の実装においては，性能を向上させるためのいくつかのテクニックを利用します．次の項でそれらを紹介します．</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>学習の過程で Q ネットワークは状態の遷移が起こる度にパラメータの更新がされます．最終的な価値を得るのではなく即時的な報酬を得る度に更新されるということです．そうではなくてエピソードが終了して価値の計算が終わってはじめて，その情報に基づいてエージェントを成長させたいということが開発者のやりたいことです．ターゲットネットワークはその情報に基づいて学習が行われるネットワークです．</p>
</div>
</div>
<div class="section" id="id20">
<h3><span class="section-number">12.4.4. </span>性能向上テクニック<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<p>前述のように<strong>ターゲットネットワークの利用</strong>をすることで常にパラメータが成長させられる Q ネットワークによって Q 値を生成するという不安定さを関係することができます．ターゲットネットワークの構造は Q ネットワークと完全に一致します．</p>
<p><strong>経験再生法</strong>（<strong>Experience Replay</strong>）は強化学習の最中にミニバッチ学習法を利用すための方法です．環境を進めることで，状態やそのときの行動や停止判定の情報を得ることができますが，その都度にネットワークのパラメータを更新するのではなく，ある一定の情報（経験）が収集された時点ではじめて学習を行う方法です．この経験をどれだけ蓄積するかはハイパーパラメータです．その経験を溜めるものを経験バッファと呼びます．以下のコードでは最大で 512 個の経験を溜めます．新しい経験を記憶した時点で古い記憶を消します．</p>
<p>イプシロングリーディ法はイプシロンの確率でエージェントにランダムな行動を選択させる方法ですが，この<strong>イプシロンの減衰</strong>をさせることで学習を経るにつれてランダムな行動を減らすという戦略をとることがあります．</p>
</div>
<div class="section" id="id21">
<h3><span class="section-number">12.4.5. </span>取り組む問題<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<p>この節では上の節で紹介した CartPole というゲームを解きます．台車の上に設置されている棒が倒れないように台車を動かすゲームです．エージェントが選択できる行動は「台車を右に動かす」または「台車を左に動かす」の 2 個です．環境を進めることで得られる状態は前述のように「台車の位置」，「台車の速さ」，「棒の角度」，「棒の角速度」の 4 個です．ゲームの停止条件は「棒の角度が 12 度，または，-12 度より大きく，または，小さくなったとき」，「台車の位置がディスプレイの端に位置（2.4 または -2.4）したとき」，「500 単位時間ゲームが続いたとき」です．</p>
</div>
<div class="section" id="id22">
<h3><span class="section-number">12.4.6. </span>深層 Q 学習法の実装<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h3>
<p>この問題を解決するために以下のような深層 Q 学習法の実装コードを実行します．少々行儀が悪いのですが，強化学習が終わった直後にテストを行ってその様子を可視化します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">animation</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">gym</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定．</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="c1"># イプシロングリーディ法のハイパーパラメータ．</span>
    <span class="n">epsilonDecayRate</span> <span class="o">=</span> <span class="mf">0.99</span> <span class="c1"># イプシロンの値を学習が進むにつれて小さくするための値．</span>
    <span class="n">minimumEpsilon</span> <span class="o">=</span> <span class="mf">0.06</span> <span class="c1"># イプシロンの値はこの値以上は維持する．</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.9</span>
    <span class="n">replaySize</span> <span class="o">=</span> <span class="mi">512</span> <span class="c1"># 記憶を溜めるサイズ．</span>
    <span class="n">minibatchSize</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">middleUnitSize</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">dropoutRate</span> <span class="o">=</span> <span class="mf">0.2</span>
    
    <span class="c1"># 環境の生成．</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 再現性確保のため乱数の種は絶対に指定する．</span>
    
    <span class="c1"># 環境情報の取得．</span>
    <span class="n">actionShape</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span> <span class="c1"># ニューラルネットワークの出力サイズを指定するため取得．</span>
    <span class="n">observationShape</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># ニューラルネットワークの入力サイズを指定するため取得．</span>
    
    <span class="c1"># リプレイバッファの生成．</span>
    <span class="n">experiences</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">replaySize</span><span class="p">)</span> <span class="c1"># 記憶を溜めるためのリスト．</span>
    
    <span class="c1"># エージェントの生成．</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">epsilonDecayRate</span><span class="p">,</span> <span class="n">minimumEpsilon</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">actionShape</span><span class="p">,</span> <span class="n">observationShape</span><span class="p">,</span> <span class="n">middleUnitSize</span><span class="p">,</span> <span class="n">minibatchSize</span><span class="p">,</span> <span class="n">dropoutRate</span><span class="p">)</span>
      
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">rewards</span><span class="p">,</span> <span class="n">costs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span> <span class="c1"># エピソード毎に報酬とニューラルネットワークの学習コストを溜めるリスト．</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span> <span class="c1"># エージェントによる行動の選択．これはターゲットネットワークによる選択．</span>
            <span class="n">newObservation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># 環境を進める．</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
            <span class="n">experiences</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;observation&quot;</span><span class="p">:</span> <span class="n">observation</span><span class="p">,</span> <span class="s2">&quot;action&quot;</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span> <span class="s2">&quot;reward&quot;</span><span class="p">:</span> <span class="n">reward</span><span class="p">,</span> <span class="s2">&quot;newObservation&quot;</span><span class="p">:</span> <span class="n">newObservation</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">:</span> <span class="n">done</span><span class="p">})</span> <span class="c1"># 経験を蓄積．</span>
            <span class="n">observation</span> <span class="o">=</span> <span class="n">newObservation</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">experiences</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">minibatchSize</span><span class="p">:</span> <span class="c1"># ミニバッチのサイズに達するまで経験がたまったらニューラルネットワークの学習を開始する．</span>
                <span class="n">cost</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">experiences</span><span class="p">)</span> <span class="c1"># Qネットワーク（qModel）の学習．</span>
                <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="k">break</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">experiences</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">minibatchSize</span><span class="p">:</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">update</span><span class="p">()</span> <span class="c1"># エピソードの最後にターゲットネットワーク（targetModel）の更新．</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Episode: </span><span class="si">{:3d}</span><span class="s2">, Number of steps: </span><span class="si">{:3d}</span><span class="s2">, Mean reward: </span><span class="si">{:3.1f}</span><span class="s2">, Cost: </span><span class="si">{:5.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">episode</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">costs</span><span class="p">)))</span>
        
    <span class="c1"># 以下はテスト結果を可視化するため．</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">frame</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">))</span>
    <span class="n">frames</span> <span class="o">=</span> <span class="p">[[</span><span class="n">frame</span><span class="p">]]</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">))</span> <span class="c1"># 描画のための記述</span>
        <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">frame</span><span class="p">])</span>
    <span class="n">generatedAnimation</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">ArtistAnimation</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">(),</span> <span class="n">frames</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 描画のための記述</span>
    <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">generatedAnimation</span><span class="o">.</span><span class="n">to_jshtml</span><span class="p">()))</span> <span class="c1"># 描画のための記述</span>
    <span class="n">generatedAnimation</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;cartpole-01.gif&quot;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s2">&quot;pillow&quot;</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Agent</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">epsilonDecayRate</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">minimumEpsilon</span><span class="o">=</span><span class="mf">0.06</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actionShape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">observationShape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">middleUnitSize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">minibatchSize</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">dropoutRate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilonDecayRate</span> <span class="o">=</span> <span class="n">epsilonDecayRate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minimumEpsilon</span> <span class="o">=</span> <span class="n">minimumEpsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actionShape</span> <span class="o">=</span> <span class="n">actionShape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observationShape</span> <span class="o">=</span> <span class="n">observationShape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qModel</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span><span class="n">middleUnitSize</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">actionShape</span><span class="p">,</span> <span class="n">dropoutRate</span><span class="p">)</span> <span class="c1"># Q値をその都度学習するためのネットワーク．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">targetModel</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span><span class="n">middleUnitSize</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">actionShape</span><span class="p">,</span> <span class="n">dropoutRate</span><span class="p">)</span> <span class="c1"># Q値を計算するためのネットワーク．エピソードが終わる度にQネットワークと同じパラメータに同期される．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatchSize</span> <span class="o">=</span> <span class="n">minibatchSize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mseComputer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()</span> <span class="c1"># Q値は右に動かすか左に動かすかの値なのでそれと同じになるように二乗誤差をコストとする．元の論文だとフーバーロスを利用．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>
    
    <span class="c1"># 以下の関数はイプシロングリーディ法を利用して行動を選択する関数．</span>
    <span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actionShape</span><span class="p">)</span> <span class="c1"># イプシロンの確率でランダムに行動する．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">targetModel</span><span class="p">(</span><span class="n">observation</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="c1"># 最もQ値が高い行動を選択．予測はターゲットネットワークで行う．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilonDecay</span><span class="p">()</span> <span class="c1"># イプシロンの値を少しずつ小さくする．</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="c1"># 以下の関数はイプシロンを少しずつ小さくするためのもの．</span>
    <span class="k">def</span> <span class="nf">epsilonDecay</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilonDecayRate</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">minimumEpsilon</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">minimumEpsilon</span>
    
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tx</span><span class="p">,</span> <span class="n">tt</span><span class="p">,</span> <span class="n">flag</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qModel</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">flag</span> <span class="c1"># ここで学習させるのはQネットワークの方なのでQネットワークの記述．</span>
            <span class="n">ty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qModel</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="n">flag</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mseComputer</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">ty</span><span class="p">)</span> <span class="c1"># コストを計算．</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">qModel</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span> <span class="c1"># 勾配の計算．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">qModel</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span> <span class="c1"># 最適化．</span>
        <span class="k">return</span> <span class="n">costvalue</span>
    
    <span class="c1"># 以下の関数はQネットワークの学習のため．</span>
    <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experiences</span><span class="p">):</span>
        <span class="n">instances</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">experiences</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatchSize</span><span class="p">)</span> <span class="c1"># リプレイバッファからミニバッチサイズ分のデータを抽出．</span>
        <span class="n">observationInstances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">instance</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">instances</span><span class="p">])</span> <span class="c1"># ニューラルネットワークの入力値を取り出しているだけ．</span>
        <span class="n">qValues</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">targetModel</span><span class="p">(</span><span class="n">observationInstances</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># Q値を計算（Q値を格納するための変数を作っただけ）．</span>
        <span class="n">newObservationInstances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">instance</span><span class="p">[</span><span class="s2">&quot;newObservation&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">instances</span><span class="p">])</span> <span class="c1"># ニューラルネットワークの入力値を取り出しているだけ．</span>
        <span class="n">newQValues</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">targetModel</span><span class="p">(</span><span class="n">newObservationInstances</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># Q値を計算．</span>
        <span class="c1"># 以下のforは教師データを作成するための記述．</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">instance</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">instances</span><span class="p">):</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">instance</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">instance</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">instance</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]:</span>
                <span class="n">qValues</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">qValues</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">newQValues</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">learncostvalue</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">observationInstances</span><span class="p">,</span> <span class="n">qValues</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">learncostvalue</span>
    
    <span class="c1"># 以下の関数はターゲットネットワークの更新（Qネットワークと同じにすること）のため．</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">targetModel</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qModel</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">middleUnitSize</span><span class="p">,</span> <span class="n">outputSize</span><span class="p">,</span> <span class="n">dropoutRate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">middleUnitSize</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">middleUnitSize</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">outputSize</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropoutRate</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">learningFlag</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">a1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">learningFlag</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">a1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">learningFlag</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>実行した結果，エピソードに対して，ゲームを継続することができたステップ数，エピソード毎の平均報酬とニューラルネットワークのコストが出力されました．ステップ数は学習を経るにつれて増えていると思います．また，平均報酬は常に <code class="docutils literal notranslate"><span class="pre">1.0</span></code> となっているはずです．ゲーム終了までの間，1 単位時間ゲームを継続すると報酬が 1 ポイントもらえるというシステムなので，平均報酬は <code class="docutils literal notranslate"><span class="pre">1.0</span></code> となるのです．また，テストを実行した結果すると棒が倒れずに維持される動画を確認できると思います．GPU の利用や乱数の種の状況によっては異なる結果が得られているかもしれません．</p>
<img alt="https://github.com/yamada-kd/binds-training/blob/main/image/cartpole.gif?raw=1" src="https://github.com/yamada-kd/binds-training/blob/main/image/cartpole.gif?raw=1" />
<p>以下の部分ではハイパーパラメータを設定します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># ハイパーパラメータの設定．</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="c1"># イプシロングリーディ法のハイパーパラメータ．</span>
    <span class="n">epsilonDecayRate</span> <span class="o">=</span> <span class="mf">0.99</span> <span class="c1"># イプシロンの値を学習が進むにつれて小さくするための値．</span>
    <span class="n">minimumEpsilon</span> <span class="o">=</span> <span class="mf">0.06</span> <span class="c1"># イプシロンの値はこの値以上は維持する．</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.9</span>
    <span class="n">replaySize</span> <span class="o">=</span> <span class="mi">512</span> <span class="c1"># 記憶を溜めるサイズ．</span>
    <span class="n">minibatchSize</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">middleUnitSize</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">dropoutRate</span> <span class="o">=</span> <span class="mf">0.2</span>
</pre></div>
</div>
<p>以下の部分では環境を静止して，環境の情報を取得して，経験バッファを生成します．再現性確保のために乱数の種は指定すべきです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 環境の生成．</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 再現性確保のため乱数の種は絶対に指定する．</span>
    
    <span class="c1"># 環境情報の取得．</span>
    <span class="n">actionShape</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span> <span class="c1"># ニューラルネットワークの出力サイズを指定するため取得．</span>
    <span class="n">observationShape</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># ニューラルネットワークの入力サイズを指定するため取得．</span>
    
    <span class="c1"># リプレイバッファの生成．</span>
    <span class="n">experiences</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">replaySize</span><span class="p">)</span> <span class="c1"># 記憶を溜めるためのリスト．</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>何をするにしても乱数の種は絶対に指定しましょう．</p>
</div>
<p>以下の部分はエージェントを生成するためのものです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># エージェントの生成．</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">epsilonDecayRate</span><span class="p">,</span> <span class="n">minimumEpsilon</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">actionShape</span><span class="p">,</span> <span class="n">observationShape</span><span class="p">,</span> <span class="n">middleUnitSize</span><span class="p">,</span> <span class="n">minibatchSize</span><span class="p">,</span> <span class="n">dropoutRate</span><span class="p">)</span>
</pre></div>
</div>
<p>エージェントはクラス <code class="docutils literal notranslate"><span class="pre">Agent</span></code> によって生成されますが，これについて説明します．以下の部分でこのクラスで利用する変数等を生成します．ネットワークは Q ネットワークとターゲットネットワークの 2 個を生成します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">epsilonDecayRate</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">minimumEpsilon</span><span class="o">=</span><span class="mf">0.06</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">actionShape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">observationShape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">middleUnitSize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">minibatchSize</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">dropoutRate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilonDecayRate</span> <span class="o">=</span> <span class="n">epsilonDecayRate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minimumEpsilon</span> <span class="o">=</span> <span class="n">minimumEpsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actionShape</span> <span class="o">=</span> <span class="n">actionShape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observationShape</span> <span class="o">=</span> <span class="n">observationShape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qModel</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span><span class="n">middleUnitSize</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">actionShape</span><span class="p">,</span> <span class="n">dropoutRate</span><span class="p">)</span> <span class="c1"># Q値をその都度学習するためのネットワーク．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">targetModel</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span><span class="n">middleUnitSize</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">actionShape</span><span class="p">,</span> <span class="n">dropoutRate</span><span class="p">)</span> <span class="c1"># Q値を計算するためのネットワーク．エピソードが終わる度にQネットワークと同じパラメータに同期される．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatchSize</span> <span class="o">=</span> <span class="n">minibatchSize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mseComputer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()</span> <span class="c1"># Q値は右に動かすか左に動かすかの値なのでそれと同じになるように二乗誤差をコストとする．元の論文だとフーバーロスを利用．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>
</pre></div>
</div>
<p>以下の部分はイプシロングリーディ法の記述ですが，このコードにおいてはイプシロン減衰も行うのでその記述もあります．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 以下の関数はイプシロングリーディ法を利用して行動を選択する関数．</span>
    <span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actionShape</span><span class="p">)</span> <span class="c1"># イプシロンの確率でランダムに行動する．</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">targetModel</span><span class="p">(</span><span class="n">observation</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="c1"># 最もQ値が高い行動を選択．予測はターゲットネットワークで行う．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilonDecay</span><span class="p">()</span> <span class="c1"># イプシロンの値を少しずつ小さくする．</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="c1"># 以下の関数はイプシロンを少しずつ小さくするためのもの．</span>
    <span class="k">def</span> <span class="nf">epsilonDecay</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilonDecayRate</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">minimumEpsilon</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">minimumEpsilon</span>
</pre></div>
</div>
<p>以下の部分は Subclassing API のいつもの記述です．注意すべき点は，これで学習させられるネットワークは Q ネットワークの方であるということです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tx</span><span class="p">,</span> <span class="n">tt</span><span class="p">,</span> <span class="n">flag</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qModel</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">flag</span> <span class="c1"># ここで学習させるのはQネットワークの方なのでQネットワークの記述．</span>
            <span class="n">ty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qModel</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="n">flag</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mseComputer</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">ty</span><span class="p">)</span> <span class="c1"># コストを計算．</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">qModel</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span> <span class="c1"># 勾配の計算．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">qModel</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span> <span class="c1"># 最適化．</span>
        <span class="k">return</span> <span class="n">costvalue</span>
</pre></div>
</div>
<p>以下の記述は Q ネットワークのパラメータ更新のための記述です．経験バッファからミニバッチサイズ分のインスタンスを取り出し，そこから状態と次の状態を抽出し，それに対してターゲットネットワークを利用して Q 値を計算します．その Q 値を教師データとして Q ネットワークを学習させます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 以下の関数はQネットワークの学習のため．</span>
    <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experiences</span><span class="p">):</span>
        <span class="n">instances</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">experiences</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatchSize</span><span class="p">)</span> <span class="c1"># リプレイバッファからミニバッチサイズ分のデータを抽出．</span>
        <span class="n">observationInstances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">instance</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">instances</span><span class="p">])</span> <span class="c1"># ニューラルネットワークの入力値を取り出しているだけ．</span>
        <span class="n">qValues</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">targetModel</span><span class="p">(</span><span class="n">observationInstances</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># Q値を計算（Q値を格納するための変数を作っただけ）．</span>
        <span class="n">newObservationInstances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">instance</span><span class="p">[</span><span class="s2">&quot;newObservation&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">instances</span><span class="p">])</span> <span class="c1"># ニューラルネットワークの入力値を取り出しているだけ．</span>
        <span class="n">newQValues</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">targetModel</span><span class="p">(</span><span class="n">newObservationInstances</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># Q値を計算．</span>
        <span class="c1"># 以下のforは教師データを作成するための記述．</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">instance</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">instances</span><span class="p">):</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">instance</span><span class="p">[</span><span class="s2">&quot;action&quot;</span><span class="p">]</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">instance</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">instance</span><span class="p">[</span><span class="s2">&quot;done&quot;</span><span class="p">]:</span>
                <span class="n">qValues</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">qValues</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">newQValues</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">learncostvalue</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">observationInstances</span><span class="p">,</span> <span class="n">qValues</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">learncostvalue</span>
</pre></div>
</div>
<p>以下の記述はターゲットネットワークを更新するためのものです．ターゲットネットワークの更新方法は，Q ネットワークのパラメータをそのまま利用するハードアップデートと一部を利用するソフトアップデートがあるのですが，ここではハードアップデートを利用しました．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 以下の関数はターゲットネットワークの更新（Qネットワークと同じにすること）のため．</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">targetModel</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qModel</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>
</pre></div>
</div>
<p>さらに，<code class="docutils literal notranslate"><span class="pre">main()</span></code> に戻って以下の記述ですが，これが強化学習を進めるためのものです．環境をリセットして，エージェントによる行動の選択，経験バッファに経験を溜めて，Q ネットワークを学習，エピソード終了後にターゲットネットワークを更新します．特に難しいところはないように思います．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">rewards</span><span class="p">,</span> <span class="n">costs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span> <span class="c1"># エピソード毎に報酬とニューラルネットワークの学習コストを溜めるリスト．</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span> <span class="c1"># エージェントによる行動の選択．これはターゲットネットワークによる選択．</span>
            <span class="n">newObservation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="c1"># 環境を進める．</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
            <span class="n">experiences</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;observation&quot;</span><span class="p">:</span> <span class="n">observation</span><span class="p">,</span> <span class="s2">&quot;action&quot;</span><span class="p">:</span> <span class="n">action</span><span class="p">,</span> <span class="s2">&quot;reward&quot;</span><span class="p">:</span> <span class="n">reward</span><span class="p">,</span> <span class="s2">&quot;newObservation&quot;</span><span class="p">:</span> <span class="n">newObservation</span><span class="p">,</span> <span class="s2">&quot;done&quot;</span><span class="p">:</span> <span class="n">done</span><span class="p">})</span> <span class="c1"># 経験を蓄積．</span>
            <span class="n">observation</span> <span class="o">=</span> <span class="n">newObservation</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">experiences</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">minibatchSize</span><span class="p">:</span> <span class="c1"># ミニバッチのサイズに達するまで経験がたまったらニューラルネットワークの学習を開始する．</span>
                <span class="n">cost</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">experiences</span><span class="p">)</span> <span class="c1"># Qネットワーク（qModel）の学習．</span>
                <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span> <span class="k">break</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">experiences</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">minibatchSize</span><span class="p">:</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">update</span><span class="p">()</span> <span class="c1"># エピソードの最後にターゲットネットワーク（targetModel）の更新．</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Episode: </span><span class="si">{:3d}</span><span class="s2">, Number of steps: </span><span class="si">{:3d}</span><span class="s2">, Mean reward: </span><span class="si">{:3.1f}</span><span class="s2">, Cost: </span><span class="si">{:5.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">episode</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">costs</span><span class="p">)))</span>
</pre></div>
</div>
<p>最後の以下の部分はテスト結果を可視化するための記述です．本来は学習とテストのコードは分けた方が良いです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 以下はテスト結果を可視化するため．</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">frame</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">))</span>
    <span class="n">frames</span> <span class="o">=</span> <span class="p">[[</span><span class="n">frame</span><span class="p">]]</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">))</span> <span class="c1"># 描画のための記述</span>
        <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">frame</span><span class="p">])</span>
    <span class="n">generatedAnimation</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">ArtistAnimation</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">(),</span> <span class="n">frames</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 描画のための記述</span>
    <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">display</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">generatedAnimation</span><span class="o">.</span><span class="n">to_jshtml</span><span class="p">()))</span> <span class="c1"># 描画のための記述</span>
    <span class="n">generatedAnimation</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;cartpole-01.gif&quot;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s2">&quot;pillow&quot;</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>終わりです．</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebook"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="tensorflow_08.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">11. </span>敵対的生成ネットワーク</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="worksheet.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">演習問題</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      <div class="extra_footer">
        <a href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img style="0;margin-bottom:0.2em;" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a> © Copyright 2022 Graduate School of Information Sciences, Tohoku University．

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>