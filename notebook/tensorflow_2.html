
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>7. 多層パーセプトロン &#8212; 実践！データ科学 🎲</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8. Hugging Face の利用方法" href="tensorflow_7.html" />
    <link rel="prev" title="6. TensorFlow の基本的な利用方法" href="tensorflow_1.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/neko.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">実践！データ科学 🎲</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  データ科学を学ぶにあたって
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="introduction.html">
   1. 機械学習とその周辺事項
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  プログラミングの基礎
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="python_1.html">
   2. Python の基本的な使用方法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_2.html">
   3. Python の発展的な使用方法
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  scikit-learn を利用した機械学習
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="scikit_learn_1.html">
   4. 教師あり学習法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scikit_learn_2.html">
   5. 教師なし学習法
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  深層学習
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="tensorflow_1.html">
   6. TensorFlow の基本的な利用方法
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   7. 多層パーセプトロン
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tensorflow_7.html">
   8. Hugging Face の利用方法
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebook/tensorflow_2.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/yamada-kd/binds-training/tree/main/notebook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/yamada-kd/binds-training/blob/main/notebook/tensorflow_2.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   7.1. 扱うデータの紹介
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mnist">
     7.1.1. MNIST について
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     7.1.2. ダウンロードと可視化
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mlp">
   7.2. MLP の実装
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     7.2.1. 簡単な MLP の実装
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     7.2.2. MNIST を利用した学習
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     7.2.3. 学習曲線の描画
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     7.2.4. 早期終了
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     7.2.5. モデルの保存と利用
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>多層パーセプトロン</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   7.1. 扱うデータの紹介
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mnist">
     7.1.1. MNIST について
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     7.1.2. ダウンロードと可視化
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mlp">
   7.2. MLP の実装
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     7.2.1. 簡単な MLP の実装
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     7.2.2. MNIST を利用した学習
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     7.2.3. 学習曲線の描画
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     7.2.4. 早期終了
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     7.2.5. モデルの保存と利用
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1><span class="section-number">7. </span>多層パーセプトロン<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id2">
<h2><span class="section-number">7.1. </span>扱うデータの紹介<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>このコンテンツでは最も基本的な深層学習アルゴリズムである多層パーセプトロンを実装する方法を紹介します．多層パーセプトロンは英語では multilayer perceptron（MLP）と言います．ニューラルネットワークの一種です．層という概念があり，この層を幾重にも重ねることで深層ニューラルネットワークを構築することができます．MLP を実装するためにとても有名なデータセットを利用しますが，この節ではそのデータセットの紹介をします．</p>
<div class="section" id="mnist">
<h3><span class="section-number">7.1.1. </span>MNIST について<a class="headerlink" href="#mnist" title="Permalink to this headline">¶</a></h3>
<p>MLP に処理させるデータセットとして，機械学習界隈で最も有名なデータセットである MNIST（Mixed National Institute of Standards and Technology database）を解析対象に用います．「エムニスト」と発音します．MNIST は縦横28ピクセル，合計784ピクセルよりなる画像データです．画像には手書きの一桁の数字（0から9）が含まれています．公式ウェブサイトでは，学習データセット6万個とテストデータセット1万個，全部で7万個の画像からなるデータセットが無償で提供されています．</p>
</div>
<div class="section" id="id3">
<h3><span class="section-number">7.1.2. </span>ダウンロードと可視化<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>公式サイトよりダウンロードしてきても良いのですが，TensorFlow がダウンロードするためのユーティリティを準備してくれているため，それを用います．以下の <code class="docutils literal notranslate"><span class="pre">tf.keras.datasets.mnist.load_data()</span></code> を用いることで可能です．MNIST は合計7万インスタンスからなるデータセットです．5行目でふたつのタプルにデータをダウンロードしていますが，最初のタプルは学習データセット，次のタプルはテストデータセットのためのものです．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">),</span> <span class="p">(</span><span class="n">litestx</span><span class="p">,</span> <span class="n">litestt</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of instances in the learning dataset:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lilearnx</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of instances in the test dataset:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">litestx</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">litestt</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The input vector of the first instance in the learning dataset:&quot;</span><span class="p">,</span> <span class="n">lilearnx</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Its shape:&quot;</span><span class="p">,</span> <span class="n">lilearnx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The target vector of the first instance in the learning datast:&quot;</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1"># 2番目のインスタンスのインプットデータとターゲットデータを確認．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
	<span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>データを可視化します．可視化のために matplotlib というライブラリをインポートします．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span> <span class="n">lilearnt</span><span class="p">),</span> <span class="p">(</span><span class="n">litestx</span><span class="p">,</span> <span class="n">litestt</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">lilearnx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
    <span class="c1"># 別のインプットデータを表示．</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
	<span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>このデータセットがダウンロードされている場所は <code class="docutils literal notranslate"><span class="pre">~/.keras/datasets</span></code> です．以下のような BaSH のコマンドを打つことで確認することができます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> ls /root/.keras/datasets
</pre></div>
</div>
</div>
</div>
<p>MNIST はこのような縦が28ピクセル，横が28ピクセルからなる手書き文字が書かれた（描かれた）画像です（0から9までの値）．それに対して，その手書き文字が0から9のどれなのかという正解データが紐づいています．この画像データを MLP に読み込ませ，それがどの数字なのかを当てるという課題に取り組みます．</p>
</div>
</div>
<div class="section" id="mlp">
<h2><span class="section-number">7.2. </span>MLP の実装<a class="headerlink" href="#mlp" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id4">
<h3><span class="section-number">7.2.1. </span>簡単な MLP の実装<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>実際に MNIST を処理する MLP を実装する前に，とても簡単なデータを処理するための MLP を実装します．ここでは，以下のようなデータを利用します．これが学習セットです．ここでは MLP の実装の方法を紹介するだけなのでバリデーションセットもテストセットも使用しません．</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>入力ベクトル</p></th>
<th class="text-align:center head"><p>ターゲットベクトル</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>[ 1.1, 2.2, 3.0, 4.0 ]</p></td>
<td class="text-align:center"><p>[ 0 ]</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>[ 2.0, 3.0, 4.0, 1.0 ]</p></td>
<td class="text-align:center"><p>[ 1 ]</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>[ 2.0, 2.0, 3.0, 4.0 ]</p></td>
<td class="text-align:center"><p>[ 2 ]</p></td>
</tr>
</tbody>
</table>
<p>すなわち，<code class="docutils literal notranslate"><span class="pre">[1.1,</span> <span class="pre">2.2,</span> <span class="pre">3.0,</span> <span class="pre">4.0]</span></code> が人工知能へ入力されたら，<code class="docutils literal notranslate"><span class="pre">0</span></code> というクラスを返し，<code class="docutils literal notranslate"><span class="pre">[2.0,</span> <span class="pre">3.0,</span> <span class="pre">4.0,</span> <span class="pre">1.0]</span></code> というベクトルが入力されたら <code class="docutils literal notranslate"><span class="pre">1</span></code> というクラスを返し，<code class="docutils literal notranslate"><span class="pre">[2.0,</span> <span class="pre">2.0,</span> <span class="pre">3.0,</span> <span class="pre">4.0]</span></code> というベクトルが入力されたら <code class="docutils literal notranslate"><span class="pre">2</span></code> というクラスを返す人工知能を MLP で構築します．実際には以下のように書きます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># データセットの生成</span>
    <span class="n">tx</span><span class="o">=</span><span class="p">[[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]]</span>
    <span class="n">tx</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tt</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">tt</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">()</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span> <span class="c1">#正解と出力の順番はこの通りにする必要がある．</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3000</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span> <span class="c1"># 学習の回数の上限値</span>
        <span class="n">traincost</span><span class="p">,</span><span class="n">trainacc</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="k">100</span>==0:
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:5d}</span><span class="s2">: Training cost= </span><span class="si">{:.4f}</span><span class="s2">, Training ACC= </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">trainacc</span><span class="p">))</span>
    
    <span class="c1"># 学習が本当にうまくいったのか入力ベクトルのひとつを処理させてみる</span>
    <span class="n">tx1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">ty1</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ty1</span><span class="p">)</span>

    <span class="c1"># 未知のデータを読ませてみる</span>
    <span class="n">tu</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">999</span><span class="p">,</span><span class="mi">888</span><span class="p">,</span><span class="mi">777</span><span class="p">,</span><span class="mi">666</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tu</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>

    <span class="c1"># Denseの最初の引数の値やエポックの値や変化させて，何が起こっているか把握する．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span> <span class="c1"># これは全結合層を生成するための記述．</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>上から説明を行います．以下のような記述があります．ここで，上述のデータを生成しています．<code class="docutils literal notranslate"><span class="pre">tx</span></code> は入力ベクトル3つです．<code class="docutils literal notranslate"><span class="pre">tt</span></code> はそれに対応するターゲットベクトル（スカラ）3つです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">tx</span><span class="o">=</span><span class="p">[[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]]</span>
    <span class="n">tx</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tt</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">tt</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tt</span><span class="p">)</span>
</pre></div>
</div>
<p>次に，以下のような記述があります．この記述によって未学習の人工知能を生成します．生成した人工知能は <code class="docutils literal notranslate"><span class="pre">model</span></code> です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">()</span>
</pre></div>
</div>
<p>この未学習の人工知能を生成するための記述の本体はプログラムの最下層辺りにある以下の記述です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
<p>ここに <code class="docutils literal notranslate"><span class="pre">Dense(10,</span> <span class="pre">activation=&quot;relu&quot;)</span></code> とありますが，これは10個のニューロンを持つ層を1個生成するための記述です．活性化関数に ReLU を使うようにしています．これによって生成される層の名前は <code class="docutils literal notranslate"><span class="pre">self.d1()</span></code> です．ここでは10個という値を設定していますが，これは100でも1万でも1兆でもなんでも良いです．解きたい課題にあわせて増やしたり減らしたりします．ここをうまく選ぶことでより良い人工知能を構築でき，腕の見せ所です．次に，<code class="docutils literal notranslate"><span class="pre">Dense(3,</span> <span class="pre">activation=&quot;softmax&quot;)</span></code> という記述で3個のニューロンを持つ層を1個生成します．この3個という値は意味を持っています．入力するデータのクラスが0，1または2の3分類（クラス）であるからです．また，活性化関数にはソフトマックス関数を指定しています．ソフトマックス関数の出力ベクトルの要素を合計すると1になります．各要素の最小値は0です．よって出力結果を確率として解釈できます．次の，<code class="docutils literal notranslate"><span class="pre">def</span> <span class="pre">call(self,x):</span></code> という記述はこれ（<code class="docutils literal notranslate"><span class="pre">class</span> <span class="pre">Network()</span></code>）によって生成した人工知能を呼び出したときにどのような計算をさせるかを定義するものです．入力として <code class="docutils literal notranslate"><span class="pre">x</span></code> というベクトルが与えられたら，それに対して最初の層を適用し，次に，その出力に対して次の層を適用し，その値を出力する，と定義しています．構築した人工知能 <code class="docutils literal notranslate"><span class="pre">model</span></code> に対して <code class="docutils literal notranslate"><span class="pre">model.call()</span></code> のような方法で呼び出すことができます．</p>
<p>次の以下の記述は，それぞれ，損失関数，正確度（ACC）を計算する関数，最急降下法の最適化法（パラメータの更新ルール）を定義するものです．これは，TensorFlow ではこのように書くのだと覚えるものです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
</pre></div>
</div>
<p>次の以下の記述は損失を計算するためのものです．この <code class="docutils literal notranslate"><span class="pre">tf.GradientTapa()</span></code> は上でも出ました．最初に，<code class="docutils literal notranslate"><span class="pre">model.call()</span></code> に入力ベクトルのデータを処理させて出力ベクトル <code class="docutils literal notranslate"><span class="pre">ty</span></code> を得ます．この出力ベクトルとターゲットベクトルを損失関数の入力として損失 <code class="docutils literal notranslate"><span class="pre">traincost</span></code> を得ます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span> <span class="c1">#正解と出力の順番はこの通りにする必要がある．</span>
</pre></div>
</div>
<p>この損失は人工知能が持つパラメータによって微分可能なので，以下の記述によって勾配を求めます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
</pre></div>
</div>
<p>以下の記述はパラメータ更新のための最急降下法の定義と損失とは別の性能評価指標である正確度（accuracy（ACC））を計算するための定義です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
</pre></div>
</div>
<p>最後の以下の記述はこの関数の戻り値を定義するものです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
</pre></div>
</div>
<p>次に記述されている以下の部分は，実際の学習のループに関するものです．このループでデータを何度も何度も予測器（人工知能）に読ませ，そのパラメータを成長させます．この場合，3000回データを学習させます．また，学習100回毎に学習の状況を出力させます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3000</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">traincost</span><span class="p">,</span><span class="n">trainacc</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="mi">100</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:5d}</span><span class="s2">: Training cost= </span><span class="si">{:.4f}</span><span class="s2">, Training ACC= </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">trainacc</span><span class="p">))</span>
</pre></div>
</div>
<p>次の記述，以下の部分では学習がうまくいったのかを確認するために学習データのひとつを学習済みの人工知能に読ませて予測をさせています．この場合，最初のデータのターゲットベクトルは0なので0が出力されなければなりません．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習が本当にうまくいったのか入力ベクトルのひとつを処理させてみる</span>
    <span class="n">tx1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">ty1</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ty1</span><span class="p">)</span>
</pre></div>
</div>
<p>出力結果は以下のようになっているはずです．出力はソフトマックス関数なので各クラスの確率が表示されています．これを確認すると，最初のクラス（0）である確率が99%以上であると出力されています．よって，やはり人工知能は意図した通り成長したことが確認できます．</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">9.932116e-01</span> <span class="mf">7.842198e-06</span> <span class="mf">6.780579e-03</span><span class="p">]],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>次に，全く新たなデータを入力しています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 未知のデータを読ませてみる</span>
    <span class="n">tu</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">999</span><span class="p">,</span><span class="mi">888</span><span class="p">,</span><span class="mi">777</span><span class="p">,</span><span class="mi">666</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tu</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">[999,888,777,666]</span></code> というベクトルを入力したときにどのような出力がされるかということですが，この場合，以下のような出力がされています．このベクトルを入力したときの予測値は2であるとこの人工知能は予測したということです．</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">0.</span> <span class="mf">0.</span> <span class="mf">1.</span><span class="p">]],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p>以下では <code class="docutils literal notranslate"><span class="pre">Dense()</span></code> の挙動を確認してみます．<code class="docutils literal notranslate"><span class="pre">Dense()</span></code> はもちろんクラスの中でなければ使えない関数ではなく，<code class="docutils literal notranslate"><span class="pre">main()</span></code> の中でも呼び出して利用可能です．これで挙動を確認することでどのようにネットワークが構築されているか把握できるかもしれません．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># データセットの生成</span>
    <span class="n">tx</span><span class="o">=</span><span class="p">[[</span><span class="mf">1.1</span><span class="p">,</span><span class="mf">2.2</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">3.0</span><span class="p">,</span><span class="mf">4.0</span><span class="p">]]</span>
    <span class="n">tx</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="c1"># 関数を定義</span>
    <span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>

    <span class="c1"># データセットの最初の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;1-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># データセットの全部の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;2-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">))</span>

    <span class="c1"># 活性化関数を変更した関数を定義</span>
    <span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>

    <span class="c1"># データセットの最初の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;3-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># データセットの全部の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;4-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">))</span>

    <span class="c1"># 最初の引数の値を変更した関数を定義</span>
    <span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>

    <span class="c1"># データセットの最初の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;5-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># データセットの全部の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;6-----------&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">))</span>

    <span class="c1"># 別の関数を定義</span>
    <span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>
    <span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>

    <span class="c1"># データセットの最初の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;7-----------&quot;</span><span class="p">)</span>
    <span class="n">y</span><span class="o">=</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

    <span class="c1"># データセットの全部の値を入力</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;8-----------&quot;</span><span class="p">)</span>
    <span class="n">y</span><span class="o">=</span><span class="n">d1</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id5">
<h3><span class="section-number">7.2.2. </span>MNIST を利用した学習<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>次に，MNIST を処理して「0から9の数字が書かれた（描かれた）手書き文字を入力にして，その手書き文字が0から9のどれなのかを判別する人工知能」を構築します．以下のように書きます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>
    <span class="n">MINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># ミニバッチのサイズとトレーニングデータのサイズから何個のミニバッチができるか計算</span>

    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span> <span class="c1"># MNISTにおいて出力ベクトルのサイズは0から9の10</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
    
    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用するため学習では利用しないが次のコードのために一応定義しておく．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span> <span class="c1"># 「mode」という変数を新たに設定．これでパラメータ更新をするかしないかを制御する（バリデーションではパラメータ更新はしない）．</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>

    <span class="c1"># ユニットサイズやミニバッチサイズを変更したり層を追加したりして挙動を把握する．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>プログラムの中身について上から順に説明します．以下の部分はハイパーパラメータを設定する記述です．<code class="docutils literal notranslate"><span class="pre">MAXEPOCH</span></code> は計算させる最大エポックです．このエポックに至るまで繰り返しの学習をさせるということです．<code class="docutils literal notranslate"><span class="pre">MINIBATCHSIZE</span></code> とはミニバッチ処理でサンプリングするデータのサイズです．これが大きいとき実計算時間は短縮されます．この値が <code class="docutils literal notranslate"><span class="pre">1</span></code> のとき，学習法はオンライン学習法であり，この値がトレーニングセットのサイズと等しいとき，学習法は一括更新法です．ミニバッチの大きさは持っているマシンのスペックと相談しつつ，色々な値を試してみて一番良い値をトライアンドエラーで探します．<code class="docutils literal notranslate"><span class="pre">UNITSIZE</span></code> は MLP の層のサイズ，つまり，ニューロンの数です．<code class="docutils literal notranslate"><span class="pre">TRAINSIZE</span></code> はトレーニングセットのインスタンスの大きさです．MNIST の学習セットは60000インスタンスからなるのでその90%をトレーニングセットとして利用することにしています．<code class="docutils literal notranslate"><span class="pre">MINIBATCHNUMBER</span></code> はミニバッチのサイズとデータのサイズから計算されるミニバッチの個数です．オンライン学習法の場合，1エポックでパラメータ更新は，この例の場合，54000回行われます．一括更新法の場合，1エポックでパラメータ更新は1回行われます．このミニバッチのサイズ（500）とデータサイズの場合，1エポックでパラメータ更新は108回行われます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>
    <span class="n">MINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># ミニバッチのサイズとトレーニングデータのサイズから何個のミニバッチができるか計算</span>
</pre></div>
</div>
<p>データの読み込みは上で説明したため省略し，以下の部分では読み込んだデータをトレーニングセットとバリデーションセットに分割しています．この <code class="docutils literal notranslate"><span class="pre">:</span></code> の利用方法は NumPy の使い方解説のところで行った通りです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
</pre></div>
</div>
<p>以下の記述では，MNIST に含まれる値を0以上1以下の値に変換しています（元々の MNIST は0から255の値で構成されています）．用いるオプティマイザの種類やそのパラメータ更新を大きさを決めるハイパーパラメータ（学習率）の設定によってはこのような操作が良い効果をもたらす場合があります．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
</pre></div>
</div>
<p>ネットワークの定義は以下で行います．これは前述の例と同じです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用するため学習では利用しないが次のコードのために一応定義しておく．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
</pre></div>
</div>
<p>ネットワーク自体は以下の部分で定義されているのですが，前述の例と少し異なります．ここでは，28行28列の行列を784要素のベクトルに変換するための層 <code class="docutils literal notranslate"><span class="pre">self.d0</span></code> を定義しています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
<p>学習1回分の記述は前述の例と少し異なります．<code class="docutils literal notranslate"><span class="pre">mode</span></code> という変数を利用して，トレーニングの際にはパラメータ更新を行い，バリデーションの際にはパラメータ更新を行わないように制御します．その他は前述の例と同じです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span> <span class="c1"># 「mode」という変数を新たに設定．これでパラメータ更新をするかしないかを制御する（バリデーションではパラメータ更新はしない）．</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
</pre></div>
</div>
<p>学習ループが開始された最初の <code class="docutils literal notranslate"><span class="pre">index=np.random.permutation(TRAINSIZE)</span></code> ではトレーニングセットのサイズに応じた（この場合，0から53999）整数からなる要素をランダムに並べた配列を生成します．これを利用して，ミニバッチのときにランダムにインスタンスを抽出します．<code class="docutils literal notranslate"><span class="pre">traincost=0</span></code> のところではトレーニングコストを計算するための変数を宣言しています．ミニバッチ処理をするので，トレーニングコストはミニバッチの個数分，この場合108個分計算されるのですが，これを平均するために利用する変数です．この変数にミニバッチ処理1回毎に出力されるコストを足し合わせて，最後にミニバッチ処理の回数で割り平均値を出します．その次の <code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">subepoch</span> <span class="pre">in</span> <span class="pre">range(MINIBATCHNUMBER):</span></code> がミニバッチの処理です．この場合，最初に <code class="docutils literal notranslate"><span class="pre">somb</span></code> に入る値は <code class="docutils literal notranslate"><span class="pre">0</span></code>，<code class="docutils literal notranslate"><span class="pre">eomb</span></code> に入る値は <code class="docutils literal notranslate"><span class="pre">500</span></code> です．1番目から500番目までのデータを抽出する作業のためです．<code class="docutils literal notranslate"><span class="pre">index[somb:eomb]</span></code> には500個のランダムに抽出された整数が入っていますが，それを <code class="docutils literal notranslate"><span class="pre">litrainx[index[somb:eomb]]</span></code> のように使うことで，トレーニングセットからランダムに500個のインスタンスを抽出します．<code class="docutils literal notranslate"><span class="pre">traincost+=subtraincost</span></code> は1回のミニバッチ処理で計算されたコストを上で準備した変数に足し合わせる記述です．ミニバッチ処理が終了した後は，<code class="docutils literal notranslate"><span class="pre">traincost=traincost/MINIBATCHNUMBER</span></code> によって平均トレーニングコストを計算し，また，<code class="docutils literal notranslate"><span class="pre">validcost,_=inference(livalidx,livalidt,False)</span></code> によってバリデーションコストを計算し，それらの値をエポック毎に出力する記述をしています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習ループ</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
</pre></div>
</div>
<p>次に，出力結果について説明します．このプログラムを実行するとエポックとその時のトレーニングコストとバリデーションコストが出力されます．</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span>    <span class="mi">1</span><span class="p">:</span> <span class="n">Training</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.4437</span> <span class="n">Validation</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.1900</span>
<span class="n">Epoch</span>    <span class="mi">2</span><span class="p">:</span> <span class="n">Training</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.1914</span> <span class="n">Validation</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.1325</span>
<span class="n">Epoch</span>    <span class="mi">3</span><span class="p">:</span> <span class="n">Training</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.1372</span> <span class="n">Validation</span> <span class="n">cost</span><span class="o">=</span>  <span class="mf">0.1056</span>
<span class="o">.</span>
<span class="o">.</span>
<span class="o">.</span>
</pre></div>
</div>
<p>これは各エポックのときの人工知能の性能です．エポックが50のとき，トレーニングのコストはとても小さい値です．コストは小さければ小さいほど良いので，学習はしっかりされていることが確認されます．しかし，これはトレーニングデータに対する人工知能の性能です．もしかしたらトレーニングデータに対してのみ性能を発揮できる，トレーニングデータに過剰に適合してしまった人工知能である可能性があります．だから，そうなっていないかどうかを確認する別のデータ，つまり，バリデーションデータセットにおけるコストも確認する必要があります．エポックが50のときのバリデーションのコストはエポック20くらいのときのコストより大きくなっています．すなわち，この人工知能はトレーニングデータに過剰に適合しています．おそらくエポック20くらいの人工知能が最も良い人工知能であって，これを最終的なプロダクトとして選択する必要があります．次の操作ではこれを行います．</p>
</div>
<div class="section" id="id6">
<h3><span class="section-number">7.2.3. </span>学習曲線の描画<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>学習曲線とは横軸にエポック，縦軸にコストの値をプロットした図です．これを観察することで，どれくらいのエポックで学習が進み始めたか，人工知能の成長が止まったか，どのくらいのエポックで過剰適合が起きたか等を視覚的に理解することができます（慣れたら前述の結果のような数字を読むだけでこの図を想像できるようになるのだと思います）．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>
    <span class="n">MINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># ミニバッチのサイズとトレーニングデータのサイズから何個のミニバッチができるか計算</span>

    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span> <span class="c1"># MNISTにおいて出力ベクトルのサイズは0から9の10</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
    
    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用するため学習では利用しないが次のコードのために一応定義しておく．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>

    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># 次に進む．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>最初に，コードの変更部位について説明します．以下の部分を追加しました．これは描画に必要なライブラリである <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> を利用するための記述です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
<p>次に，学習ループの記述ですが，以下のように最初に <code class="docutils literal notranslate"><span class="pre">liepoch</span></code>，<code class="docutils literal notranslate"><span class="pre">litraincost</span></code>，<code class="docutils literal notranslate"><span class="pre">livalidcost</span></code> という3つの空の配列を用意しました．その後ループの最後で，これらの配列に，それぞれ，エポックの値，トレーニングのコストおよびバリデーションのコストをエポックを進めるたびに追加しています．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
</pre></div>
</div>
<p>最後の以下の部分は学習曲線をプロットするためのコードです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>結果を観ると，トレーニングセットにおけるコストの値はエポックを経るにつれて小さくなっていることがわかります．これは，人工知能が与えられたデータに適合していることを示しています．一方で，バリデーションセットにおけるコストの値は大体エポックが10と20の間くらいで下げ止まり，その後はコストが増加に転じています．このコストの増加，人工知能がこのデータセットに適合するのとは逆の方向に成長を始めたことを意味しています．この現象が起こった原因は，この人工知能がその成長に利用するデータセット（トレーニングデータセット）に（のみ）過剰に適合し，汎化性能を失ったことにあります．この曲線を観察する限り，エポックは大体10から20の間くらいに留めておいた方が良さそうです．このような画像を観て，大体20で学習を止める，みたいに決めても悪くはありませんが，もっと体系的な方法があるので次にその方法を紹介します．</p>
</div>
<div class="section" id="id7">
<h3><span class="section-number">7.2.4. </span>早期終了<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>学習の早期終了（early stopping）とは過学習を防ぐための方法です．ここでは，ペイシェンス（patience）を利用した早期終了を紹介します．この方法では最も良い値のバリデーションコストを記録し続けます．そして学習を続け，そのベストなバリデーションコストを <span class="math notranslate nohighlight">\(n\)</span> 回連続で更新できなかった場合，そこで学習を打ち切ります．この <span class="math notranslate nohighlight">\(n\)</span> がペイシェンスと呼ばれる値です．ペイシェンスには我慢とか忍耐とかそのような意味があります．コードは以下のように書きます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>
    <span class="n">MINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># ミニバッチのサイズとトレーニングデータのサイズから何個のミニバッチができるか計算</span>
    <span class="n">PATIENCE</span><span class="o">=</span><span class="mi">5</span>

    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span> <span class="c1"># MNISTにおいて出力ベクトルのサイズは0から9の10</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
    
    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用するため学習では利用しないが次のコードのために一応定義しておく．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="n">patiencecounter</span><span class="p">,</span><span class="n">bestvalue</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">100000</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># 次に進む．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>プログラムには以下の部分を追加しました．今回は4回までコストが改善しなくても許すが，5回目は許さないということです．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">PATIENCE</span><span class="o">=</span><span class="mi">5</span>
</pre></div>
</div>
<p>学習ループを以下のようにコードを追加しました．<code class="docutils literal notranslate"><span class="pre">patiencecounter</span></code> はコストが更新されなかった回数を数えるカウンタです．<code class="docutils literal notranslate"><span class="pre">bestvalue</span></code> は最も良いコストの値を記録する変数です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="n">patiencecounter</span><span class="p">,</span><span class="n">bestvalue</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">100000</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="k">break</span>
</pre></div>
</div>
<p>以下の部分で，もし最も良いコストよりさらに良いコストが得られたらベストなコストを更新し，また，ペイシェンスのカウンタを元に（<code class="docutils literal notranslate"><span class="pre">0</span></code>）戻す作業をし，それ以外の場合はペイシェンスのカウンタを1ずつ増やします．もし，カウンタの値があらかじめ設定したペイシェンスの値に達したら学習ループを停止します．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="k">break</span>
</pre></div>
</div>
<p>結果を観ると，過学習が起こっていなさそうなところで学習が停止されているのが解ります．</p>
</div>
<div class="section" id="id8">
<h3><span class="section-number">7.2.5. </span>モデルの保存と利用<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>これまでに，早期終了を利用して良い人工知能が生成できるエポックが判明しました．機械学習の目的は当然，良い人工知能を開発することです．開発した人工知能は普通，別のサーバーとかトレーニングした時とは別の時間に利用したいはずです．ここで，この学習で発見した人工知能を保存して別のプログラムから，独立した人工知能として利用する方法を紹介します．最後に，テストセットでのその人工知能の性能を評価します．コードは以下のように変更します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">MAXEPOCH</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">MINIBATCHSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>
    <span class="n">MINIBATCHNUMBER</span><span class="o">=</span><span class="n">TRAINSIZE</span><span class="o">//</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># ミニバッチのサイズとトレーニングデータのサイズから何個のミニバッチができるか計算</span>
    <span class="n">PATIENCE</span><span class="o">=</span><span class="mi">5</span>

    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span> <span class="c1"># MNISTにおいて出力ベクトルのサイズは0から9の10</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
    
    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用するため学習では利用しないが次のコードのために一応定義しておく．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    <span class="c1"># モデルを保存するための記述</span>
    <span class="n">checkpoint</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># 学習ループ</span>
    <span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">livalidcost</span><span class="o">=</span><span class="p">[],[],[]</span>
    <span class="n">patiencecounter</span><span class="p">,</span><span class="n">bestvalue</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">100000</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">MAXEPOCH</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="c1"># トレーニング</span>
        <span class="n">index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">TRAINSIZE</span><span class="p">)</span>
        <span class="n">traincost</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">for</span> <span class="n">subepoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MINIBATCHNUMBER</span><span class="p">):</span> <span class="c1"># 「subepoch」は「epoch in epoch」と呼ばれるのを見たことがある．</span>
            <span class="n">somb</span><span class="o">=</span><span class="n">subepoch</span><span class="o">*</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「start of minibatch」</span>
            <span class="n">eomb</span><span class="o">=</span><span class="n">somb</span><span class="o">+</span><span class="n">MINIBATCHSIZE</span> <span class="c1"># 「end of minibatch」</span>
            <span class="n">subtraincost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litrainx</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="n">litraint</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">somb</span><span class="p">:</span><span class="n">eomb</span><span class="p">]],</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">traincost</span><span class="o">+=</span><span class="n">subtraincost</span>
        <span class="n">traincost</span><span class="o">=</span><span class="n">traincost</span><span class="o">/</span><span class="n">MINIBATCHNUMBER</span>
        <span class="c1"># バリデーション</span>
        <span class="n">validcost</span><span class="p">,</span><span class="n">_</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 学習過程の出力</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{:4d}</span><span class="s2">: Training cost= </span><span class="si">{:7.4f}</span><span class="s2"> Validation cost= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">traincost</span><span class="p">,</span><span class="n">validcost</span><span class="p">))</span>
        <span class="n">liepoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">litraincost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">traincost</span><span class="p">)</span>
        <span class="n">livalidcost</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validcost</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">validcost</span><span class="o">&lt;</span><span class="n">bestvalue</span><span class="p">:</span>
            <span class="n">bestvalue</span><span class="o">=</span><span class="n">validcost</span>
            <span class="n">patiencecounter</span><span class="o">=</span><span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">patiencecounter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">patiencecounter</span><span class="o">==</span><span class="n">PATIENCE</span><span class="p">:</span>
            <span class="n">checkpoint</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;mlp-mnist/model&quot;</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="c1"># 学習曲線の描画    </span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">litraincost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">liepoch</span><span class="p">,</span><span class="n">livalidcost</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># ユニットサイズや層の数やその他のハイパーパラメータを色々変更してより良いバリデーションコストを出力する予測器を作る．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>以下の記述を追加しました．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># モデルを保存するための記述</span>
    <span class="n">checkpoint</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>また，学習ループの最後に以下のような記述を追加しました．<code class="docutils literal notranslate"><span class="pre">mlp-mnist</span></code> というディレクトリに <code class="docutils literal notranslate"><span class="pre">model</span></code> という名前で学習済みモデルを保存するように，という意味です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>            <span class="n">checkpoint</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;mlp-mnist/model&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>以下のシェルのコマンドを打つと，ディレクトリが新規に生成されていることを確認できます．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> ls mlp-mnist
</pre></div>
</div>
</div>
</div>
<p>最後に，以下のコードで保存したモデル（実体はパラメータ）を呼び出して，テストセットにてその性能を評価します．</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># ハイパーパラメータの設定</span>
    <span class="n">UNITSIZE</span><span class="o">=</span><span class="mi">500</span>
    <span class="n">TRAINSIZE</span><span class="o">=</span><span class="mi">54000</span>

    <span class="c1"># データの読み込み</span>
    <span class="p">(</span><span class="n">lilearnx</span><span class="p">,</span><span class="n">lilearnt</span><span class="p">),(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">)</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">outputsize</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">lilearnt</span><span class="p">))</span> <span class="c1"># MNISTにおいて出力ベクトルのサイズは0から9の10</span>
    
    <span class="c1"># 学習セットをトレーニングセットとバリデーションセットに分割（9:1）</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">litraint</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">],</span><span class="n">lilearnt</span><span class="p">[:</span><span class="n">TRAINSIZE</span><span class="p">]</span>
    <span class="n">livalidx</span><span class="p">,</span><span class="n">livalidt</span><span class="o">=</span><span class="n">lilearnx</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:],</span><span class="n">lilearnt</span><span class="p">[</span><span class="n">TRAINSIZE</span><span class="p">:]</span>
    
    <span class="c1"># 最大値を1にしておく</span>
    <span class="n">litrainx</span><span class="p">,</span><span class="n">livalidx</span><span class="p">,</span><span class="n">litestx</span><span class="o">=</span><span class="n">litrainx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">livalidx</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">litestx</span><span class="o">/</span><span class="mi">255</span>
    
    <span class="c1"># ネットワークの定義</span>
    <span class="n">model</span><span class="o">=</span><span class="n">Network</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">outputsize</span><span class="p">)</span>
    <span class="n">cce</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span> <span class="c1">#これでロス関数を生成する．</span>
    <span class="n">acc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span> <span class="c1"># これはテストの際に利用する．</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span> <span class="c1">#これでオプティマイザを生成する．</span>
    <span class="c1"># モデルの読み込み</span>
    <span class="n">checkpoint</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    <span class="n">checkpoint</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s2">&quot;mlp-mnist&quot;</span><span class="p">))</span>
    
    <span class="c1"># 学習1回の記述</span>
    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">tt</span><span class="p">,</span><span class="n">mode</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="n">mode</span>
            <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>
            <span class="n">costvalue</span><span class="o">=</span><span class="n">cce</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="n">gradient</span><span class="o">=</span><span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">costvalue</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        <span class="n">accvalue</span><span class="o">=</span><span class="n">acc</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span><span class="n">ty</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">costvalue</span><span class="p">,</span><span class="n">accvalue</span>
    
    <span class="c1"># テストセットでの性能評価</span>
    <span class="n">testcost</span><span class="p">,</span><span class="n">testacc</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test cost= </span><span class="si">{:7.4f}</span><span class="s2"> Test ACC= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">testcost</span><span class="p">,</span><span class="n">testacc</span><span class="p">))</span>

    <span class="c1"># テストセットの最初の画像を入力してみる</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">litestx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">litestt</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
    <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">litestx</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># 予測器にデータを入れて予測</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output vector:&quot;</span><span class="p">,</span><span class="n">ty</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="c1"># 出力ベクトルを表示</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Argmax of the output vector:&quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ty</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span> <span class="c1"># 出力ベクトルの要素の中で最も大きい値のインデックスを表示</span>

    <span class="c1"># 上で構築したハイパーパラメータを変化させたより良い人工知能の性能評価をする．</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">UNITSIZE</span><span class="p">,</span><span class="n">OUTPUTSIZE</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="o">=</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span> <span class="c1"># 行列をベクトルに変換</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">UNITSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="o">=</span><span class="n">Dense</span><span class="p">(</span><span class="n">OUTPUTSIZE</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d1</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">d2</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>学習済みモデルは以下のような記述で読み込みます．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># モデルの読み込み</span>
    <span class="n">checkpoint</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
    <span class="n">checkpoint</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s2">&quot;mlp-mnist&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>テストセットでの性能評価のための記述です．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># テストセットでの性能評価</span>
    <span class="n">testcost</span><span class="p">,</span><span class="n">testacc</span><span class="o">=</span><span class="n">inference</span><span class="p">(</span><span class="n">litestx</span><span class="p">,</span><span class="n">litestt</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test cost= </span><span class="si">{:7.4f}</span><span class="s2"> Test ACC= </span><span class="si">{:7.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">testcost</span><span class="p">,</span><span class="n">testacc</span><span class="p">))</span>
</pre></div>
</div>
<p>最後に，テストセットの最初の画像を予測器に入れてその結果を確認してみます．以下のコードで行います．</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># テストセットの最初の画像を入力してみる</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">litestx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">litestt</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
    <span class="n">ty</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">litestx</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># 予測器にデータを入れて予測</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output vector:&quot;</span><span class="p">,</span><span class="n">ty</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="c1"># 出力ベクトルを表示</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Argmax of the output vector:&quot;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ty</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span> <span class="c1"># 出力ベクトルの要素の中で最も大きい値のインデックスを表示</span>
</pre></div>
</div>
<p>実行すると，テストセットでも高い性能を示すことが確認できました．また，7が答えである画像を入力に，<code class="docutils literal notranslate"><span class="pre">7</span></code> を出力できていることを確認しました．</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>終わりです．</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebook"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="tensorflow_1.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">6. </span>TensorFlow の基本的な利用方法</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="tensorflow_7.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8. </span>Hugging Face の利用方法</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      <div class="extra_footer">
        <a href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img style="0;margin-bottom:0.2em;" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a> © Copyright 2022 Graduate School of Information Sciences, Tohoku University．

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>